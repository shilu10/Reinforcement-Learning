{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install gymnasium[atari] --quiet\n","!pip install gymnasium --quiet\n","!pip install -U gymnasium[atari] --quiet\n","!pip install imageio_ffmpeg --quiet\n","!pip install npy_append_array --quiet\n","!pip install pyTelegramBotAPI --quiet\n","!pip install gymnasium[accept-rom-license] --quiet\n","!pip install gymnasium[box2d] --quiet"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:22:00.957219Z","iopub.status.busy":"2023-03-14T08:22:00.956805Z","iopub.status.idle":"2023-03-14T08:22:00.973409Z","shell.execute_reply":"2023-03-14T08:22:00.972425Z","shell.execute_reply.started":"2023-03-14T08:22:00.957175Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","\n","class ExperienceReplayBuffer: \n","    def __init__(self, max_memory, input_shape, batch_size, cer=False): \n","        self.mem_size = max_memory\n","        self.mem_counter = 0\n","        self.state_memory = np.zeros((self.mem_size, *input_shape),\n","                                     dtype=np.float32)\n","        self.next_state_memory = np.zeros((self.mem_size, *input_shape),\n","                                         dtype=np.float32)\n","\n","        self.action_memory = np.zeros(self.mem_size, dtype=np.int64)\n","        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n","        self.terminal_memory = np.zeros(self.mem_size, dtype=bool)\n","        self.batch_size = batch_size\n","        self.cer = cer\n","\n","    def store_experience(self, state, action, reward, next_state, done): \n","        index = self.mem_counter % self.mem_size \n","\n","        self.state_memory[index] = state\n","        self.next_state_memory[index] = next_state\n","        self.reward_memory[index] = reward\n","        self.action_memory[index] = action\n","        self.terminal_memory[index] = done\n","        self.mem_counter += 1\n","\n","    def sample_experience(self, batch_size):\n","        # used to get the last transition\n","        offset = 1 if self.cer else 0\n","\n","        max_mem = min(self.mem_counter, self.mem_size) - offset\n","        batch_index = np.random.choice(max_mem, batch_size - offset, replace=False)\n","\n","        states = self.state_memory[batch_index]\n","        next_states = self.next_state_memory[batch_index]\n","        rewards = self.reward_memory[batch_index]\n","        actions = self.action_memory[batch_index]\n","        terminals = self.terminal_memory[batch_index]\n","\n","        if self.cer: \n","            last_index = self.mem_counter % self.mem_size - 1\n","            last_state = self.state_memory[last_index]\n","            last_action = self.action_memory[last_index]\n","            last_terminal = self.terminal_memory[last_index]\n","            last_next_state = self.next_state_memory[last_index]\n","            last_reward = self.reward_memory[last_index]\n","\n","            # for 2d and 3d use vstack to append, for 1d array use append() to append the data\n","            states = np.vstack((self.state_memory[batch_index], last_state))\n","            next_states = np.vstack((self.next_state_memory[batch_index], last_next_state))\n","\n","            actions = np.append(actions, last_action)\n","            terminals = np.append(terminals, last_terminal)\n","            rewards = np.append(rewards, last_reward)\n","    \n","        return states, actions, rewards, next_states, terminals\n","    \n","    \n","    def is_sufficient(self): \n","        return self.mem_counter > self.batch_size\n","        "]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:07:09.361208Z","iopub.status.busy":"2023-03-14T08:07:09.360455Z","iopub.status.idle":"2023-03-14T08:07:09.372361Z","shell.execute_reply":"2023-03-14T08:07:09.370960Z","shell.execute_reply.started":"2023-03-14T08:07:09.361146Z"},"trusted":true},"outputs":[],"source":["import tensorflow.keras as keras\n","from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPool2D, Input\n","\n","\n","class DeepQNetwork2D(keras.Model):\n","\n","    def __init__(self, input_dims, n_actions):\n","        super(DeepQNetwork2D, self).__init__()\n","     #   self.fc1 = Dense(64, activation='relu')\n","        self.fc1 = Dense(64, activation='relu')\n","        self.fc2 = Dense(64, activation='relu')\n","        self.fc3 = Dense(n_actions, activation=None)\n","\n","    def call(self, state):\n","\n","        x = self.fc1(state)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","\n","class DeepQNetwork3D(keras.Model): \n","    \n","    def __init__(self, input_dims, n_actions):\n","        super(DeepQNetwork3D, self).__init__()\n","\n","        self.conv1 = Conv2D(32, 8, strides=(4, 4), activation='relu', data_format=\"channels_first\")\n","        self.conv2 = Conv2D(32, 4, strides=(2, 2), activation='relu', data_format=\"channels_first\")\n","        self.conv3 = Conv2D(64, 3, strides=(1, 1), activation='relu', data_format=\"channels_first\")\n","        self.flatten = Flatten()\n","\n","        self.fc2 = Dense(128, activation='relu')\n","        self.fc3 = Dense(n_actions, activation=None)\n","\n","    def call(self, state):\n","\n","        x = self.conv1(state)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.flatten(x)\n","        \n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:02:21.570296Z","iopub.status.busy":"2023-03-14T08:02:21.569486Z","iopub.status.idle":"2023-03-14T08:02:21.578431Z","shell.execute_reply":"2023-03-14T08:02:21.577139Z","shell.execute_reply.started":"2023-03-14T08:02:21.570253Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","def epsilon_greedy_policy(q_val_network, observation, action_space, epsilon):\n","        if np.random.random() > epsilon:\n","            state = tf.convert_to_tensor([observation])\n","            actions = q_val_network.predict(state, verbose=0)\n","            action = tf.math.argmax(actions, axis=1).numpy()[0]\n","        else:\n","            action = np.random.choice(action_space)\n","        return action\n","\n","\n","def greedy_policy(observation, q_val_network, action_space): \n","    state = tf.convert_to_tensor([observation])\n","    actions = q_val_network(state)\n","    action = tf.math.argmax(actions, axis=1).numpy()[0]\n","    return action\n"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:22:18.669416Z","iopub.status.busy":"2023-03-14T08:22:18.669004Z","iopub.status.idle":"2023-03-14T08:22:18.707224Z","shell.execute_reply":"2023-03-14T08:22:18.705703Z","shell.execute_reply.started":"2023-03-14T08:22:18.669378Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras.optimizers import Adam\n","\n","#https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code/blob/master/DQN/tf2/agent.py\n","class Agent: \n","    def __init__(self, agent_params):\n","        # Parameters\n","        self.gamma = agent_params.get(\"gamma\")\n","        self.lr = agent_params.get(\"lr\")\n","        self.input_dims = agent_params.get(\"input_dims\")\n","        self.batch_size = agent_params.get(\"batch_size\")\n","        self.replace_target_weight_counter = agent_params.get(\"replace\")\n","        self.algo = agent_params.get(\"algo\")\n","        self.env_name = agent_params.get(\"env_name\")\n","        self.chkpt_dir = agent_params.get(\"chkpt_dir\")\n","        self.n_actions = agent_params.get(\"n_actions\")\n","        self.action_space = agent_params.get('actions')\n","        \n","        self.eps = agent_params.get(\"eps\")\n","        self.min_eps = agent_params.get(\"min_eps\")\n","        self.eps_decay_rate = agent_params.get(\"eps_decay_rate\")\n","        \n","        self.learn_step_counter = 0\n","        self.fname = self.chkpt_dir + self.env_name + '_' + self.algo + '_'\n","        self.mem_size = agent_params.get(\"mem_size\")\n","        \n","        self.cer = agent_params.get(\"cer\")\n","\n","        # networks and replaybuffer\n","        self.memory = ExperienceReplayBuffer(self.mem_size, self.input_dims, self.batch_size, self.cer)\n","        self.q_value_network = DeepQNetwork2D(self.input_dims, self.n_actions) if len(self.input_dims) < 3 else \\\n","                                                        DeepQNetwork3D(self.input_dims, self.n_actions)\n","        self.q_value_network.compile(optimizer=Adam(learning_rate=self.lr))\n","        self.target_q_network = DeepQNetwork2D(self.input_dims, self.n_actions) if len(self.input_dims) < 3 else \\\n","                                                        DeepQNetwork3D(self.input_dims, self.n_actions)\n","        self.target_q_network.compile(optimizer=Adam(learning_rate=self.lr))\n","\n","    def save_models(self):\n","        self.q_value_network.save(self.fname+'q_value_cer')\n","        self.target_q_network.save(self.fname+'target_q_cer')\n","        print('... models saved successfully ...')\n","\n","    def load_models(self):\n","        self.q_value_network = keras.models.load_model(self.fname+'q_value_cer')\n","        self.target_q_network = keras.models.load_model(self.fname+'target_q_cer')\n","        print('... models loaded successfully ...')\n","\n","    def store_experience(self, state, action, reward, state_, done):\n","        self.memory.store_experience(state, action, reward, state_, done)\n","\n","    def sample_experience(self):\n","        state, action, reward, new_state, done = \\\n","                                  self.memory.sample_experience(self.batch_size)\n","        states = tf.convert_to_tensor(state)\n","        rewards = tf.convert_to_tensor(reward)\n","        dones = tf.convert_to_tensor(done)\n","        actions = tf.convert_to_tensor(action, dtype=tf.int32)\n","        states_ = tf.convert_to_tensor(new_state)\n","        return states, actions, rewards, states_, dones\n","\n","    def choose_action(self, observation):\n","        if np.random.random() > self.eps:\n","            state = tf.convert_to_tensor([observation])\n","            actions = self.q_value_network(state)\n","            action = tf.math.argmax(actions, axis=1).numpy()[0]\n","        else:\n","            action = np.random.choice(self.action_space)\n","        return action\n","\n","    def replace_target_network(self):\n","        if self.learn_step_counter % self.replace_target_weight_counter == 0:\n","            self.target_q_network.set_weights(self.q_value_network.get_weights())\n","    \n","    def decrement_epsilon(self): \n","        self.eps -= self.eps_decay_rate\n","        self.eps = max(self.eps, self.min_eps)\n","\n","    def learn(self):\n","        if not self.memory.is_sufficient():\n","            return\n","\n","        states, actions, rewards, states_, dones = self.sample_experience()\n","        \n","        indices = tf.range(self.batch_size, dtype=tf.int32)\n","      \n","        action_indices = tf.stack([indices, actions], axis=1)\n","\n","        with tf.GradientTape() as tape:\n","            q_pred = tf.gather_nd(self.q_value_network(states), indices=action_indices)\n","            q_eval = self.target_q_network(states_)\n","\n","            max_actions = tf.math.argmax(q_eval, axis=1, output_type=tf.int32)\n","            max_action_idx = tf.stack([indices, max_actions], axis=1)\n","\n","            q_target = rewards + \\\n","                self.gamma*tf.gather_nd(q_eval, indices=max_action_idx) *\\\n","                (1 - dones.numpy())\n","\n","            loss = keras.losses.MSE(q_pred, q_target)\n","\n","        params = self.q_value_network.trainable_variables\n","        grads = tape.gradient(loss, params)\n","\n","        self.q_value_network.optimizer.apply_gradients(zip(grads, params))\n","\n","        self.learn_step_counter += 1\n","        \n","        self.decrement_epsilon()\n","        \n","        self.replace_target_network()\n","        \n","        return self.eps"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:02:21.609263Z","iopub.status.busy":"2023-03-14T08:02:21.606365Z","iopub.status.idle":"2023-03-14T08:02:24.289467Z","shell.execute_reply":"2023-03-14T08:02:24.288432Z","shell.execute_reply.started":"2023-03-14T08:02:21.609223Z"},"trusted":true},"outputs":[],"source":["import collections\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gymnasium as gym\n","import tensorflow as tf\n","from gymnasium.wrappers import *\n","\n","\n","def manage_memory():\n","    gpus = tf.config.list_physical_devices('GPU')\n","    if gpus:\n","        try:\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, True)\n","        except RuntimeError as e:\n","            print(e)\n","\n","\n","def plot_learning_curve(scores, epsilons, filename, lines=None):\n","    x = [_ for _ in range(len(scores))]\n","    fig=plt.figure()\n","    ax=fig.add_subplot(111, label=\"1\")\n","    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n","\n","    ax.plot(x, epsilons, color=\"C0\")\n","    ax.set_xlabel(\"Training Steps\", color=\"C0\")\n","    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n","    ax.tick_params(axis='x', colors=\"C0\")\n","    ax.tick_params(axis='y', colors=\"C0\")\n","\n","    N = len(scores)\n","    running_avg = np.empty(N)\n","    for t in range(N):\n","\t    running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n","\n","    ax2.scatter(x, running_avg, color=\"C1\")\n","    ax2.axes.get_xaxis().set_visible(False)\n","    ax2.yaxis.tick_right()\n","    ax2.set_ylabel('Score', color=\"C1\")\n","    ax2.yaxis.set_label_position('right')\n","    ax2.tick_params(axis='y', colors=\"C1\")\n","\n","    if lines is not None:\n","        for line in lines:\n","            plt.axvline(x=line)\n","\n","    plt.savefig(filename)\n","\n","\n","def make_env(env_name, video_file_name, episode_freq_fo_video): \n","    env = gym.make(env_name, render_mode=\"rgb_array\")\n","    \n","    if len(env.observation_space.shape) >= 3: \n","        #env = AtariPreprocessing(env, 10, 4, 84, False, True)\n","        env = ResizeObservation(env, 84)\n","        env = GrayScaleObservation(env, keep_dim=False)\n","        env = FrameStack(env, 4, lz4_compress=False)\n","        env = NormalizeObservation(env)\n","\n","    return env"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:02:24.291257Z","iopub.status.busy":"2023-03-14T08:02:24.290863Z","iopub.status.idle":"2023-03-14T08:02:24.298126Z","shell.execute_reply":"2023-03-14T08:02:24.296868Z","shell.execute_reply.started":"2023-03-14T08:02:24.291219Z"},"trusted":true},"outputs":[],"source":["class Writer:\n","    def __init__(self, fname): \n","        self.fname = fname \n","\n","    def write_to_file(self, content): \n","        with open(self.fname, \"a\") as file: \n","            file.write(content + \"\\n\")\n","\n","    def read_file(self, fname):\n","        with open(fname, \"r\") as file: \n","            return file.read()\n","            "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:02:24.300447Z","iopub.status.busy":"2023-03-14T08:02:24.299748Z","iopub.status.idle":"2023-03-14T08:02:24.329409Z","shell.execute_reply":"2023-03-14T08:02:24.328487Z","shell.execute_reply.started":"2023-03-14T08:02:24.300403Z"},"trusted":true},"outputs":[],"source":["import time\n","from telebot import TeleBot\n","import datetime\n","import telebot\n","\n","token = \"6238487424:AAG0jRhvbiVa90qUcf2fAirQr_-quPMs7cU\"\n","chat_id = \"1055055706\"\n","bot = TeleBot(token=token) \n","\n","def telegram_send(message, bot):\n","    chat_id = \"1055055706\"\n","    bot.send_message(chat_id=chat_id, text=message)\n","\n","def welcome_msg(multi_step, double_dqn, dueling):\n","    st = 'Hi! Starting learning with DQN Multi-step = %d, Double DQN = %r, Dueling DQN = %r' % (multi_step, double_dqn, dueling)\n","    telegram_send(st, bot)\n","    \n","def info_msg(episode, max_episode, reward, best_score, loss): \n","    st = f\"Current Episode: {episode}, Current Reward: {reward}, Max Episode: {max_episode}, Best Score: {best_score}, loss: {loss}\"\n","    telegram_send(st, bot)\n","\n","def end_msg(learning_time):\n","    st = 'Finished! Learning time: ' + str(datetime.timedelta(seconds=int(learning_time)))\n","    telegram_send(st, bot)\n","    print(st)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:03:26.180662Z","iopub.status.busy":"2023-03-14T08:03:26.180281Z","iopub.status.idle":"2023-03-14T08:03:26.188873Z","shell.execute_reply":"2023-03-14T08:03:26.187809Z","shell.execute_reply.started":"2023-03-14T08:03:26.180629Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import imageio\n","\n","\n","class RecordVideo: \n","    \n","    def __init__(self, prefix_fname,  out_directory=\"videos/\", fps=10): \n","        self.prefix_fname = prefix_fname\n","        self.out_directory = out_directory\n","        self.fps = fps\n","        self.images = []\n","        \n","    def add_image(self, image): \n","        self.images.append(image)\n","    \n","    def save(self, episode_no): \n","        name = self.out_directory + self.prefix_fname + \"_\" + str(episode_no) + \".mp4\"\n","        imageio.mimsave(name, [np.array(img) for i, img in enumerate(self.images)], fps=self.fps)\n","        self.images = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:03:00.371835Z","iopub.status.busy":"2023-03-14T08:03:00.371085Z","iopub.status.idle":"2023-03-14T08:03:00.386313Z","shell.execute_reply":"2023-03-14T08:03:00.385227Z","shell.execute_reply.started":"2023-03-14T08:03:00.371795Z"},"trusted":true},"outputs":[],"source":["import collections\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gymnasium as gym\n","import tensorflow as tf\n","from gymnasium.wrappers import *\n","\n","\n","def manage_memory():\n","    gpus = tf.config.list_physical_devices('GPU')\n","    if gpus:\n","        try:\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, True)\n","        except RuntimeError as e:\n","            print(e)\n","\n","\n","def plot_learning_curve(scores, epsilons, filename, lines=None):\n","    x = [_ for _ in range(len(scores))]\n","    fig=plt.figure()\n","    ax=fig.add_subplot(111, label=\"1\")\n","    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n","\n","    ax.plot(x, epsilons, color=\"C0\")\n","    ax.set_xlabel(\"Training Steps\", color=\"C0\")\n","    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n","    ax.tick_params(axis='x', colors=\"C0\")\n","    ax.tick_params(axis='y', colors=\"C0\")\n","\n","    N = len(scores)\n","    running_avg = np.empty(N)\n","    for t in range(N):\n","\t    running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n","\n","    ax2.scatter(x, running_avg, color=\"C1\")\n","    ax2.axes.get_xaxis().set_visible(False)\n","    ax2.yaxis.tick_right()\n","    ax2.set_ylabel('Score', color=\"C1\")\n","    ax2.yaxis.set_label_position('right')\n","    ax2.tick_params(axis='y', colors=\"C1\")\n","\n","    if lines is not None:\n","        for line in lines:\n","            plt.axvline(x=line)\n","\n","    plt.savefig(filename)\n","\n","\n","def make_env(env_name, video_file_name, episode_freq_fo_video): \n","    env = gym.make(env_name, render_mode=\"rgb_array\")\n","    \n","    if len(env.observation_space.shape) >= 3: \n","        #env = AtariPreprocessing(env, 10, 4, 84, False, True)\n","        env = ResizeObservation(env, 84)\n","        env = GrayScaleObservation(env, keep_dim=False)\n","        env = FrameStack(env, 4, lz4_compress=False)\n","        env = NormalizeObservation(env)\n","\n","    return env"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:11:11.097557Z","iopub.status.busy":"2023-03-14T08:11:11.096736Z","iopub.status.idle":"2023-03-14T08:11:11.116466Z","shell.execute_reply":"2023-03-14T08:11:11.115423Z","shell.execute_reply.started":"2023-03-14T08:11:11.097518Z"},"trusted":true},"outputs":[],"source":["from npy_append_array import NpyAppendArray\n","import numpy as np\n","\n","class Trainer:   \n","    def __init__(self, env, trainer_params): \n","       \n","        self.env = env \n","        self.noe = trainer_params.get(\"noe\")\n","        self.max_steps = trainer_params.get(\"max_steps\")\n","       \n","        self.eps_decay_rate = trainer_params.get(\"eps_decay_rate\")\n","        self.action_space = trainer_params.get(\"action_space\")\n","        self.is_tg = trainer_params.get(\"is_tg\")\n","        self.tg_bot_freq_epi = trainer_params.get(\"tg_bot_freq_epi\")\n","        self.record = trainer_params.get(\"record\")\n","        self.agent_params = {\n","                        \"gamma\":  trainer_params.get(\"gamma\"), \n","                        \"lr\":  trainer_params.get(\"lr\"), \n","                        \"input_dims\":  trainer_params.get(\"input_dims\"),\n","                        \"mem_size\" :  trainer_params.get(\"mem_size\"),\n","                        \"batch_size\" :  trainer_params.get(\"batch_size\"),\n","                        \"replace\" :  trainer_params.get(\"replace\"),\n","                        \"algo\" :  trainer_params.get(\"algo\"),\n","                        \"env_name\" :  trainer_params.get(\"env_name\"),\n","                        \"n_actions\" :  trainer_params.get(\"n_actions\"),\n","                        \"chkpt_dir\":  trainer_params.get(\"chkpt_dir\"),\n","                        \"actions\":  trainer_params.get(\"actions\"),\n","                        \"eps\": trainer_params.get(\"eps\"),\n","                        \"min_eps\": trainer_params.get(\"min_eps\"),\n","                        \"eps_decay_rate\": trainer_params.get(\"eps_decay_rate\"),\n","                        \"cer\": trainer_params.get(\"cer\")\n","                    }\n","        \n","        self.agent = Agent(self.agent_params)\n","        \n","        self.writer = Writer(\"model_training_results.txt\")\n","        self.recorder = RecordVideo(\"dqn\", \"videos/\", 20)\n","        print(self.recorder)\n","        \n","        self.target_score = trainer_params.get(\"target_score\")\n","\n","    def train_rl_model(self): \n","        episode_rewards = []\n","        epsilon_history = []\n","        avg_rewards = []\n","        best_reward = float(\"-inf\")\n","\n","        for episode in range(self.noe): \n","            n_steps = 0 \n","            episodic_loss = 0\n","            state = self.env.reset()\n","            reward = 0 \n","            \n","            if self.record and episode%100==0: \n","                img = self.env.render()\n","                self.recorder.add_image(img)\n","\n","            for step in range(self.max_steps): \n","                \n","                if self.record and episode%100==0: \n","                    img = self.env.render()\n","                    self.recorder.add_image(img)\n","\n","                if type(state) == tuple: \n","                    state = state[0]\n","                state = state\n","\n","                action = self.agent.choose_action(state)\n","\n","                next_info = self.env.step(action)\n","                next_state, reward_prob, terminated, truncated, _ = next_info\n","                done = truncated or terminated\n","                reward += reward_prob\n","\n","                self.agent.store_experience(state, action, reward_prob, next_state, done)\n","                eps = self.agent.learn()\n","\n","                state = next_state\n","                n_steps += 1 \n","               \n","                \n","                if done: \n","                    break\n","\n","            epsilon_history.append(eps)\n","            episode_rewards.append(reward)\n","            avg_reward = np.mean(episode_rewards[-100:])\n","            avg_rewards.append(avg_reward)\n","\n","            result = f\"Episode: {episode}, Epsilon: {eps}, Steps: {n_steps}, Reward: {reward}, Best reward: {best_reward}, Avg reward: {avg_reward}\"\n","            self.writer.write_to_file(result)\n","            print(result)\n","            \n","            # Saving Best Model\n","            if reward > best_reward: \n","                best_reward = reward\n","                self.agent.save_models()\n","            \n","            # video Recorder\n","            if episode % 100 ==0:\n","                self.recorder.save(episode)\n","                \n","          # Telegram bot\n","            if self.is_tg and episode % self.tg_bot_freq_epi == 0: \n","                info_msg(episode+1, self.noe, reward, best_reward, \"d\")\n","                \n","         # Eatly Stopping\n","            if episode > 100 and np.mean(episode_rewards[-100:]) >= self.target_score: \n","                break\n","                \n","                \n","        return episode_rewards, epsilon_history, avg_rewards, best_reward"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gymnasium as gym\n","import time\n","\n","env = make_env(\"ALE/Pong-v5\", \"videos/\", 50)\n","action_space = [_ for _ in range(env.action_space.n)]\n","\n","episodic_rewards_filename = 'array_files/episodic_reward.npy'\n","epsilon_history_filename = 'array_files/epsilon_history.npy'\n","cum_avg_reward_filename = 'array_files/cum_avg_rewards.npy'\n","losses_filename = 'array_files/losses.npy'\n","\n","agent_params = {\n","    \"gamma\": 0.997, \n","    \"lr\": 0.0001, \n","    \"input_dims\": env.observation_space.shape,\n","    \"mem_size\" : 15000,\n","    \"batch_size\" : 32,\n","    \"replace\" : 1000,\n","    \"algo\" : \"DQN\",\n","    \"env_name\" : \"pong-v5\",\n","    \"n_actions\" : len(action_space),\n","    \"chkpt_dir\": \"tmp/dqn/\",\n","    \"actions\": action_space\n","}\n","\n","trainer_params = {\n","    \"noe\": 50, \n","    \"max_steps\": 10000,\n","    \"max_eps\": 1,\n","    \"min_eps\": 0.02,\n","    \"eps_decay_rate\": 1e-4,\n","    \"eps\": 1,\n","    \"action_space\": action_space,\n","    \"is_tg\": True,\n","    \"tg_bot_freq_epi\": 10\n","}\n","\n","if __name__ == \"__main__\": \n","    try: \n","        manage_memory()\n","        agent = Agent(agent_params)\n","        trainer = Trainer(agent, env, trainer_params)\n","\n","        episode_rewards, epsilon_history, avg_rewards, best_reward = trainer.train_rl_model()\n","        plot_learning_curve(episode_rewards, epsilon_history, \"plot_file\")\n","\n","       # eval_model(env, \"keras model\", \"videos/\", fps=10)\n","    \n","    except Exception as error:\n","        raise error\n"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T08:22:58.441459Z","iopub.status.busy":"2023-03-14T08:22:58.440936Z","iopub.status.idle":"2023-03-14T10:28:55.792257Z","shell.execute_reply":"2023-03-14T10:28:55.790854Z","shell.execute_reply.started":"2023-03-14T08:22:58.441413Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<__main__.RecordVideo object at 0x7f81d86d2110>\n","Episode: 0, Epsilon: 0.1, Steps: 101, Reward: -298.57479471474994, Best reward: -inf, Avg reward: -298.57479471474994\n","... models saved successfully ...\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x6d6f200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 1, Epsilon: 0.1, Steps: 71, Reward: -182.66471380789858, Best reward: -298.57479471474994, Avg reward: -240.61975426132426\n","... models saved successfully ...\n","Episode: 2, Epsilon: 0.1, Steps: 67, Reward: -96.86358100293687, Best reward: -182.66471380789858, Avg reward: -192.70102984186178\n","... models saved successfully ...\n","Episode: 3, Epsilon: 0.1, Steps: 60, Reward: -362.1572104070789, Best reward: -96.86358100293687, Avg reward: -235.06507498316606\n","Episode: 4, Epsilon: 0.1, Steps: 78, Reward: -375.63638086746596, Best reward: -96.86358100293687, Avg reward: -263.179336160026\n","Episode: 5, Epsilon: 0.1, Steps: 63, Reward: -111.07589669033865, Best reward: -96.86358100293687, Avg reward: -237.8287629150781\n","Episode: 6, Epsilon: 0.1, Steps: 52, Reward: -133.7130316451271, Best reward: -96.86358100293687, Avg reward: -222.95508701937084\n","Episode: 7, Epsilon: 0.1, Steps: 52, Reward: -113.07209068863651, Best reward: -96.86358100293687, Avg reward: -209.21971247802907\n","Episode: 8, Epsilon: 0.1, Steps: 88, Reward: -205.13056452855824, Best reward: -96.86358100293687, Avg reward: -208.76536270586564\n","Episode: 9, Epsilon: 0.1, Steps: 114, Reward: -151.08381024972465, Best reward: -96.86358100293687, Avg reward: -202.99720746025156\n","Episode: 10, Epsilon: 0.1, Steps: 68, Reward: -154.54068024116077, Best reward: -96.86358100293687, Avg reward: -198.5920686221524\n","Episode: 11, Epsilon: 0.1, Steps: 69, Reward: -106.20004045543115, Best reward: -96.86358100293687, Avg reward: -190.89273294159227\n","Episode: 12, Epsilon: 0.1, Steps: 83, Reward: -149.7293876875341, Best reward: -96.86358100293687, Avg reward: -187.72632176820318\n","Episode: 13, Epsilon: 0.1, Steps: 252, Reward: -248.9550169937426, Best reward: -96.86358100293687, Avg reward: -192.09979999859885\n","Episode: 14, Epsilon: 0.1, Steps: 96, Reward: -291.1008316323236, Best reward: -96.86358100293687, Avg reward: -198.69986877418052\n","Episode: 15, Epsilon: 0.1, Steps: 153, Reward: -72.37125764678551, Best reward: -96.86358100293687, Avg reward: -190.8043305787183\n","... models saved successfully ...\n","Episode: 16, Epsilon: 0.1, Steps: 507, Reward: -378.8283584015828, Best reward: -72.37125764678551, Avg reward: -201.86456750947502\n","Episode: 17, Epsilon: 0.1, Steps: 128, Reward: -191.49412602651063, Best reward: -72.37125764678551, Avg reward: -201.28843187153254\n","Episode: 18, Epsilon: 0.1, Steps: 196, Reward: -327.50548116549123, Best reward: -72.37125764678551, Avg reward: -207.9314344659514\n","Episode: 19, Epsilon: 0.1, Steps: 279, Reward: -650.742733910291, Best reward: -72.37125764678551, Avg reward: -230.0719994381684\n","Episode: 20, Epsilon: 0.1, Steps: 200, Reward: -361.30377672447867, Best reward: -72.37125764678551, Avg reward: -236.32113168989747\n","Episode: 21, Epsilon: 0.1, Steps: 128, Reward: -288.43261058514815, Best reward: -72.37125764678551, Avg reward: -238.68983527604522\n","Episode: 22, Epsilon: 0.1, Steps: 68, Reward: -201.5785625591541, Best reward: -72.37125764678551, Avg reward: -237.07630167965866\n","Episode: 23, Epsilon: 0.1, Steps: 183, Reward: -355.7171114415538, Best reward: -72.37125764678551, Avg reward: -242.019668753071\n","Episode: 24, Epsilon: 0.1, Steps: 79, Reward: -115.69896108402058, Best reward: -72.37125764678551, Avg reward: -236.966840446309\n","Episode: 25, Epsilon: 0.1, Steps: 123, Reward: -281.59219421647674, Best reward: -72.37125764678551, Avg reward: -238.68320020670006\n","Episode: 26, Epsilon: 0.1, Steps: 95, Reward: -60.36041340225806, Best reward: -72.37125764678551, Avg reward: -232.07865254727628\n","... models saved successfully ...\n","Episode: 27, Epsilon: 0.1, Steps: 231, Reward: -174.36525235368458, Best reward: -60.36041340225806, Avg reward: -230.01745968321944\n","Episode: 28, Epsilon: 0.1, Steps: 117, Reward: -358.7707575644173, Best reward: -60.36041340225806, Avg reward: -234.45722857567455\n","Episode: 29, Epsilon: 0.1, Steps: 156, Reward: -445.5849731876301, Best reward: -60.36041340225806, Avg reward: -241.49482006273973\n","Episode: 30, Epsilon: 0.1, Steps: 98, Reward: -226.6765492018784, Best reward: -60.36041340225806, Avg reward: -241.01681132529262\n","Episode: 31, Epsilon: 0.1, Steps: 211, Reward: -87.49406716348987, Best reward: -60.36041340225806, Avg reward: -236.2192255702362\n","Episode: 32, Epsilon: 0.1, Steps: 118, Reward: -315.23808787798373, Best reward: -60.36041340225806, Avg reward: -238.61373654925887\n","Episode: 33, Epsilon: 0.1, Steps: 255, Reward: -400.58416898230047, Best reward: -60.36041340225806, Avg reward: -243.3775727972895\n","Episode: 34, Epsilon: 0.1, Steps: 236, Reward: -432.31614309856576, Best reward: -60.36041340225806, Avg reward: -248.77581766304024\n","Episode: 35, Epsilon: 0.1, Steps: 189, Reward: -358.67985769591576, Best reward: -60.36041340225806, Avg reward: -251.82870766395342\n","Episode: 36, Epsilon: 0.1, Steps: 248, Reward: -235.53288750499468, Best reward: -60.36041340225806, Avg reward: -251.38828009208967\n","Episode: 37, Epsilon: 0.1, Steps: 183, Reward: -78.02485838152703, Best reward: -60.36041340225806, Avg reward: -246.82608478391697\n","Episode: 38, Epsilon: 0.1, Steps: 125, Reward: -220.28689378900668, Best reward: -60.36041340225806, Avg reward: -246.1455927071244\n","Episode: 39, Epsilon: 0.1, Steps: 107, Reward: -41.157228585705056, Best reward: -60.36041340225806, Avg reward: -241.02088360408897\n","... models saved successfully ...\n","Episode: 40, Epsilon: 0.1, Steps: 153, Reward: -191.55632161019417, Best reward: -41.157228585705056, Avg reward: -239.81443087253058\n","Episode: 41, Epsilon: 0.1, Steps: 131, Reward: -122.60455773374318, Best reward: -41.157228585705056, Avg reward: -237.02371960732134\n","Episode: 42, Epsilon: 0.1, Steps: 143, Reward: -368.13568353652187, Best reward: -41.157228585705056, Avg reward: -240.0728350475353\n","Episode: 43, Epsilon: 0.1, Steps: 318, Reward: -430.84003673408387, Best reward: -41.157228585705056, Avg reward: -244.40845326768414\n","Episode: 44, Epsilon: 0.1, Steps: 145, Reward: -343.42616094728396, Best reward: -41.157228585705056, Avg reward: -246.60884677167525\n","Episode: 45, Epsilon: 0.1, Steps: 189, Reward: -246.22337430593797, Best reward: -41.157228585705056, Avg reward: -246.60046693546357\n","Episode: 46, Epsilon: 0.1, Steps: 118, Reward: -180.3252744857379, Best reward: -41.157228585705056, Avg reward: -245.19035645780983\n","Episode: 47, Epsilon: 0.1, Steps: 166, Reward: -204.9727915086268, Best reward: -41.157228585705056, Avg reward: -244.3524905213685\n","Episode: 48, Epsilon: 0.1, Steps: 180, Reward: -264.00660350073974, Best reward: -41.157228585705056, Avg reward: -244.7535948678863\n","Episode: 49, Epsilon: 0.1, Steps: 290, Reward: -436.0770890216344, Best reward: -41.157228585705056, Avg reward: -248.58006475096124\n","Episode: 50, Epsilon: 0.1, Steps: 194, Reward: -228.65687027434916, Best reward: -41.157228585705056, Avg reward: -248.18941387887082\n","Episode: 51, Epsilon: 0.1, Steps: 94, Reward: -109.07570116629533, Best reward: -41.157228585705056, Avg reward: -245.51415017285976\n","Episode: 52, Epsilon: 0.1, Steps: 183, Reward: -258.48585113099125, Best reward: -41.157228585705056, Avg reward: -245.7588992475415\n","Episode: 53, Epsilon: 0.1, Steps: 195, Reward: -226.31619562448444, Best reward: -41.157228585705056, Avg reward: -245.39884918044785\n","Episode: 54, Epsilon: 0.1, Steps: 316, Reward: -374.30382954217527, Best reward: -41.157228585705056, Avg reward: -247.7425760961156\n","Episode: 55, Epsilon: 0.1, Steps: 114, Reward: -408.9352058645895, Best reward: -41.157228585705056, Avg reward: -250.62101591340976\n","Episode: 56, Epsilon: 0.1, Steps: 105, Reward: -272.7474787816632, Best reward: -41.157228585705056, Avg reward: -251.0091994725019\n","Episode: 57, Epsilon: 0.1, Steps: 141, Reward: -243.97384064316955, Best reward: -41.157228585705056, Avg reward: -250.887900182341\n","Episode: 58, Epsilon: 0.1, Steps: 297, Reward: -286.4106533119438, Best reward: -41.157228585705056, Avg reward: -251.4899807438597\n","Episode: 59, Epsilon: 0.1, Steps: 103, Reward: -238.9883896698166, Best reward: -41.157228585705056, Avg reward: -251.28162089262565\n","Episode: 60, Epsilon: 0.1, Steps: 148, Reward: -248.0512304905726, Best reward: -41.157228585705056, Avg reward: -251.22866367291988\n","Episode: 61, Epsilon: 0.1, Steps: 111, Reward: -192.85625426092815, Best reward: -41.157228585705056, Avg reward: -250.28717319853294\n","Episode: 62, Epsilon: 0.1, Steps: 107, Reward: -375.4865076545805, Best reward: -41.157228585705056, Avg reward: -252.2744642216448\n","Episode: 63, Epsilon: 0.1, Steps: 179, Reward: -230.85367269716815, Best reward: -41.157228585705056, Avg reward: -251.93976435407484\n","Episode: 64, Epsilon: 0.1, Steps: 96, Reward: -181.3837571372984, Best reward: -41.157228585705056, Avg reward: -250.85428731997058\n","Episode: 65, Epsilon: 0.1, Steps: 167, Reward: -233.33700048382528, Best reward: -41.157228585705056, Avg reward: -250.58887388305934\n","Episode: 66, Epsilon: 0.1, Steps: 178, Reward: -301.0084770741971, Best reward: -41.157228585705056, Avg reward: -251.34140527397182\n","Episode: 67, Epsilon: 0.1, Steps: 131, Reward: -185.91229143434916, Best reward: -41.157228585705056, Avg reward: -250.37921242338913\n","Episode: 68, Epsilon: 0.1, Steps: 160, Reward: -83.63374605900017, Best reward: -41.157228585705056, Avg reward: -247.9626114615864\n","Episode: 69, Epsilon: 0.1, Steps: 164, Reward: -91.4064985767265, Best reward: -41.157228585705056, Avg reward: -245.72609556323124\n","Episode: 70, Epsilon: 0.1, Steps: 154, Reward: -310.23628548399785, Best reward: -41.157228585705056, Avg reward: -246.6346897874674\n","Episode: 71, Epsilon: 0.1, Steps: 89, Reward: -188.7835475186382, Best reward: -41.157228585705056, Avg reward: -245.83120170040033\n","Episode: 72, Epsilon: 0.1, Steps: 357, Reward: -248.84249335507562, Best reward: -41.157228585705056, Avg reward: -245.8724522710123\n","Episode: 73, Epsilon: 0.1, Steps: 112, Reward: -195.75286020931262, Best reward: -41.157228585705056, Avg reward: -245.1951604863947\n","Episode: 74, Epsilon: 0.1, Steps: 478, Reward: -110.55965416700622, Best reward: -41.157228585705056, Avg reward: -243.4000204021362\n","Episode: 75, Epsilon: 0.1, Steps: 160, Reward: -217.7796485003331, Best reward: -41.157228585705056, Avg reward: -243.06291024553354\n","Episode: 76, Epsilon: 0.1, Steps: 1000, Reward: -25.36566405598707, Best reward: -41.157228585705056, Avg reward: -240.2356732820329\n","... models saved successfully ...\n","Episode: 77, Epsilon: 0.1, Steps: 124, Reward: -374.6338958244064, Best reward: -25.36566405598707, Avg reward: -241.95872741719154\n","Episode: 78, Epsilon: 0.1, Steps: 1000, Reward: 8.943136609946524, Best reward: -25.36566405598707, Avg reward: -238.7827544548227\n","... models saved successfully ...\n","Episode: 79, Epsilon: 0.1, Steps: 1000, Reward: -71.56896000650639, Best reward: 8.943136609946524, Avg reward: -236.69258202421878\n","Episode: 80, Epsilon: 0.1, Steps: 1000, Reward: -44.10588774834542, Best reward: 8.943136609946524, Avg reward: -234.3149685146401\n","Episode: 81, Epsilon: 0.1, Steps: 1000, Reward: -61.39493574238864, Best reward: 8.943136609946524, Avg reward: -232.20618762717362\n","Episode: 82, Epsilon: 0.1, Steps: 1000, Reward: -65.27379444597896, Best reward: 8.943136609946524, Avg reward: -230.19495397438814\n","Episode: 83, Epsilon: 0.1, Steps: 1000, Reward: -73.00898092655636, Best reward: 8.943136609946524, Avg reward: -228.32369239048538\n","Episode: 84, Epsilon: 0.1, Steps: 104, Reward: -135.37890583670045, Best reward: 8.943136609946524, Avg reward: -227.23022431338202\n","Episode: 85, Epsilon: 0.1, Steps: 1000, Reward: -97.36510949203355, Best reward: 8.943136609946524, Avg reward: -225.7201648387152\n","Episode: 86, Epsilon: 0.1, Steps: 244, Reward: -161.07422604692508, Best reward: 8.943136609946524, Avg reward: -224.97710807099347\n","Episode: 87, Epsilon: 0.1, Steps: 148, Reward: -50.0296186836451, Best reward: 8.943136609946524, Avg reward: -222.9890684188645\n","Episode: 88, Epsilon: 0.1, Steps: 1000, Reward: -11.188494987185397, Best reward: 8.943136609946524, Avg reward: -220.60928669491307\n","Episode: 89, Epsilon: 0.1, Steps: 1000, Reward: -78.4494384656208, Best reward: 8.943136609946524, Avg reward: -219.0297328256987\n","Episode: 90, Epsilon: 0.1, Steps: 270, Reward: -82.97983029138562, Best reward: 8.943136609946524, Avg reward: -217.53467895169524\n","Episode: 91, Epsilon: 0.1, Steps: 1000, Reward: -4.231278336590761, Best reward: 8.943136609946524, Avg reward: -215.21616372761804\n","Episode: 92, Epsilon: 0.1, Steps: 1000, Reward: 20.498604490856817, Best reward: 8.943136609946524, Avg reward: -212.68159632741936\n","... models saved successfully ...\n","Episode: 93, Epsilon: 0.1, Steps: 1000, Reward: 18.117901188775107, Best reward: 20.498604490856817, Avg reward: -210.2262825240556\n","Episode: 94, Epsilon: 0.1, Steps: 1000, Reward: -9.699594225176304, Best reward: 20.498604490856817, Avg reward: -208.11547527880424\n","Episode: 95, Epsilon: 0.1, Steps: 1000, Reward: -9.293148357543293, Best reward: 20.498604490856817, Avg reward: -206.04440937337446\n","Episode: 96, Epsilon: 0.1, Steps: 938, Reward: -178.82293379960586, Best reward: 20.498604490856817, Avg reward: -205.76377560457271\n","Episode: 97, Epsilon: 0.1, Steps: 218, Reward: 4.958522196346891, Best reward: 20.498604490856817, Avg reward: -203.6135480759919\n","Episode: 98, Epsilon: 0.1, Steps: 1000, Reward: -68.31318760219499, Best reward: 20.498604490856817, Avg reward: -202.24687776817578\n","Episode: 99, Epsilon: 0.1, Steps: 990, Reward: -211.9790822138766, Best reward: 20.498604490856817, Avg reward: -202.3441998126328\n","Episode: 100, Epsilon: 0.1, Steps: 1000, Reward: 38.000227155265804, Best reward: 20.498604490856817, Avg reward: -198.9784495939326\n","... models saved successfully ...\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x5c10200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 101, Epsilon: 0.1, Steps: 242, Reward: -20.924699213426237, Best reward: 38.000227155265804, Avg reward: -197.36104944798785\n","Episode: 102, Epsilon: 0.1, Steps: 567, Reward: -309.21688126558496, Best reward: 38.000227155265804, Avg reward: -199.4845824506143\n","Episode: 103, Epsilon: 0.1, Steps: 150, Reward: -115.88664674378781, Best reward: 38.000227155265804, Avg reward: -197.02187681398146\n","Episode: 104, Epsilon: 0.1, Steps: 175, Reward: -514.2103127187836, Best reward: 38.000227155265804, Avg reward: -198.40761613249458\n","Episode: 105, Epsilon: 0.1, Steps: 253, Reward: -476.58587045201267, Best reward: 38.000227155265804, Avg reward: -202.0627158701114\n","Episode: 106, Epsilon: 0.1, Steps: 102, Reward: -276.1100582467891, Best reward: 38.000227155265804, Avg reward: -203.48668613612801\n","Episode: 107, Epsilon: 0.1, Steps: 112, Reward: -273.0033018800617, Best reward: 38.000227155265804, Avg reward: -205.08599824804227\n","Episode: 108, Epsilon: 0.1, Steps: 208, Reward: -355.05968368988874, Best reward: 38.000227155265804, Avg reward: -206.58528943965553\n","Episode: 109, Epsilon: 0.1, Steps: 495, Reward: -318.05211938462674, Best reward: 38.000227155265804, Avg reward: -208.25497253100457\n","Episode: 110, Epsilon: 0.1, Steps: 201, Reward: -337.8399053882372, Best reward: 38.000227155265804, Avg reward: -210.08796478247532\n","Episode: 111, Epsilon: 0.1, Steps: 203, Reward: -210.04810514590358, Best reward: 38.000227155265804, Avg reward: -211.12644542938008\n","Episode: 112, Epsilon: 0.1, Steps: 223, Reward: -260.5682185123388, Best reward: 38.000227155265804, Avg reward: -212.23483373762815\n","Episode: 113, Epsilon: 0.1, Steps: 154, Reward: -87.05763667394433, Best reward: 38.000227155265804, Avg reward: -210.61585993443015\n","Episode: 114, Epsilon: 0.1, Steps: 205, Reward: -171.06967163291682, Best reward: 38.000227155265804, Avg reward: -209.4155483344361\n","Episode: 115, Epsilon: 0.1, Steps: 508, Reward: -353.2104079550851, Best reward: 38.000227155265804, Avg reward: -212.22393983751905\n","Episode: 116, Epsilon: 0.1, Steps: 141, Reward: -214.4207103664999, Best reward: 38.000227155265804, Avg reward: -210.57986335716825\n","Episode: 117, Epsilon: 0.1, Steps: 186, Reward: -430.3265681312182, Best reward: 38.000227155265804, Avg reward: -212.96818777821534\n","Episode: 118, Epsilon: 0.1, Steps: 195, Reward: -276.4636018294744, Best reward: 38.000227155265804, Avg reward: -212.45776898485514\n","Episode: 119, Epsilon: 0.1, Steps: 287, Reward: -63.794939392192845, Best reward: 38.000227155265804, Avg reward: -206.58829103967412\n","Episode: 120, Epsilon: 0.1, Steps: 148, Reward: -49.44944761446693, Best reward: 38.000227155265804, Avg reward: -203.469747748574\n","Episode: 121, Epsilon: 0.1, Steps: 146, Reward: -68.4587405159405, Best reward: 38.000227155265804, Avg reward: -201.27000904788193\n","Episode: 122, Epsilon: 0.1, Steps: 214, Reward: -185.96518049765461, Best reward: 38.000227155265804, Avg reward: -201.11387522726693\n","Episode: 123, Epsilon: 0.1, Steps: 272, Reward: -231.80746975111967, Best reward: 38.000227155265804, Avg reward: -199.87477881036259\n","Episode: 124, Epsilon: 0.1, Steps: 886, Reward: -312.9759859351409, Best reward: 38.000227155265804, Avg reward: -201.84754905887377\n","Episode: 125, Epsilon: 0.1, Steps: 1000, Reward: -72.4486138846265, Best reward: 38.000227155265804, Avg reward: -199.75611325555528\n","Episode: 126, Epsilon: 0.1, Steps: 1000, Reward: 7.186056074862823, Best reward: 38.000227155265804, Avg reward: -199.08064856078406\n","Episode: 127, Epsilon: 0.1, Steps: 1000, Reward: -19.914636176449932, Best reward: 38.000227155265804, Avg reward: -197.53614239901174\n","Episode: 128, Epsilon: 0.1, Steps: 1000, Reward: -119.20308114588143, Best reward: 38.000227155265804, Avg reward: -195.14046563482643\n","Episode: 129, Epsilon: 0.1, Steps: 1000, Reward: -118.90185421309089, Best reward: 38.000227155265804, Avg reward: -191.87363444508105\n","Episode: 130, Epsilon: 0.1, Steps: 1000, Reward: -11.752967168774877, Best reward: 38.000227155265804, Avg reward: -189.72439862475\n","Episode: 131, Epsilon: 0.1, Steps: 1000, Reward: -107.00229073052132, Best reward: 38.000227155265804, Avg reward: -189.9194808604203\n","Episode: 132, Epsilon: 0.1, Steps: 1000, Reward: 26.55497944843768, Best reward: 38.000227155265804, Avg reward: -186.5015501871561\n","Episode: 133, Epsilon: 0.1, Steps: 1000, Reward: -113.67598182742887, Best reward: 38.000227155265804, Avg reward: -183.6324683156074\n","Episode: 134, Epsilon: 0.1, Steps: 1000, Reward: -104.28491485385582, Best reward: 38.000227155265804, Avg reward: -180.35215603316027\n","Episode: 135, Epsilon: 0.1, Steps: 1000, Reward: -98.2209171891325, Best reward: 38.000227155265804, Avg reward: -177.74756662809247\n","Episode: 136, Epsilon: 0.1, Steps: 1000, Reward: -90.48440555506862, Best reward: 38.000227155265804, Avg reward: -176.29708180859316\n","Episode: 137, Epsilon: 0.1, Steps: 1000, Reward: -34.637487085853216, Best reward: 38.000227155265804, Avg reward: -175.86320809563642\n","Episode: 138, Epsilon: 0.1, Steps: 1000, Reward: -25.004177329753855, Best reward: 38.000227155265804, Avg reward: -173.9103809310439\n","Episode: 139, Epsilon: 0.1, Steps: 1000, Reward: -74.17685499714744, Best reward: 38.000227155265804, Avg reward: -174.2405771951583\n","Episode: 140, Epsilon: 0.1, Steps: 1000, Reward: -83.56536095827792, Best reward: 38.000227155265804, Avg reward: -173.16066758863911\n","Episode: 141, Epsilon: 0.1, Steps: 1000, Reward: -123.60080312113321, Best reward: 38.000227155265804, Avg reward: -173.17063004251304\n","Episode: 142, Epsilon: 0.1, Steps: 1000, Reward: -98.42361059827685, Best reward: 38.000227155265804, Avg reward: -170.47350931313065\n","Episode: 143, Epsilon: 0.1, Steps: 1000, Reward: -64.15685364263975, Best reward: 38.000227155265804, Avg reward: -166.80667748221617\n","Episode: 144, Epsilon: 0.1, Steps: 1000, Reward: -34.0186251653833, Best reward: 38.000227155265804, Avg reward: -163.7126021243972\n","Episode: 145, Epsilon: 0.1, Steps: 579, Reward: -116.73552898066299, Best reward: 38.000227155265804, Avg reward: -162.41772367114442\n","Episode: 146, Epsilon: 0.1, Steps: 1000, Reward: -108.90486446936242, Best reward: 38.000227155265804, Avg reward: -161.7035195709807\n","Episode: 147, Epsilon: 0.1, Steps: 1000, Reward: -97.66701153838949, Best reward: 38.000227155265804, Avg reward: -160.6304617712783\n","Episode: 148, Epsilon: 0.1, Steps: 1000, Reward: -110.01451753304237, Best reward: 38.000227155265804, Avg reward: -159.09054091160132\n","Episode: 149, Epsilon: 0.1, Steps: 411, Reward: -100.65632306306686, Best reward: 38.000227155265804, Avg reward: -155.73633325201564\n","Episode: 150, Epsilon: 0.1, Steps: 1000, Reward: -43.817093783813654, Best reward: 38.000227155265804, Avg reward: -153.88793548711027\n","Episode: 151, Epsilon: 0.1, Steps: 1000, Reward: -73.05843327568574, Best reward: 38.000227155265804, Avg reward: -153.5277628082042\n","Episode: 152, Epsilon: 0.1, Steps: 1000, Reward: -22.198688847506364, Best reward: 38.000227155265804, Avg reward: -151.16489118536936\n","Episode: 153, Epsilon: 0.1, Steps: 1000, Reward: -38.05974008601121, Best reward: 38.000227155265804, Avg reward: -149.28232662998462\n","Episode: 154, Epsilon: 0.1, Steps: 1000, Reward: -49.83847362963303, Best reward: 38.000227155265804, Avg reward: -146.0376730708592\n","Episode: 155, Epsilon: 0.1, Steps: 1000, Reward: -64.6031522834021, Best reward: 38.000227155265804, Avg reward: -142.5943525350473\n","Episode: 156, Epsilon: 0.1, Steps: 1000, Reward: -76.00875605183293, Best reward: 38.000227155265804, Avg reward: -140.626965307749\n","Episode: 157, Epsilon: 0.1, Steps: 1000, Reward: -99.37017691298384, Best reward: 38.000227155265804, Avg reward: -139.18092867044717\n","Episode: 158, Epsilon: 0.1, Steps: 1000, Reward: -73.2867977826234, Best reward: 38.000227155265804, Avg reward: -137.04969011515396\n","Episode: 159, Epsilon: 0.1, Steps: 1000, Reward: -93.50637272496711, Best reward: 38.000227155265804, Avg reward: -135.59486994570545\n","Episode: 160, Epsilon: 0.1, Steps: 1000, Reward: -49.30228193168759, Best reward: 38.000227155265804, Avg reward: -133.6073804601166\n","Episode: 161, Epsilon: 0.1, Steps: 1000, Reward: -36.64256272648952, Best reward: 38.000227155265804, Avg reward: -132.04524354477223\n","Episode: 162, Epsilon: 0.1, Steps: 1000, Reward: -87.12533228663861, Best reward: 38.000227155265804, Avg reward: -129.16163179109282\n","Episode: 163, Epsilon: 0.1, Steps: 1000, Reward: -95.80787010533298, Best reward: 38.000227155265804, Avg reward: -127.81117376517444\n","Episode: 164, Epsilon: 0.1, Steps: 1000, Reward: -42.423046135798835, Best reward: 38.000227155265804, Avg reward: -126.42156665515944\n","Episode: 165, Epsilon: 0.1, Steps: 1000, Reward: -35.03550435226626, Best reward: 38.000227155265804, Avg reward: -124.43855169384386\n","Episode: 166, Epsilon: 0.1, Steps: 1000, Reward: -63.460231693447454, Best reward: 38.000227155265804, Avg reward: -122.06306924003637\n","Episode: 167, Epsilon: 0.1, Steps: 1000, Reward: -74.8376108745926, Best reward: 38.000227155265804, Avg reward: -120.9523224344388\n","Episode: 168, Epsilon: 0.1, Steps: 1000, Reward: -75.13510131263489, Best reward: 38.000227155265804, Avg reward: -120.86733598697514\n","Episode: 169, Epsilon: 0.1, Steps: 552, Reward: 190.4719872854211, Best reward: 38.000227155265804, Avg reward: -118.04855112835368\n","... models saved successfully ...\n","Episode: 170, Epsilon: 0.1, Steps: 1000, Reward: -96.01650497984004, Best reward: 190.4719872854211, Avg reward: -115.9063533233121\n","Episode: 171, Epsilon: 0.1, Steps: 1000, Reward: -96.90360754241892, Best reward: 190.4719872854211, Avg reward: -114.98755392354991\n","Episode: 172, Epsilon: 0.1, Steps: 1000, Reward: -104.75315516841228, Best reward: 190.4719872854211, Avg reward: -113.54666054168327\n","Episode: 173, Epsilon: 0.1, Steps: 1000, Reward: -77.3669237330189, Best reward: 190.4719872854211, Avg reward: -112.36280117692033\n","Episode: 174, Epsilon: 0.1, Steps: 1000, Reward: -74.47876367496274, Best reward: 190.4719872854211, Avg reward: -112.00199227199988\n","Episode: 175, Epsilon: 0.1, Steps: 1000, Reward: -80.37206553534287, Best reward: 190.4719872854211, Avg reward: -110.62791644235\n","Episode: 176, Epsilon: 0.1, Steps: 1000, Reward: -75.87442229695489, Best reward: 190.4719872854211, Avg reward: -111.13300402475967\n","Episode: 177, Epsilon: 0.1, Steps: 1000, Reward: -17.818664953442276, Best reward: 190.4719872854211, Avg reward: -107.56485171605001\n","Episode: 178, Epsilon: 0.1, Steps: 1000, Reward: -82.85307178715361, Best reward: 190.4719872854211, Avg reward: -108.48281380002103\n","Episode: 179, Epsilon: 0.1, Steps: 1000, Reward: -18.683446560772428, Best reward: 190.4719872854211, Avg reward: -107.95395866556368\n","Episode: 180, Epsilon: 0.1, Steps: 1000, Reward: -55.48709934125317, Best reward: 190.4719872854211, Avg reward: -108.06777078149277\n","Episode: 181, Epsilon: 0.1, Steps: 1000, Reward: -11.26958326564257, Best reward: 190.4719872854211, Avg reward: -107.56651725672533\n","Episode: 182, Epsilon: 0.1, Steps: 289, Reward: -37.11902114739277, Best reward: 190.4719872854211, Avg reward: -107.28496952373945\n","Episode: 183, Epsilon: 0.1, Steps: 1000, Reward: -43.02053745492742, Best reward: 190.4719872854211, Avg reward: -106.98508508902317\n","Episode: 184, Epsilon: 0.1, Steps: 1000, Reward: 4.171470743588408, Best reward: 190.4719872854211, Avg reward: -105.58958132322029\n","Episode: 185, Epsilon: 0.1, Steps: 1000, Reward: -42.061884030209875, Best reward: 190.4719872854211, Avg reward: -105.03654906860206\n","Episode: 186, Epsilon: 0.1, Steps: 1000, Reward: 2.6913461604325017, Best reward: 190.4719872854211, Avg reward: -103.39889334652845\n","Episode: 187, Epsilon: 0.1, Steps: 1000, Reward: -27.721407815372086, Best reward: 190.4719872854211, Avg reward: -103.17581123784574\n","Episode: 188, Epsilon: 0.1, Steps: 1000, Reward: -34.15811485436743, Best reward: 190.4719872854211, Avg reward: -103.40550743651757\n","Episode: 189, Epsilon: 0.1, Steps: 1000, Reward: -48.277599360606494, Best reward: 190.4719872854211, Avg reward: -103.10378904546741\n","Episode: 190, Epsilon: 0.1, Steps: 1000, Reward: -45.87983931016133, Best reward: 190.4719872854211, Avg reward: -102.73278913565517\n","Episode: 191, Epsilon: 0.1, Steps: 1000, Reward: -86.3709107589885, Best reward: 190.4719872854211, Avg reward: -103.55418545987914\n","Episode: 192, Epsilon: 0.1, Steps: 1000, Reward: -57.21159714448824, Best reward: 190.4719872854211, Avg reward: -104.3312874762326\n","Episode: 193, Epsilon: 0.1, Steps: 1000, Reward: -50.55350204801814, Best reward: 190.4719872854211, Avg reward: -105.01800150860053\n","Episode: 194, Epsilon: 0.1, Steps: 1000, Reward: -47.51908504734704, Best reward: 190.4719872854211, Avg reward: -105.39619641682224\n","Episode: 195, Epsilon: 0.1, Steps: 1000, Reward: -84.41637514249871, Best reward: 190.4719872854211, Avg reward: -106.14742868467178\n","Episode: 196, Epsilon: 0.1, Steps: 181, Reward: -14.476128694433271, Best reward: 190.4719872854211, Avg reward: -104.50396063362007\n","Episode: 197, Epsilon: 0.1, Steps: 880, Reward: 98.07008262785584, Best reward: 190.4719872854211, Avg reward: -103.57284502930497\n","Episode: 198, Epsilon: 0.1, Steps: 1000, Reward: -31.31929646058708, Best reward: 190.4719872854211, Avg reward: -103.2029061178889\n","Episode: 199, Epsilon: 0.1, Steps: 1000, Reward: -29.374417417015348, Best reward: 190.4719872854211, Avg reward: -101.37685946992029\n","Episode: 200, Epsilon: 0.1, Steps: 1000, Reward: -23.093087921128063, Best reward: 190.4719872854211, Avg reward: -101.98779262068422\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x7428200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 201, Epsilon: 0.1, Steps: 1000, Reward: -116.31469234103976, Best reward: 190.4719872854211, Avg reward: -102.94169255196037\n","Episode: 202, Epsilon: 0.1, Steps: 1000, Reward: -71.6866297205448, Best reward: 190.4719872854211, Avg reward: -100.56639003650994\n","Episode: 203, Epsilon: 0.1, Steps: 1000, Reward: -74.80610703146876, Best reward: 190.4719872854211, Avg reward: -100.15558463938677\n","Episode: 204, Epsilon: 0.1, Steps: 899, Reward: -174.96453032910682, Best reward: 190.4719872854211, Avg reward: -96.76312681549\n","Episode: 205, Epsilon: 0.1, Steps: 1000, Reward: -35.17078494196786, Best reward: 190.4719872854211, Avg reward: -92.34897596038957\n","Episode: 206, Epsilon: 0.1, Steps: 1000, Reward: 33.90288732998401, Best reward: 190.4719872854211, Avg reward: -89.2488465046218\n","Episode: 207, Epsilon: 0.1, Steps: 1000, Reward: -72.63346021936273, Best reward: 190.4719872854211, Avg reward: -87.24514808801482\n","Episode: 208, Epsilon: 0.1, Steps: 1000, Reward: -75.68905811606537, Best reward: 190.4719872854211, Avg reward: -84.45144183227656\n","Episode: 209, Epsilon: 0.1, Steps: 1000, Reward: -76.37490432875865, Best reward: 190.4719872854211, Avg reward: -82.03466968171792\n","Episode: 210, Epsilon: 0.1, Steps: 1000, Reward: -34.36305825792325, Best reward: 190.4719872854211, Avg reward: -78.99990121041478\n","Episode: 211, Epsilon: 0.1, Steps: 259, Reward: -59.80954553770739, Best reward: 190.4719872854211, Avg reward: -77.49751561433281\n","Episode: 212, Epsilon: 0.1, Steps: 793, Reward: 164.84680268609407, Best reward: 190.4719872854211, Avg reward: -73.24336540234849\n","Episode: 213, Epsilon: 0.1, Steps: 663, Reward: 168.59191307433332, Best reward: 190.4719872854211, Avg reward: -70.6868699048657\n","Episode: 214, Epsilon: 0.1, Steps: 1000, Reward: -72.18434798133292, Best reward: 190.4719872854211, Avg reward: -69.69801666834988\n","Episode: 215, Epsilon: 0.1, Steps: 390, Reward: -104.6698568698552, Best reward: 190.4719872854211, Avg reward: -67.21261115749756\n","Episode: 216, Epsilon: 0.1, Steps: 126, Reward: -88.61003461896611, Best reward: 190.4719872854211, Avg reward: -65.95450440002223\n","Episode: 217, Epsilon: 0.1, Steps: 433, Reward: -76.84075779949104, Best reward: 190.4719872854211, Avg reward: -62.41964629670495\n","Episode: 218, Epsilon: 0.1, Steps: 923, Reward: 177.28195510487365, Best reward: 190.4719872854211, Avg reward: -57.882190727361476\n","Episode: 219, Epsilon: 0.1, Steps: 1000, Reward: 3.541919390491267, Best reward: 190.4719872854211, Avg reward: -57.20882213953464\n","Episode: 220, Epsilon: 0.1, Steps: 677, Reward: 107.88584398778428, Best reward: 190.4719872854211, Avg reward: -55.63546922351214\n","Episode: 221, Epsilon: 0.1, Steps: 165, Reward: -76.13705619963021, Best reward: 190.4719872854211, Avg reward: -55.71225238034903\n","Episode: 222, Epsilon: 0.1, Steps: 150, Reward: -16.11254636818734, Best reward: 190.4719872854211, Avg reward: -54.01372603905435\n","Episode: 223, Epsilon: 0.1, Steps: 495, Reward: -98.16265098730642, Best reward: 190.4719872854211, Avg reward: -52.677277851416214\n","Episode: 224, Epsilon: 0.1, Steps: 155, Reward: 1.8911274177592503, Best reward: 190.4719872854211, Avg reward: -49.52860671788722\n","Episode: 225, Epsilon: 0.1, Steps: 293, Reward: -105.96582853212755, Best reward: 190.4719872854211, Avg reward: -49.86377886436223\n","Episode: 226, Epsilon: 0.1, Steps: 490, Reward: -48.753618220446576, Best reward: 190.4719872854211, Avg reward: -50.423175607315315\n","Episode: 227, Epsilon: 0.1, Steps: 534, Reward: -169.35529545905158, Best reward: 190.4719872854211, Avg reward: -51.91758220014133\n","Episode: 228, Epsilon: 0.1, Steps: 306, Reward: -177.04307769288397, Best reward: 190.4719872854211, Avg reward: -52.495982165611366\n","Episode: 229, Epsilon: 0.1, Steps: 280, Reward: -165.8659052554894, Best reward: 190.4719872854211, Avg reward: -52.96562267603535\n","Episode: 230, Epsilon: 0.1, Steps: 119, Reward: -192.8988578551893, Best reward: 190.4719872854211, Avg reward: -54.777081582899484\n","Episode: 231, Epsilon: 0.1, Steps: 220, Reward: -193.60469867413138, Best reward: 190.4719872854211, Avg reward: -55.64310566233559\n","Episode: 232, Epsilon: 0.1, Steps: 111, Reward: -230.03616144135327, Best reward: 190.4719872854211, Avg reward: -58.20901707123349\n","Episode: 233, Epsilon: 0.1, Steps: 594, Reward: 171.27069028647935, Best reward: 190.4719872854211, Avg reward: -55.359550350094416\n","Episode: 234, Epsilon: 0.1, Steps: 502, Reward: 172.04145100586766, Best reward: 190.4719872854211, Avg reward: -52.59628669149717\n","Episode: 235, Epsilon: 0.1, Steps: 1000, Reward: -65.48303419062485, Best reward: 190.4719872854211, Avg reward: -52.2689078615121\n","Episode: 236, Epsilon: 0.1, Steps: 132, Reward: -205.88565106797762, Best reward: 190.4719872854211, Avg reward: -53.4229203166412\n","Episode: 237, Epsilon: 0.1, Steps: 112, Reward: -241.97533964909576, Best reward: 190.4719872854211, Avg reward: -55.49629884227362\n","Episode: 238, Epsilon: 0.1, Steps: 138, Reward: -193.55426712403437, Best reward: 190.4719872854211, Avg reward: -57.18179974021644\n","Episode: 239, Epsilon: 0.1, Steps: 103, Reward: -233.02003389086275, Best reward: 190.4719872854211, Avg reward: -58.77023152915359\n","Episode: 240, Epsilon: 0.1, Steps: 273, Reward: -198.88071001926107, Best reward: 190.4719872854211, Avg reward: -59.92338501976341\n","Episode: 241, Epsilon: 0.1, Steps: 114, Reward: -174.59649015214967, Best reward: 190.4719872854211, Avg reward: -60.43334189007357\n","Episode: 242, Epsilon: 0.1, Steps: 220, Reward: -135.61584662562174, Best reward: 190.4719872854211, Avg reward: -60.805264250347015\n","Episode: 243, Epsilon: 0.1, Steps: 117, Reward: -284.57339260577544, Best reward: 190.4719872854211, Avg reward: -63.00942963997838\n","Episode: 244, Epsilon: 0.1, Steps: 155, Reward: -78.45737089403866, Best reward: 190.4719872854211, Avg reward: -63.45381709726494\n","Episode: 245, Epsilon: 0.1, Steps: 326, Reward: -199.07598580528975, Best reward: 190.4719872854211, Avg reward: -64.2772216655112\n","Episode: 246, Epsilon: 0.1, Steps: 1000, Reward: -112.94725191809934, Best reward: 190.4719872854211, Avg reward: -64.31764553999858\n","Episode: 247, Epsilon: 0.1, Steps: 819, Reward: 130.7817444106525, Best reward: 190.4719872854211, Avg reward: -62.03315798050815\n","Episode: 248, Epsilon: 0.1, Steps: 188, Reward: -207.31508176424725, Best reward: 190.4719872854211, Avg reward: -63.0061636228202\n","Episode: 249, Epsilon: 0.1, Steps: 143, Reward: -128.60247669582958, Best reward: 190.4719872854211, Avg reward: -63.28562515914783\n","Episode: 250, Epsilon: 0.1, Steps: 1000, Reward: -54.1588494217146, Best reward: 190.4719872854211, Avg reward: -63.38904271552684\n","Episode: 251, Epsilon: 0.1, Steps: 138, Reward: -304.10248101342563, Best reward: 190.4719872854211, Avg reward: -65.69948319290424\n","Episode: 252, Epsilon: 0.1, Steps: 115, Reward: -154.06347940330141, Best reward: 190.4719872854211, Avg reward: -67.01813109846219\n","Episode: 253, Epsilon: 0.1, Steps: 273, Reward: -62.234832378075204, Best reward: 190.4719872854211, Avg reward: -67.25988202138282\n","Episode: 254, Epsilon: 0.1, Steps: 194, Reward: -192.40172440952801, Best reward: 190.4719872854211, Avg reward: -68.68551452918179\n","Episode: 255, Epsilon: 0.1, Steps: 175, Reward: -204.1781598436647, Best reward: 190.4719872854211, Avg reward: -70.0812646047844\n","Episode: 256, Epsilon: 0.1, Steps: 81, Reward: -105.92013456315246, Best reward: 190.4719872854211, Avg reward: -70.3803783898976\n","Episode: 257, Epsilon: 0.1, Steps: 1000, Reward: -98.33201516522304, Best reward: 190.4719872854211, Avg reward: -70.36999677242\n","Episode: 258, Epsilon: 0.1, Steps: 127, Reward: -66.28240119094032, Best reward: 190.4719872854211, Avg reward: -70.29995280650316\n","Episode: 259, Epsilon: 0.1, Steps: 1000, Reward: -97.93070225063438, Best reward: 190.4719872854211, Avg reward: -70.34419610175983\n","Episode: 260, Epsilon: 0.1, Steps: 625, Reward: 153.19067899993246, Best reward: 190.4719872854211, Avg reward: -68.31926649244365\n","Episode: 261, Epsilon: 0.1, Steps: 1000, Reward: -61.406019792889474, Best reward: 190.4719872854211, Avg reward: -68.56690106310764\n","Episode: 262, Epsilon: 0.1, Steps: 139, Reward: -51.22110312518991, Best reward: 190.4719872854211, Avg reward: -68.20785877149315\n","Episode: 263, Epsilon: 0.1, Steps: 522, Reward: 176.35766150699737, Best reward: 190.4719872854211, Avg reward: -65.48620345536985\n","Episode: 264, Epsilon: 0.1, Steps: 197, Reward: -159.9770411081661, Best reward: 190.4719872854211, Avg reward: -66.66174340509352\n","Episode: 265, Epsilon: 0.1, Steps: 115, Reward: -177.7027120516908, Best reward: 190.4719872854211, Avg reward: -68.08841548208777\n","Episode: 266, Epsilon: 0.1, Steps: 209, Reward: -205.96531618979782, Best reward: 190.4719872854211, Avg reward: -69.51346632705126\n","Episode: 267, Epsilon: 0.1, Steps: 138, Reward: -200.71645274760436, Best reward: 190.4719872854211, Avg reward: -70.77225474578137\n","Episode: 268, Epsilon: 0.1, Steps: 121, Reward: -180.89696928589433, Best reward: 190.4719872854211, Avg reward: -71.82987342551397\n","Episode: 269, Epsilon: 0.1, Steps: 183, Reward: -180.8102718999333, Best reward: 190.4719872854211, Avg reward: -75.54269601736752\n","Episode: 270, Epsilon: 0.1, Steps: 1000, Reward: -89.54725191051726, Best reward: 190.4719872854211, Avg reward: -75.47800348667428\n","Episode: 271, Epsilon: 0.1, Steps: 208, Reward: -130.57587101673647, Best reward: 190.4719872854211, Avg reward: -75.81472612141746\n","Episode: 272, Epsilon: 0.1, Steps: 140, Reward: -110.67731671037313, Best reward: 190.4719872854211, Avg reward: -75.87396773683707\n","Episode: 273, Epsilon: 0.1, Steps: 121, Reward: -176.42874315425667, Best reward: 190.4719872854211, Avg reward: -76.86458593104945\n","Episode: 274, Epsilon: 0.1, Steps: 104, Reward: -233.92215163549653, Best reward: 190.4719872854211, Avg reward: -78.4590198106548\n","Episode: 275, Epsilon: 0.1, Steps: 161, Reward: -90.13104884816818, Best reward: 190.4719872854211, Avg reward: -78.55660964378305\n","Episode: 276, Epsilon: 0.1, Steps: 137, Reward: -56.959617659275565, Best reward: 190.4719872854211, Avg reward: -78.36746159740626\n","Episode: 277, Epsilon: 0.1, Steps: 1000, Reward: -84.05570333690407, Best reward: 190.4719872854211, Avg reward: -79.02983198124087\n","Episode: 278, Epsilon: 0.1, Steps: 307, Reward: -89.54828678229917, Best reward: 190.4719872854211, Avg reward: -79.09678413119234\n","Episode: 279, Epsilon: 0.1, Steps: 219, Reward: -79.63526958183095, Best reward: 190.4719872854211, Avg reward: -79.70630236140292\n","Episode: 280, Epsilon: 0.1, Steps: 492, Reward: 129.67901791534578, Best reward: 190.4719872854211, Avg reward: -77.85464118883692\n","Episode: 281, Epsilon: 0.1, Steps: 292, Reward: -22.097714676855276, Best reward: 190.4719872854211, Avg reward: -77.96292250294906\n","Episode: 282, Epsilon: 0.1, Steps: 573, Reward: 171.83453404544912, Best reward: 190.4719872854211, Avg reward: -75.87338695102063\n","Episode: 283, Epsilon: 0.1, Steps: 217, Reward: -103.9351912355858, Best reward: 190.4719872854211, Avg reward: -76.48253348882722\n","Episode: 284, Epsilon: 0.1, Steps: 488, Reward: 198.17397458995413, Best reward: 190.4719872854211, Avg reward: -74.54250845036357\n","... models saved successfully ...\n","Episode: 285, Epsilon: 0.1, Steps: 1000, Reward: -79.57307643172727, Best reward: 198.17397458995413, Avg reward: -74.91762037437873\n","Episode: 286, Epsilon: 0.1, Steps: 211, Reward: -185.29887398183746, Best reward: 198.17397458995413, Avg reward: -76.79752257580144\n","Episode: 287, Epsilon: 0.1, Steps: 167, Reward: -50.9282476703867, Best reward: 198.17397458995413, Avg reward: -77.02959097435156\n","Episode: 288, Epsilon: 0.1, Steps: 136, Reward: -143.00664549773055, Best reward: 198.17397458995413, Avg reward: -78.1180762807852\n","Episode: 289, Epsilon: 0.1, Steps: 111, Reward: -170.51001322695276, Best reward: 198.17397458995413, Avg reward: -79.34040041944866\n","Episode: 290, Epsilon: 0.1, Steps: 126, Reward: -164.67170626772582, Best reward: 198.17397458995413, Avg reward: -80.52831908902432\n","Episode: 291, Epsilon: 0.1, Steps: 1000, Reward: -62.52873933582053, Best reward: 198.17397458995413, Avg reward: -80.28989737479263\n","Episode: 292, Epsilon: 0.1, Steps: 1000, Reward: -87.81030745441562, Best reward: 198.17397458995413, Avg reward: -80.59588447789191\n","Episode: 293, Epsilon: 0.1, Steps: 1000, Reward: -48.961775875883745, Best reward: 198.17397458995413, Avg reward: -80.57996721617059\n","Episode: 294, Epsilon: 0.1, Steps: 1000, Reward: -102.66956520264452, Best reward: 198.17397458995413, Avg reward: -81.13147201772354\n","Episode: 295, Epsilon: 0.1, Steps: 1000, Reward: -84.17339045255117, Best reward: 198.17397458995413, Avg reward: -81.12904217082406\n","Episode: 296, Epsilon: 0.1, Steps: 1000, Reward: -89.14582506285548, Best reward: 198.17397458995413, Avg reward: -81.87573913450828\n","Episode: 297, Epsilon: 0.1, Steps: 1000, Reward: -57.37186486549642, Best reward: 198.17397458995413, Avg reward: -83.4301586094418\n","Episode: 298, Epsilon: 0.1, Steps: 1000, Reward: -3.141394917028115, Best reward: 198.17397458995413, Avg reward: -83.1483795940062\n","Episode: 299, Epsilon: 0.1, Steps: 1000, Reward: 55.10155965916877, Best reward: 198.17397458995413, Avg reward: -82.30361982324435\n","Episode: 300, Epsilon: 0.1, Steps: 299, Reward: -41.43096992424175, Best reward: 198.17397458995413, Avg reward: -82.4869986432755\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x581e200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 301, Epsilon: 0.1, Steps: 342, Reward: 174.5858563975807, Best reward: 198.17397458995413, Avg reward: -79.57799315588932\n","Episode: 302, Epsilon: 0.1, Steps: 1000, Reward: -56.09659634687575, Best reward: 198.17397458995413, Avg reward: -79.42209282215262\n","Episode: 303, Epsilon: 0.1, Steps: 1000, Reward: -93.71327290994826, Best reward: 198.17397458995413, Avg reward: -79.61116448093742\n","Episode: 304, Epsilon: 0.1, Steps: 188, Reward: -15.830157410689594, Best reward: 198.17397458995413, Avg reward: -78.01982075175324\n","Episode: 305, Epsilon: 0.1, Steps: 333, Reward: -251.36129605023822, Best reward: 198.17397458995413, Avg reward: -80.18172586283595\n","Episode: 306, Epsilon: 0.1, Steps: 132, Reward: -117.85707496910125, Best reward: 198.17397458995413, Avg reward: -81.6993254858268\n","Episode: 307, Epsilon: 0.1, Steps: 301, Reward: -43.17027252547476, Best reward: 198.17397458995413, Avg reward: -81.40469360888791\n","Episode: 308, Epsilon: 0.1, Steps: 369, Reward: 168.58439138407945, Best reward: 198.17397458995413, Avg reward: -78.96195911388646\n","Episode: 309, Epsilon: 0.1, Steps: 1000, Reward: -96.02274597787248, Best reward: 198.17397458995413, Avg reward: -79.15843753037761\n","Episode: 310, Epsilon: 0.1, Steps: 1000, Reward: 33.37842918736585, Best reward: 198.17397458995413, Avg reward: -78.48102265592472\n","Episode: 311, Epsilon: 0.1, Steps: 274, Reward: -174.95033517688023, Best reward: 198.17397458995413, Avg reward: -79.63243055231644\n","Episode: 312, Epsilon: 0.1, Steps: 1000, Reward: 109.56880270777697, Best reward: 198.17397458995413, Avg reward: -80.1852105520996\n","Episode: 313, Epsilon: 0.1, Steps: 279, Reward: -20.34239746273495, Best reward: 198.17397458995413, Avg reward: -82.07455365747029\n","Episode: 314, Epsilon: 0.1, Steps: 1000, Reward: -54.94891229432209, Best reward: 198.17397458995413, Avg reward: -81.90219930060019\n","Episode: 315, Epsilon: 0.1, Steps: 198, Reward: -8.182200220955266, Best reward: 198.17397458995413, Avg reward: -80.93732273411119\n","Episode: 316, Epsilon: 0.1, Steps: 234, Reward: -140.95229420042207, Best reward: 198.17397458995413, Avg reward: -81.46074532992576\n","Episode: 317, Epsilon: 0.1, Steps: 397, Reward: 203.2512106931643, Best reward: 198.17397458995413, Avg reward: -78.6598256449992\n","... models saved successfully ...\n","Episode: 318, Epsilon: 0.1, Steps: 272, Reward: -57.46809712858715, Best reward: 203.2512106931643, Avg reward: -81.00732616733382\n","Episode: 319, Epsilon: 0.1, Steps: 1000, Reward: -46.4971064439334, Best reward: 203.2512106931643, Avg reward: -81.50771642567805\n","Episode: 320, Epsilon: 0.1, Steps: 1000, Reward: -66.66548223797842, Best reward: 203.2512106931643, Avg reward: -83.25322968793569\n","Episode: 321, Epsilon: 0.1, Steps: 193, Reward: -16.9487835967214, Best reward: 203.2512106931643, Avg reward: -82.66134696190659\n","Episode: 322, Epsilon: 0.1, Steps: 448, Reward: 179.6310112673778, Best reward: 203.2512106931643, Avg reward: -80.70391138555092\n","Episode: 323, Epsilon: 0.1, Steps: 175, Reward: -113.58527804126895, Best reward: 203.2512106931643, Avg reward: -80.85813765609056\n","Episode: 324, Epsilon: 0.1, Steps: 204, Reward: -42.77990045796602, Best reward: 203.2512106931643, Avg reward: -81.30484793484781\n","Episode: 325, Epsilon: 0.1, Steps: 170, Reward: 41.826272218578396, Best reward: 203.2512106931643, Avg reward: -79.82692692734076\n","Episode: 326, Epsilon: 0.1, Steps: 1000, Reward: -91.11738760339037, Best reward: 203.2512106931643, Avg reward: -80.25056462117018\n","Episode: 327, Epsilon: 0.1, Steps: 1000, Reward: -83.82226538946124, Best reward: 203.2512106931643, Avg reward: -79.39523432047429\n","Episode: 328, Epsilon: 0.1, Steps: 172, Reward: -152.61635965456173, Best reward: 203.2512106931643, Avg reward: -79.15096714009108\n","Episode: 329, Epsilon: 0.1, Steps: 1000, Reward: 118.91825924745393, Best reward: 203.2512106931643, Avg reward: -76.30312549506164\n","Episode: 330, Epsilon: 0.1, Steps: 1000, Reward: 90.4484050643268, Best reward: 203.2512106931643, Avg reward: -73.46965286586648\n","Episode: 331, Epsilon: 0.1, Steps: 1000, Reward: -0.11776247786379757, Best reward: 203.2512106931643, Avg reward: -71.53478350390381\n","Episode: 332, Epsilon: 0.1, Steps: 1000, Reward: -181.8965646064826, Best reward: 203.2512106931643, Avg reward: -71.0533875355551\n","Episode: 333, Epsilon: 0.1, Steps: 169, Reward: -156.65612996855273, Best reward: 203.2512106931643, Avg reward: -74.3326557381054\n","Episode: 334, Epsilon: 0.1, Steps: 1000, Reward: -18.873031562734546, Best reward: 203.2512106931643, Avg reward: -76.24180056379144\n","Episode: 335, Epsilon: 0.1, Steps: 112, Reward: -40.12089936372735, Best reward: 203.2512106931643, Avg reward: -75.98817921552246\n","Episode: 336, Epsilon: 0.1, Steps: 1000, Reward: 135.2381808240916, Best reward: 203.2512106931643, Avg reward: -72.57694089660177\n","Episode: 337, Epsilon: 0.1, Steps: 294, Reward: 6.00189796309057, Best reward: 203.2512106931643, Avg reward: -70.0971685204799\n","Episode: 338, Epsilon: 0.1, Steps: 1000, Reward: 121.75441418269021, Best reward: 203.2512106931643, Avg reward: -66.94408170741266\n","Episode: 339, Epsilon: 0.1, Steps: 1000, Reward: 47.87476782630273, Best reward: 203.2512106931643, Avg reward: -64.135133690241\n","Episode: 340, Epsilon: 0.1, Steps: 285, Reward: 203.7266400457538, Best reward: 203.2512106931643, Avg reward: -60.10906018959086\n","... models saved successfully ...\n","Episode: 341, Epsilon: 0.1, Steps: 1000, Reward: 115.90201750603023, Best reward: 203.7266400457538, Avg reward: -57.20407511300907\n","Episode: 342, Epsilon: 0.1, Steps: 123, Reward: -91.44012294893746, Best reward: 203.7266400457538, Avg reward: -56.762317876242214\n","Episode: 343, Epsilon: 0.1, Steps: 1000, Reward: 85.20720518299528, Best reward: 203.7266400457538, Avg reward: -53.06451189835451\n","Episode: 344, Epsilon: 0.1, Steps: 1000, Reward: 55.619858179269535, Best reward: 203.7266400457538, Avg reward: -51.723739607621425\n","Episode: 345, Epsilon: 0.1, Steps: 662, Reward: 153.33286142249258, Best reward: 203.7266400457538, Avg reward: -48.1996511353436\n","Episode: 346, Epsilon: 0.1, Steps: 1000, Reward: 3.7769541772947215, Best reward: 203.7266400457538, Avg reward: -47.032409074389655\n","Episode: 347, Epsilon: 0.1, Steps: 1000, Reward: 128.95505650191495, Best reward: 203.7266400457538, Avg reward: -47.05067595347702\n","Episode: 348, Epsilon: 0.1, Steps: 994, Reward: 45.15445566904931, Best reward: 203.7266400457538, Avg reward: -44.52598057914406\n","Episode: 349, Epsilon: 0.1, Steps: 706, Reward: 198.30422457609893, Best reward: 203.7266400457538, Avg reward: -41.256913566424785\n","Episode: 350, Epsilon: 0.1, Steps: 1000, Reward: 128.6984659387108, Best reward: 203.7266400457538, Avg reward: -39.428340412820525\n","Episode: 351, Epsilon: 0.1, Steps: 1000, Reward: 28.033745828700464, Best reward: 203.7266400457538, Avg reward: -36.10697814439927\n","Episode: 352, Epsilon: 0.1, Steps: 410, Reward: 248.0913682104855, Best reward: 203.7266400457538, Avg reward: -32.085429668261405\n","... models saved successfully ...\n","Episode: 353, Epsilon: 0.1, Steps: 508, Reward: 193.8102962806441, Best reward: 248.0913682104855, Avg reward: -29.52497838167421\n","Episode: 354, Epsilon: 0.1, Steps: 229, Reward: 19.245531828776436, Best reward: 248.0913682104855, Avg reward: -27.408505819291165\n","Episode: 355, Epsilon: 0.1, Steps: 1000, Reward: -73.60404487701611, Best reward: 248.0913682104855, Avg reward: -26.102764669624673\n","Episode: 356, Epsilon: 0.1, Steps: 1000, Reward: -33.76550734301105, Best reward: 248.0913682104855, Avg reward: -25.381218397423254\n","Episode: 357, Epsilon: 0.1, Steps: 1000, Reward: -13.973003229977929, Best reward: 248.0913682104855, Avg reward: -24.537628278070812\n","Episode: 358, Epsilon: 0.1, Steps: 890, Reward: 151.05564754961483, Best reward: 248.0913682104855, Avg reward: -22.36424779066526\n","Episode: 359, Epsilon: 0.1, Steps: 1000, Reward: -32.344216479490115, Best reward: 248.0913682104855, Avg reward: -21.708382932953825\n","Episode: 360, Epsilon: 0.1, Steps: 958, Reward: 121.48799369915682, Best reward: 248.0913682104855, Avg reward: -22.025409785961575\n","Episode: 361, Epsilon: 0.1, Steps: 222, Reward: 38.23233692742974, Best reward: 248.0913682104855, Avg reward: -21.029026218758382\n","Episode: 362, Epsilon: 0.1, Steps: 1000, Reward: -32.6620991004001, Best reward: 248.0913682104855, Avg reward: -20.843436178510483\n","Episode: 363, Epsilon: 0.1, Steps: 894, Reward: -79.30919454414331, Best reward: 248.0913682104855, Avg reward: -23.400104739021895\n","Episode: 364, Epsilon: 0.1, Steps: 1000, Reward: 26.7806993626409, Best reward: 248.0913682104855, Avg reward: -21.532527334313823\n","Episode: 365, Epsilon: 0.1, Steps: 409, Reward: 243.49062793309795, Best reward: 248.0913682104855, Avg reward: -17.320593934465936\n","Episode: 366, Epsilon: 0.1, Steps: 1000, Reward: -38.1797389634428, Best reward: 248.0913682104855, Avg reward: -15.642738162202384\n","Episode: 367, Epsilon: 0.1, Steps: 1000, Reward: -57.43561106254014, Best reward: 248.0913682104855, Avg reward: -14.209929745351742\n","Episode: 368, Epsilon: 0.1, Steps: 1000, Reward: 0.6210452836532769, Best reward: 248.0913682104855, Avg reward: -12.394749599656269\n","Episode: 369, Epsilon: 0.1, Steps: 1000, Reward: -36.57737748790868, Best reward: 248.0913682104855, Avg reward: -10.952420655536024\n","Episode: 370, Epsilon: 0.1, Steps: 1000, Reward: -67.11050292545956, Best reward: 248.0913682104855, Avg reward: -10.728053165685441\n","Episode: 371, Epsilon: 0.1, Steps: 1000, Reward: -9.200038881778273, Best reward: 248.0913682104855, Avg reward: -9.514294844335861\n","Episode: 372, Epsilon: 0.1, Steps: 1000, Reward: -65.83494461859863, Best reward: 248.0913682104855, Avg reward: -9.065871123418116\n","Episode: 373, Epsilon: 0.1, Steps: 1000, Reward: -39.8880287025031, Best reward: 248.0913682104855, Avg reward: -7.700463978900582\n","Episode: 374, Epsilon: 0.1, Steps: 1000, Reward: -82.796250657511, Best reward: 248.0913682104855, Avg reward: -6.189204969120726\n","Episode: 375, Epsilon: 0.1, Steps: 1000, Reward: -76.79562728793273, Best reward: 248.0913682104855, Avg reward: -6.055850753518372\n","Episode: 376, Epsilon: 0.1, Steps: 1000, Reward: -29.353161382156824, Best reward: 248.0913682104855, Avg reward: -5.779786190747185\n","Episode: 377, Epsilon: 0.1, Steps: 1000, Reward: -72.17550561090607, Best reward: 248.0913682104855, Avg reward: -5.660984213487206\n","Episode: 378, Epsilon: 0.1, Steps: 1000, Reward: 39.33614893778679, Best reward: 248.0913682104855, Avg reward: -4.372139856286346\n","Episode: 379, Epsilon: 0.1, Steps: 1000, Reward: -19.276036529765193, Best reward: 248.0913682104855, Avg reward: -3.7685475257656855\n","Episode: 380, Epsilon: 0.1, Steps: 738, Reward: -159.6290919107175, Best reward: 248.0913682104855, Avg reward: -6.66162862402632\n","Episode: 381, Epsilon: 0.1, Steps: 1000, Reward: -78.43216828784834, Best reward: 248.0913682104855, Avg reward: -7.224973160136249\n","Episode: 382, Epsilon: 0.1, Steps: 1000, Reward: -90.29856063447755, Best reward: 248.0913682104855, Avg reward: -9.846304106935515\n","Episode: 383, Epsilon: 0.1, Steps: 1000, Reward: -94.3441192316802, Best reward: 248.0913682104855, Avg reward: -9.75039338689646\n","Episode: 384, Epsilon: 0.1, Steps: 1000, Reward: -77.64578514616586, Best reward: 248.0913682104855, Avg reward: -12.50859098425766\n","Episode: 385, Epsilon: 0.1, Steps: 976, Reward: -169.75014147263934, Best reward: 248.0913682104855, Avg reward: -13.410361634666781\n","Episode: 386, Epsilon: 0.1, Steps: 1000, Reward: -58.38291880470426, Best reward: 248.0913682104855, Avg reward: -12.141202082895447\n","Episode: 387, Epsilon: 0.1, Steps: 1000, Reward: -125.6747631180295, Best reward: 248.0913682104855, Avg reward: -12.888667237371877\n","Episode: 388, Epsilon: 0.1, Steps: 424, Reward: 272.9240191822435, Best reward: 248.0913682104855, Avg reward: -8.729360590572137\n","... models saved successfully ...\n","Episode: 389, Epsilon: 0.1, Steps: 1000, Reward: -77.13476993749033, Best reward: 272.9240191822435, Avg reward: -7.795608157677512\n","Episode: 390, Epsilon: 0.1, Steps: 1000, Reward: -88.38490608157798, Best reward: 272.9240191822435, Avg reward: -7.032740155816034\n","Episode: 391, Epsilon: 0.1, Steps: 1000, Reward: -67.5137256637514, Best reward: 272.9240191822435, Avg reward: -7.08259001909534\n","Episode: 392, Epsilon: 0.1, Steps: 1000, Reward: -22.600711851033928, Best reward: 272.9240191822435, Avg reward: -6.4304940630615235\n","Episode: 393, Epsilon: 0.1, Steps: 311, Reward: 257.960396041135, Best reward: 272.9240191822435, Avg reward: -3.361272343891336\n","Episode: 394, Epsilon: 0.1, Steps: 1000, Reward: -77.53484202738969, Best reward: 272.9240191822435, Avg reward: -3.1099251121387885\n","Episode: 395, Epsilon: 0.1, Steps: 171, Reward: 6.024193523050627, Best reward: 272.9240191822435, Avg reward: -2.20794927238277\n","Episode: 396, Epsilon: 0.1, Steps: 1000, Reward: -81.82800416465874, Best reward: 272.9240191822435, Avg reward: -2.1347710634008017\n","Episode: 397, Epsilon: 0.1, Steps: 293, Reward: 281.8536200069608, Best reward: 272.9240191822435, Avg reward: 1.25748378532377\n","... models saved successfully ...\n","Episode: 398, Epsilon: 0.1, Steps: 1000, Reward: -56.45704121606052, Best reward: 281.8536200069608, Avg reward: 0.7243273223334457\n","Episode: 399, Epsilon: 0.1, Steps: 1000, Reward: -26.073620666736183, Best reward: 281.8536200069608, Avg reward: -0.08742448092560359\n","Episode: 400, Epsilon: 0.1, Steps: 1000, Reward: -59.80244946177919, Best reward: 281.8536200069608, Avg reward: -0.27113927630097784\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x6ecf600] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 401, Epsilon: 0.1, Steps: 584, Reward: 240.84563609937894, Best reward: 281.8536200069608, Avg reward: 0.3914585207170046\n","Episode: 402, Epsilon: 0.1, Steps: 329, Reward: 254.77745230229314, Best reward: 281.8536200069608, Avg reward: 3.500199007208693\n","Episode: 403, Epsilon: 0.1, Steps: 455, Reward: 255.50350683477723, Best reward: 281.8536200069608, Avg reward: 6.992366804655949\n","Episode: 404, Epsilon: 0.1, Steps: 1000, Reward: -56.07172882655091, Best reward: 281.8536200069608, Avg reward: 6.589951090497335\n","Episode: 405, Epsilon: 0.1, Steps: 106, Reward: -37.39779466299541, Best reward: 281.8536200069608, Avg reward: 8.729586104369762\n","Episode: 406, Epsilon: 0.1, Steps: 1000, Reward: 29.50431958879599, Best reward: 281.8536200069608, Avg reward: 10.203200049948734\n","Episode: 407, Epsilon: 0.1, Steps: 1000, Reward: 164.56801978037566, Best reward: 281.8536200069608, Avg reward: 12.280582973007235\n","Episode: 408, Epsilon: 0.1, Steps: 1000, Reward: -45.14200343779386, Best reward: 281.8536200069608, Avg reward: 10.143319024788504\n","Episode: 409, Epsilon: 0.1, Steps: 1000, Reward: -69.15074002345007, Best reward: 281.8536200069608, Avg reward: 10.41203908433273\n","Episode: 410, Epsilon: 0.1, Steps: 1000, Reward: -67.23484369523092, Best reward: 281.8536200069608, Avg reward: 9.40590635550676\n","Episode: 411, Epsilon: 0.1, Steps: 539, Reward: 235.0145627519245, Best reward: 281.8536200069608, Avg reward: 13.505555334794808\n","Episode: 412, Epsilon: 0.1, Steps: 1000, Reward: -66.05080902331113, Best reward: 281.8536200069608, Avg reward: 11.749359217483928\n","Episode: 413, Epsilon: 0.1, Steps: 357, Reward: 210.8842148718473, Best reward: 281.8536200069608, Avg reward: 14.061625340829748\n","Episode: 414, Epsilon: 0.1, Steps: 1000, Reward: -82.46567423335226, Best reward: 281.8536200069608, Avg reward: 13.786457721439447\n","Episode: 415, Epsilon: 0.1, Steps: 425, Reward: 249.61030234307574, Best reward: 281.8536200069608, Avg reward: 16.36438274707976\n","Episode: 416, Epsilon: 0.1, Steps: 1000, Reward: 38.78952724846768, Best reward: 281.8536200069608, Avg reward: 18.161800961568655\n","Episode: 417, Epsilon: 0.1, Steps: 166, Reward: -8.075229897112735, Best reward: 281.8536200069608, Avg reward: 16.048536555665883\n","Episode: 418, Epsilon: 0.1, Steps: 246, Reward: 308.2195679132127, Best reward: 281.8536200069608, Avg reward: 19.705413206083886\n","... models saved successfully ...\n","Episode: 419, Epsilon: 0.1, Steps: 1000, Reward: -31.41752354115329, Best reward: 308.2195679132127, Avg reward: 19.856209035111686\n","Episode: 420, Epsilon: 0.1, Steps: 215, Reward: 20.289108766249782, Best reward: 308.2195679132127, Avg reward: 20.725754945153962\n","Episode: 421, Epsilon: 0.1, Steps: 307, Reward: 301.7958274140954, Best reward: 308.2195679132127, Avg reward: 23.913201055262135\n","Episode: 422, Epsilon: 0.1, Steps: 506, Reward: 240.08570866144333, Best reward: 308.2195679132127, Avg reward: 24.51774802920279\n","Episode: 423, Epsilon: 0.1, Steps: 465, Reward: 226.1578020143428, Best reward: 308.2195679132127, Avg reward: 27.915178829758908\n","Episode: 424, Epsilon: 0.1, Steps: 471, Reward: 216.08607347101724, Best reward: 308.2195679132127, Avg reward: 30.503838569048742\n","Episode: 425, Epsilon: 0.1, Steps: 1000, Reward: -66.81398800924914, Best reward: 308.2195679132127, Avg reward: 29.41743596677047\n","Episode: 426, Epsilon: 0.1, Steps: 401, Reward: 235.64804223651194, Best reward: 308.2195679132127, Avg reward: 32.68509026516949\n","Episode: 427, Epsilon: 0.1, Steps: 1000, Reward: 23.523242160941663, Best reward: 308.2195679132127, Avg reward: 33.75854534067352\n","Episode: 428, Epsilon: 0.1, Steps: 1000, Reward: 90.22412563303678, Best reward: 308.2195679132127, Avg reward: 36.18695019354951\n","Episode: 429, Epsilon: 0.1, Steps: 824, Reward: 168.13719413995625, Best reward: 308.2195679132127, Avg reward: 36.67913954247453\n","Episode: 430, Epsilon: 0.1, Steps: 789, Reward: 176.10798921755978, Best reward: 308.2195679132127, Avg reward: 37.535735384006855\n","Episode: 431, Epsilon: 0.1, Steps: 247, Reward: 12.205700689645965, Best reward: 308.2195679132127, Avg reward: 37.65897001568195\n","Episode: 432, Epsilon: 0.1, Steps: 1000, Reward: -39.61705572690382, Best reward: 308.2195679132127, Avg reward: 39.08176510447774\n","Episode: 433, Epsilon: 0.1, Steps: 1000, Reward: -47.240005039084025, Best reward: 308.2195679132127, Avg reward: 40.17592635377243\n","Episode: 434, Epsilon: 0.1, Steps: 282, Reward: 252.89240606355622, Best reward: 308.2195679132127, Avg reward: 42.893580730035325\n","Episode: 435, Epsilon: 0.1, Steps: 957, Reward: 159.65420565909147, Best reward: 308.2195679132127, Avg reward: 44.89133178026352\n","Episode: 436, Epsilon: 0.1, Steps: 1000, Reward: -25.140524929261122, Best reward: 308.2195679132127, Avg reward: 43.28754472272999\n","Episode: 437, Epsilon: 0.1, Steps: 1000, Reward: -26.85995534096997, Best reward: 308.2195679132127, Avg reward: 42.95892618968939\n","Episode: 438, Epsilon: 0.1, Steps: 1000, Reward: 51.96288339115246, Best reward: 308.2195679132127, Avg reward: 42.26101088177401\n","Episode: 439, Epsilon: 0.1, Steps: 951, Reward: 85.00388019013987, Best reward: 308.2195679132127, Avg reward: 42.632302005412384\n","Episode: 440, Epsilon: 0.1, Steps: 684, Reward: 222.8665791505222, Best reward: 308.2195679132127, Avg reward: 42.823701396460066\n","Episode: 441, Epsilon: 0.1, Steps: 207, Reward: -2.547037023831166, Best reward: 308.2195679132127, Avg reward: 41.63921085116146\n","Episode: 442, Epsilon: 0.1, Steps: 884, Reward: 88.02528218271463, Best reward: 308.2195679132127, Avg reward: 43.43386490247798\n","Episode: 443, Epsilon: 0.1, Steps: 738, Reward: 142.46684274267793, Best reward: 308.2195679132127, Avg reward: 44.0064612780748\n","Episode: 444, Epsilon: 0.1, Steps: 769, Reward: 171.49202457924017, Best reward: 308.2195679132127, Avg reward: 45.16518294207451\n","Episode: 445, Epsilon: 0.1, Steps: 176, Reward: -194.50848770721885, Best reward: 308.2195679132127, Avg reward: 41.686769450777405\n","Episode: 446, Epsilon: 0.1, Steps: 499, Reward: 208.37557449374916, Best reward: 308.2195679132127, Avg reward: 43.73275565394194\n","Episode: 447, Epsilon: 0.1, Steps: 902, Reward: 175.67968293059113, Best reward: 308.2195679132127, Avg reward: 44.20000191822871\n","Episode: 448, Epsilon: 0.1, Steps: 167, Reward: -198.94264685906768, Best reward: 308.2195679132127, Avg reward: 41.75903089294754\n","Episode: 449, Epsilon: 0.1, Steps: 316, Reward: 274.1287845183658, Best reward: 308.2195679132127, Avg reward: 42.51727649237019\n","Episode: 450, Epsilon: 0.1, Steps: 275, Reward: 310.2183089855056, Best reward: 308.2195679132127, Avg reward: 44.332474922838145\n","... models saved successfully ...\n","Episode: 451, Epsilon: 0.1, Steps: 896, Reward: 134.8377209558821, Best reward: 310.2183089855056, Avg reward: 45.400514674109964\n","Episode: 452, Epsilon: 0.1, Steps: 1000, Reward: -7.875731976828654, Best reward: 310.2183089855056, Avg reward: 42.84084367223682\n","Episode: 453, Epsilon: 0.1, Steps: 747, Reward: 135.27620458763002, Best reward: 310.2183089855056, Avg reward: 42.25550275530668\n","Episode: 454, Epsilon: 0.1, Steps: 826, Reward: 121.38750452278121, Best reward: 310.2183089855056, Avg reward: 43.27692248224674\n","Episode: 455, Epsilon: 0.1, Steps: 157, Reward: -0.4016647949536747, Best reward: 310.2183089855056, Avg reward: 44.00894628306736\n","Episode: 456, Epsilon: 0.1, Steps: 1000, Reward: 0.9652635346716663, Best reward: 310.2183089855056, Avg reward: 44.356253991844184\n","Episode: 457, Epsilon: 0.1, Steps: 933, Reward: 105.38557440789842, Best reward: 310.2183089855056, Avg reward: 45.549839768222945\n","Episode: 458, Epsilon: 0.1, Steps: 292, Reward: 252.46307652266665, Best reward: 310.2183089855056, Avg reward: 46.56391405795347\n","Episode: 459, Epsilon: 0.1, Steps: 414, Reward: 284.12360000579963, Best reward: 310.2183089855056, Avg reward: 49.72859222280636\n","Episode: 460, Epsilon: 0.1, Steps: 331, Reward: 224.0208408061873, Best reward: 310.2183089855056, Avg reward: 50.753920693876665\n","Episode: 461, Epsilon: 0.1, Steps: 852, Reward: 177.23637364303647, Best reward: 310.2183089855056, Avg reward: 52.143961061032726\n","Episode: 462, Epsilon: 0.1, Steps: 430, Reward: 238.41142604131937, Best reward: 310.2183089855056, Avg reward: 54.854696312449924\n","Episode: 463, Epsilon: 0.1, Steps: 534, Reward: 219.95658133807032, Best reward: 310.2183089855056, Avg reward: 57.84735407127206\n","Episode: 464, Epsilon: 0.1, Steps: 503, Reward: 243.3139208258093, Best reward: 310.2183089855056, Avg reward: 60.01268628590375\n","Episode: 465, Epsilon: 0.1, Steps: 828, Reward: 172.29418494378646, Best reward: 310.2183089855056, Avg reward: 59.300721856010625\n","Episode: 466, Epsilon: 0.1, Steps: 269, Reward: 310.0196639386627, Best reward: 310.2183089855056, Avg reward: 62.782715885031685\n","Episode: 467, Epsilon: 0.1, Steps: 878, Reward: 140.00660514276228, Best reward: 310.2183089855056, Avg reward: 64.75713804708472\n","Episode: 468, Epsilon: 0.1, Steps: 1000, Reward: 11.103575777253619, Best reward: 310.2183089855056, Avg reward: 64.86196335202072\n","Episode: 469, Epsilon: 0.1, Steps: 1000, Reward: 72.65331174727702, Best reward: 310.2183089855056, Avg reward: 65.95427024437257\n","Episode: 470, Epsilon: 0.1, Steps: 1000, Reward: 0.7327659986112338, Best reward: 310.2183089855056, Avg reward: 66.63270293361327\n","Episode: 471, Epsilon: 0.1, Steps: 282, Reward: 209.71144991405012, Best reward: 310.2183089855056, Avg reward: 68.82181782157157\n","Episode: 472, Epsilon: 0.1, Steps: 1000, Reward: 40.56845421052231, Best reward: 310.2183089855056, Avg reward: 69.88585180986279\n","Episode: 473, Epsilon: 0.1, Steps: 737, Reward: 259.0802032724769, Best reward: 310.2183089855056, Avg reward: 72.87553412961257\n","Episode: 474, Epsilon: 0.1, Steps: 762, Reward: 181.04135278142695, Best reward: 310.2183089855056, Avg reward: 75.51391016400196\n","Episode: 475, Epsilon: 0.1, Steps: 1000, Reward: -14.188378882741358, Best reward: 310.2183089855056, Avg reward: 76.13998264805386\n","Episode: 476, Epsilon: 0.1, Steps: 1000, Reward: 13.923383614019759, Best reward: 310.2183089855056, Avg reward: 76.57274809801562\n","Episode: 477, Epsilon: 0.1, Steps: 380, Reward: 269.0948963585736, Best reward: 310.2183089855056, Avg reward: 79.98545211771042\n","Episode: 478, Epsilon: 0.1, Steps: 393, Reward: 268.0192755051653, Best reward: 310.2183089855056, Avg reward: 82.2722833833842\n","Episode: 479, Epsilon: 0.1, Steps: 577, Reward: 211.94938196115498, Best reward: 310.2183089855056, Avg reward: 84.5845375682934\n","Episode: 480, Epsilon: 0.1, Steps: 928, Reward: 159.30224170259032, Best reward: 310.2183089855056, Avg reward: 87.77385090442647\n","Episode: 481, Epsilon: 0.1, Steps: 802, Reward: 156.527824382354, Best reward: 310.2183089855056, Avg reward: 90.12345083112851\n","Episode: 482, Epsilon: 0.1, Steps: 957, Reward: 147.56888728141155, Best reward: 310.2183089855056, Avg reward: 92.5021253102874\n","Episode: 483, Epsilon: 0.1, Steps: 589, Reward: 254.9041717875335, Best reward: 310.2183089855056, Avg reward: 95.99460822047953\n","Episode: 484, Epsilon: 0.1, Steps: 470, Reward: 254.19494596632387, Best reward: 310.2183089855056, Avg reward: 99.31301553160445\n","Episode: 485, Epsilon: 0.1, Steps: 435, Reward: 203.00199526748975, Best reward: 310.2183089855056, Avg reward: 103.04053689900574\n","Episode: 486, Epsilon: 0.1, Steps: 829, Reward: 173.3239079887668, Best reward: 310.2183089855056, Avg reward: 105.35760516694044\n","Episode: 487, Epsilon: 0.1, Steps: 567, Reward: 172.9659622433871, Best reward: 310.2183089855056, Avg reward: 108.3440124205546\n","Episode: 488, Epsilon: 0.1, Steps: 822, Reward: 139.87942583143882, Best reward: 310.2183089855056, Avg reward: 107.01356648704656\n","Episode: 489, Epsilon: 0.1, Steps: 663, Reward: 161.96771317118908, Best reward: 310.2183089855056, Avg reward: 109.40459131813336\n","Episode: 490, Epsilon: 0.1, Steps: 645, Reward: 247.71859620603504, Best reward: 310.2183089855056, Avg reward: 112.76562634100948\n","Episode: 491, Epsilon: 0.1, Steps: 778, Reward: 122.68395451961703, Best reward: 310.2183089855056, Avg reward: 114.66760314284316\n","Episode: 492, Epsilon: 0.1, Steps: 717, Reward: 144.321182507051, Best reward: 310.2183089855056, Avg reward: 116.336822086424\n","Episode: 493, Epsilon: 0.1, Steps: 615, Reward: 227.8594635032502, Best reward: 310.2183089855056, Avg reward: 116.03581276104516\n","Episode: 494, Epsilon: 0.1, Steps: 595, Reward: 203.87730686959412, Best reward: 310.2183089855056, Avg reward: 118.84993425001498\n","Episode: 495, Epsilon: 0.1, Steps: 447, Reward: 242.77217810669134, Best reward: 310.2183089855056, Avg reward: 121.2174140958514\n","Episode: 496, Epsilon: 0.1, Steps: 660, Reward: 175.16668062347193, Best reward: 310.2183089855056, Avg reward: 123.78736094373271\n","Episode: 497, Epsilon: 0.1, Steps: 825, Reward: 172.5027373817332, Best reward: 310.2183089855056, Avg reward: 122.69385211748046\n","Episode: 498, Epsilon: 0.1, Steps: 417, Reward: 245.04129818448416, Best reward: 310.2183089855056, Avg reward: 125.7088355114859\n","Episode: 499, Epsilon: 0.1, Steps: 488, Reward: 252.44111405352783, Best reward: 310.2183089855056, Avg reward: 128.49398285868855\n","Episode: 500, Epsilon: 0.1, Steps: 706, Reward: 182.11169611194737, Best reward: 310.2183089855056, Avg reward: 130.9131243144258\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x5b96600] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 501, Epsilon: 0.1, Steps: 673, Reward: 183.03148030814828, Best reward: 310.2183089855056, Avg reward: 130.33498275651348\n","Episode: 502, Epsilon: 0.1, Steps: 919, Reward: 159.444711641761, Best reward: 310.2183089855056, Avg reward: 129.3816553499082\n","Episode: 503, Epsilon: 0.1, Steps: 554, Reward: 200.58721967130268, Best reward: 310.2183089855056, Avg reward: 128.83249247827345\n","Episode: 504, Epsilon: 0.1, Steps: 818, Reward: 197.70678177328637, Best reward: 310.2183089855056, Avg reward: 131.37027758427178\n","Episode: 505, Epsilon: 0.1, Steps: 409, Reward: 230.2222592477486, Best reward: 310.2183089855056, Avg reward: 134.04647812337925\n","Episode: 506, Epsilon: 0.1, Steps: 626, Reward: 227.58010647138377, Best reward: 310.2183089855056, Avg reward: 136.0272359922051\n","Episode: 507, Epsilon: 0.1, Steps: 729, Reward: 188.60103586431643, Best reward: 310.2183089855056, Avg reward: 136.2675661530445\n","Episode: 508, Epsilon: 0.1, Steps: 892, Reward: 124.94836150487139, Best reward: 310.2183089855056, Avg reward: 137.96846980247116\n","Episode: 509, Epsilon: 0.1, Steps: 642, Reward: 204.25005750750552, Best reward: 310.2183089855056, Avg reward: 140.70247777778073\n","Episode: 510, Epsilon: 0.1, Steps: 359, Reward: 282.95681252278087, Best reward: 310.2183089855056, Avg reward: 144.20439433996086\n","Episode: 511, Epsilon: 0.1, Steps: 357, Reward: 273.75812667013577, Best reward: 310.2183089855056, Avg reward: 144.59182997914297\n","Episode: 512, Epsilon: 0.1, Steps: 680, Reward: 152.6583165559888, Best reward: 310.2183089855056, Avg reward: 146.778921234936\n","Episode: 513, Epsilon: 0.1, Steps: 1000, Reward: 3.764462136531944, Best reward: 310.2183089855056, Avg reward: 144.70772370758283\n","Episode: 514, Epsilon: 0.1, Steps: 405, Reward: 279.673405853704, Best reward: 310.2183089855056, Avg reward: 148.32911450845342\n","Episode: 515, Epsilon: 0.1, Steps: 381, Reward: 235.01864254612423, Best reward: 310.2183089855056, Avg reward: 148.18319791048384\n","Episode: 516, Epsilon: 0.1, Steps: 260, Reward: -46.749592133329124, Best reward: 310.2183089855056, Avg reward: 147.3278067166659\n","Episode: 517, Epsilon: 0.1, Steps: 516, Reward: 289.57823430278034, Best reward: 310.2183089855056, Avg reward: 150.30434135866483\n","Episode: 518, Epsilon: 0.1, Steps: 314, Reward: 304.8277973542009, Best reward: 310.2183089855056, Avg reward: 150.2704236530747\n","Episode: 519, Epsilon: 0.1, Steps: 896, Reward: 143.96250499505683, Best reward: 310.2183089855056, Avg reward: 152.0242239384368\n","Episode: 520, Epsilon: 0.1, Steps: 530, Reward: 211.33147766590065, Best reward: 310.2183089855056, Avg reward: 153.9346476274333\n","Episode: 521, Epsilon: 0.1, Steps: 1000, Reward: 74.91248944206376, Best reward: 310.2183089855056, Avg reward: 151.665814247713\n","Episode: 522, Epsilon: 0.1, Steps: 460, Reward: 208.72630445685687, Best reward: 310.2183089855056, Avg reward: 151.35222020566712\n","Episode: 523, Epsilon: 0.1, Steps: 696, Reward: 189.04568251608296, Best reward: 310.2183089855056, Avg reward: 150.98109901068455\n","Episode: 524, Epsilon: 0.1, Steps: 362, Reward: 253.95882975155652, Best reward: 310.2183089855056, Avg reward: 151.35982657348993\n","Episode: 525, Epsilon: 0.1, Steps: 428, Reward: 228.32552371581932, Best reward: 310.2183089855056, Avg reward: 154.3112216907406\n","Episode: 526, Epsilon: 0.1, Steps: 1000, Reward: 41.303758702513164, Best reward: 310.2183089855056, Avg reward: 152.36777885540062\n","Episode: 527, Epsilon: 0.1, Steps: 543, Reward: 238.4744496756329, Best reward: 310.2183089855056, Avg reward: 154.51729093054752\n","Episode: 528, Epsilon: 0.1, Steps: 399, Reward: 185.90356050116048, Best reward: 310.2183089855056, Avg reward: 155.47408527922877\n","Episode: 529, Epsilon: 0.1, Steps: 537, Reward: 170.6622252487025, Best reward: 310.2183089855056, Avg reward: 155.49933559031624\n","Episode: 530, Epsilon: 0.1, Steps: 428, Reward: 216.39716750794895, Best reward: 310.2183089855056, Avg reward: 155.90222737322011\n","Episode: 531, Epsilon: 0.1, Steps: 389, Reward: 233.42489510320405, Best reward: 310.2183089855056, Avg reward: 158.11441931735573\n","Episode: 532, Epsilon: 0.1, Steps: 712, Reward: 96.24068064504414, Best reward: 310.2183089855056, Avg reward: 159.47299668107516\n","Episode: 533, Epsilon: 0.1, Steps: 526, Reward: 155.89201619228191, Best reward: 310.2183089855056, Avg reward: 161.50431689338882\n","Episode: 534, Epsilon: 0.1, Steps: 182, Reward: 5.86314337676194, Best reward: 310.2183089855056, Avg reward: 159.0340242665209\n","Episode: 535, Epsilon: 0.1, Steps: 509, Reward: 209.453411564134, Best reward: 310.2183089855056, Avg reward: 159.53201632557133\n","Episode: 536, Epsilon: 0.1, Steps: 342, Reward: 259.65780961610034, Best reward: 310.2183089855056, Avg reward: 162.37999967102493\n","Episode: 537, Epsilon: 0.1, Steps: 373, Reward: -2.251259495092114, Best reward: 310.2183089855056, Avg reward: 162.62608662948375\n","Episode: 538, Epsilon: 0.1, Steps: 431, Reward: 165.26525905416133, Best reward: 310.2183089855056, Avg reward: 163.75911038611383\n","Episode: 539, Epsilon: 0.1, Steps: 126, Reward: -28.19199099116669, Best reward: 310.2183089855056, Avg reward: 162.62715167430076\n","Episode: 540, Epsilon: 0.1, Steps: 461, Reward: 230.06168483220296, Best reward: 310.2183089855056, Avg reward: 162.69910273111756\n","Episode: 541, Epsilon: 0.1, Steps: 278, Reward: 167.06934430533738, Best reward: 310.2183089855056, Avg reward: 164.39526654440925\n","Episode: 542, Epsilon: 0.1, Steps: 438, Reward: 206.8160582861231, Best reward: 310.2183089855056, Avg reward: 165.58317430544332\n","Episode: 543, Epsilon: 0.1, Steps: 566, Reward: 229.62817108964316, Best reward: 310.2183089855056, Avg reward: 166.45478758891295\n","Episode: 544, Epsilon: 0.1, Steps: 303, Reward: 215.69739231505173, Best reward: 310.2183089855056, Avg reward: 166.89684126627108\n","Episode: 545, Epsilon: 0.1, Steps: 452, Reward: 243.47700667776323, Best reward: 310.2183089855056, Avg reward: 171.2766962101209\n","Episode: 546, Epsilon: 0.1, Steps: 316, Reward: 216.3201992995023, Best reward: 310.2183089855056, Avg reward: 171.35614245817843\n","Episode: 547, Epsilon: 0.1, Steps: 415, Reward: 161.0375039967554, Best reward: 310.2183089855056, Avg reward: 171.20972066884005\n","Episode: 548, Epsilon: 0.1, Steps: 412, Reward: -48.04705778567972, Best reward: 310.2183089855056, Avg reward: 172.71867655957396\n","Episode: 549, Epsilon: 0.1, Steps: 341, Reward: 273.52412096108174, Best reward: 310.2183089855056, Avg reward: 172.71262992400113\n","Episode: 550, Epsilon: 0.1, Steps: 509, Reward: 208.46812545657156, Best reward: 310.2183089855056, Avg reward: 171.69512808871184\n","Episode: 551, Epsilon: 0.1, Steps: 612, Reward: 86.09184806948598, Best reward: 310.2183089855056, Avg reward: 171.20766935984787\n","Episode: 552, Epsilon: 0.1, Steps: 615, Reward: 209.1460027133907, Best reward: 310.2183089855056, Avg reward: 173.37788670675008\n","Episode: 553, Epsilon: 0.1, Steps: 160, Reward: -26.15811895592688, Best reward: 310.2183089855056, Avg reward: 171.76354347131448\n","Episode: 554, Epsilon: 0.1, Steps: 400, Reward: 200.82279718507422, Best reward: 310.2183089855056, Avg reward: 172.5578963979374\n","Episode: 555, Epsilon: 0.1, Steps: 509, Reward: 143.79630834103466, Best reward: 310.2183089855056, Avg reward: 173.9998761292973\n","Episode: 556, Epsilon: 0.1, Steps: 338, Reward: 245.69940138709242, Best reward: 310.2183089855056, Avg reward: 176.4472175078215\n","Episode: 557, Epsilon: 0.1, Steps: 411, Reward: 229.0748066266846, Best reward: 310.2183089855056, Avg reward: 177.6841098300094\n","Episode: 558, Epsilon: 0.1, Steps: 389, Reward: 200.95252068907854, Best reward: 310.2183089855056, Avg reward: 177.1690042716735\n","Episode: 559, Epsilon: 0.1, Steps: 428, Reward: 196.60696677186812, Best reward: 310.2183089855056, Avg reward: 176.2938379393342\n","Episode: 560, Epsilon: 0.1, Steps: 82, Reward: -28.17418321156015, Best reward: 310.2183089855056, Avg reward: 173.77188769915674\n","Episode: 561, Epsilon: 0.1, Steps: 453, Reward: 194.07298369080564, Best reward: 310.2183089855056, Avg reward: 173.9402537996344\n","Episode: 562, Epsilon: 0.1, Steps: 342, Reward: 236.56320872175647, Best reward: 310.2183089855056, Avg reward: 173.92177162643875\n","Episode: 563, Epsilon: 0.1, Steps: 316, Reward: 188.098004368634, Best reward: 310.2183089855056, Avg reward: 173.60318585674435\n","Episode: 564, Epsilon: 0.1, Steps: 238, Reward: 184.4019521145112, Best reward: 310.2183089855056, Avg reward: 173.01406616963138\n","Episode: 565, Epsilon: 0.1, Steps: 363, Reward: 247.54844842751032, Best reward: 310.2183089855056, Avg reward: 173.76660880446863\n","Episode: 566, Epsilon: 0.1, Steps: 355, Reward: 243.82288785215533, Best reward: 310.2183089855056, Avg reward: 173.10464104360355\n","Episode: 567, Epsilon: 0.1, Steps: 517, Reward: 184.74801178414467, Best reward: 310.2183089855056, Avg reward: 173.5520551100174\n","Episode: 568, Epsilon: 0.1, Steps: 369, Reward: 192.93040483970245, Best reward: 310.2183089855056, Avg reward: 175.37032340064187\n","Episode: 569, Epsilon: 0.1, Steps: 322, Reward: 249.04335249061955, Best reward: 310.2183089855056, Avg reward: 177.13422380807526\n","Episode: 570, Epsilon: 0.1, Steps: 557, Reward: 198.4299736421902, Best reward: 310.2183089855056, Avg reward: 179.11119588451103\n","Episode: 571, Epsilon: 0.1, Steps: 693, Reward: 191.30090289172233, Best reward: 310.2183089855056, Avg reward: 178.9270904142878\n","Episode: 572, Epsilon: 0.1, Steps: 416, Reward: 250.34369656712173, Best reward: 310.2183089855056, Avg reward: 181.02484283785373\n","Episode: 573, Epsilon: 0.1, Steps: 571, Reward: 136.36771561458494, Best reward: 310.2183089855056, Avg reward: 179.79771796127483\n","Episode: 574, Epsilon: 0.1, Steps: 501, Reward: 274.79841281289987, Best reward: 310.2183089855056, Avg reward: 180.73528856158958\n","Episode: 575, Epsilon: 0.1, Steps: 290, Reward: 186.99776685101665, Best reward: 310.2183089855056, Avg reward: 182.74715001892716\n","Episode: 576, Epsilon: 0.1, Steps: 546, Reward: 165.0114636434725, Best reward: 310.2183089855056, Avg reward: 184.25803081922172\n","Episode: 577, Epsilon: 0.1, Steps: 513, Reward: 187.8933806437155, Best reward: 310.2183089855056, Avg reward: 183.44601566207314\n","Episode: 578, Epsilon: 0.1, Steps: 1000, Reward: 83.70795468539208, Best reward: 310.2183089855056, Avg reward: 181.60290245387543\n","Episode: 579, Epsilon: 0.1, Steps: 1000, Reward: 123.41315217541218, Best reward: 310.2183089855056, Avg reward: 180.717540156018\n","Episode: 580, Epsilon: 0.1, Steps: 367, Reward: 245.1736800561855, Best reward: 310.2183089855056, Avg reward: 181.57625453955393\n","Episode: 581, Epsilon: 0.1, Steps: 381, Reward: 197.89230813347712, Best reward: 310.2183089855056, Avg reward: 181.98989937706517\n","Episode: 582, Epsilon: 0.1, Steps: 334, Reward: 188.73153174330702, Best reward: 310.2183089855056, Avg reward: 182.4015258216841\n","Episode: 583, Epsilon: 0.1, Steps: 1000, Reward: 76.7052609420931, Best reward: 310.2183089855056, Avg reward: 180.61953671322968\n","Episode: 584, Epsilon: 0.1, Steps: 446, Reward: 175.87164099042545, Best reward: 310.2183089855056, Avg reward: 179.83630366347072\n","Episode: 585, Epsilon: 0.1, Steps: 596, Reward: 196.63122327438145, Best reward: 310.2183089855056, Avg reward: 179.77259594353964\n","Episode: 586, Epsilon: 0.1, Steps: 395, Reward: -37.61377390927046, Best reward: 310.2183089855056, Avg reward: 177.66321912455925\n","Episode: 587, Epsilon: 0.1, Steps: 264, Reward: 213.05839269962303, Best reward: 310.2183089855056, Avg reward: 178.0641434291216\n","Episode: 588, Epsilon: 0.1, Steps: 357, Reward: 208.4245828159766, Best reward: 310.2183089855056, Avg reward: 178.74959499896696\n","Episode: 589, Epsilon: 0.1, Steps: 417, Reward: 211.9854378672605, Best reward: 310.2183089855056, Avg reward: 179.24977224592772\n","Episode: 590, Epsilon: 0.1, Steps: 354, Reward: 191.57123718012735, Best reward: 310.2183089855056, Avg reward: 178.68829865566863\n","Episode: 591, Epsilon: 0.1, Steps: 256, Reward: 195.76368264521395, Best reward: 310.2183089855056, Avg reward: 179.4190959369246\n","Episode: 592, Epsilon: 0.1, Steps: 479, Reward: 245.49537579175782, Best reward: 310.2183089855056, Avg reward: 180.43083786977166\n","Episode: 593, Epsilon: 0.1, Steps: 373, Reward: 133.90516341505057, Best reward: 310.2183089855056, Avg reward: 179.49129486888967\n","Episode: 594, Epsilon: 0.1, Steps: 372, Reward: 194.59774575079973, Best reward: 310.2183089855056, Avg reward: 179.3984992577017\n","Episode: 595, Epsilon: 0.1, Steps: 285, Reward: 200.32927861888015, Best reward: 310.2183089855056, Avg reward: 178.97407026282355\n","Episode: 596, Epsilon: 0.1, Steps: 396, Reward: 184.21881534206165, Best reward: 310.2183089855056, Avg reward: 179.06459161000953\n","Episode: 597, Epsilon: 0.1, Steps: 195, Reward: -19.342394320421093, Best reward: 310.2183089855056, Avg reward: 177.14614029298795\n","Episode: 598, Epsilon: 0.1, Steps: 770, Reward: 115.93237851614121, Best reward: 310.2183089855056, Avg reward: 175.8550510963045\n","Episode: 599, Epsilon: 0.1, Steps: 242, Reward: -13.7619616996909, Best reward: 310.2183089855056, Avg reward: 173.1930203387723\n","Episode: 600, Epsilon: 0.1, Steps: 327, Reward: 211.51409453332906, Best reward: 310.2183089855056, Avg reward: 173.48704432298615\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x705a200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 601, Epsilon: 0.1, Steps: 568, Reward: 187.2183726480913, Best reward: 310.2183089855056, Avg reward: 173.52891324638557\n","Episode: 602, Epsilon: 0.1, Steps: 651, Reward: 106.31213725794548, Best reward: 310.2183089855056, Avg reward: 172.9975875025474\n","Episode: 603, Epsilon: 0.1, Steps: 333, Reward: -47.39581315264374, Best reward: 310.2183089855056, Avg reward: 170.51775717430795\n","Episode: 604, Epsilon: 0.1, Steps: 411, Reward: 221.08141818762942, Best reward: 310.2183089855056, Avg reward: 170.7515035384514\n","Episode: 605, Epsilon: 0.1, Steps: 518, Reward: 188.8394109642954, Best reward: 310.2183089855056, Avg reward: 170.33767505561684\n","Episode: 606, Epsilon: 0.1, Steps: 509, Reward: 265.7704646733124, Best reward: 310.2183089855056, Avg reward: 170.71957863763615\n","Episode: 607, Epsilon: 0.1, Steps: 1000, Reward: 120.21131940308881, Best reward: 310.2183089855056, Avg reward: 170.03568147302386\n","Episode: 608, Epsilon: 0.1, Steps: 485, Reward: 192.86360694632737, Best reward: 310.2183089855056, Avg reward: 170.71483392743846\n","Episode: 609, Epsilon: 0.1, Steps: 351, Reward: 178.989615842148, Best reward: 310.2183089855056, Avg reward: 170.46222951078488\n","Episode: 610, Epsilon: 0.1, Steps: 1000, Reward: 100.34485939228207, Best reward: 310.2183089855056, Avg reward: 168.63610997947987\n","Episode: 611, Epsilon: 0.1, Steps: 305, Reward: 245.0943575549669, Best reward: 310.2183089855056, Avg reward: 168.34947228832823\n","Episode: 612, Epsilon: 0.1, Steps: 258, Reward: 232.7092505199517, Best reward: 310.2183089855056, Avg reward: 169.14998162796783\n","Episode: 613, Epsilon: 0.1, Steps: 731, Reward: 144.9155318941627, Best reward: 310.2183089855056, Avg reward: 170.56149232554412\n","Episode: 614, Epsilon: 0.1, Steps: 293, Reward: 229.85367169394846, Best reward: 310.2183089855056, Avg reward: 170.0632949839466\n","Episode: 615, Epsilon: 0.1, Steps: 473, Reward: 173.78701246120403, Best reward: 310.2183089855056, Avg reward: 169.4509786830974\n","Episode: 616, Epsilon: 0.1, Steps: 187, Reward: 37.56420433802924, Best reward: 310.2183089855056, Avg reward: 170.294116647811\n","Episode: 617, Epsilon: 0.1, Steps: 517, Reward: 193.6668911863116, Best reward: 310.2183089855056, Avg reward: 169.3350032166463\n","Episode: 618, Epsilon: 0.1, Steps: 515, Reward: 144.22615392571294, Best reward: 310.2183089855056, Avg reward: 167.72898678236143\n","Episode: 619, Epsilon: 0.1, Steps: 403, Reward: 247.26512112290217, Best reward: 310.2183089855056, Avg reward: 168.76201294363986\n","Episode: 620, Epsilon: 0.1, Steps: 172, Reward: 26.900333546772146, Best reward: 310.2183089855056, Avg reward: 166.91770150244855\n","Episode: 621, Epsilon: 0.1, Steps: 354, Reward: 178.6488521442594, Best reward: 310.2183089855056, Avg reward: 167.95506512947048\n","Episode: 622, Epsilon: 0.1, Steps: 213, Reward: 20.666066954455445, Best reward: 310.2183089855056, Avg reward: 166.0744627544465\n","Episode: 623, Epsilon: 0.1, Steps: 325, Reward: 279.944527638026, Best reward: 310.2183089855056, Avg reward: 166.98345120566592\n","Episode: 624, Epsilon: 0.1, Steps: 1000, Reward: 39.48753987333942, Best reward: 310.2183089855056, Avg reward: 164.83873830688376\n","Episode: 625, Epsilon: 0.1, Steps: 429, Reward: 159.0379086813241, Best reward: 310.2183089855056, Avg reward: 164.1458621565388\n","Episode: 626, Epsilon: 0.1, Steps: 1000, Reward: 30.671691917133227, Best reward: 310.2183089855056, Avg reward: 164.03954148868502\n","Episode: 627, Epsilon: 0.1, Steps: 326, Reward: 189.88491363053828, Best reward: 310.2183089855056, Avg reward: 163.55364612823408\n","Episode: 628, Epsilon: 0.1, Steps: 201, Reward: -28.335482630291708, Best reward: 310.2183089855056, Avg reward: 161.41125569691957\n","Episode: 629, Epsilon: 0.1, Steps: 338, Reward: 249.17982821751343, Best reward: 310.2183089855056, Avg reward: 162.19643172660767\n","Episode: 630, Epsilon: 0.1, Steps: 217, Reward: 45.12793634033886, Best reward: 310.2183089855056, Avg reward: 160.48373941493156\n","Episode: 631, Epsilon: 0.1, Steps: 415, Reward: 194.13122435896756, Best reward: 310.2183089855056, Avg reward: 160.0908027074892\n","Episode: 632, Epsilon: 0.1, Steps: 548, Reward: 211.83721770642842, Best reward: 310.2183089855056, Avg reward: 161.24676807810303\n","Episode: 633, Epsilon: 0.1, Steps: 912, Reward: 132.31904127326504, Best reward: 310.2183089855056, Avg reward: 161.01103832891286\n","Episode: 634, Epsilon: 0.1, Steps: 394, Reward: 193.1959505838504, Best reward: 310.2183089855056, Avg reward: 162.88436640098374\n","Episode: 635, Epsilon: 0.1, Steps: 296, Reward: -50.90543095927285, Best reward: 310.2183089855056, Avg reward: 160.2807779757497\n","Episode: 636, Epsilon: 0.1, Steps: 531, Reward: 173.9695281605889, Best reward: 310.2183089855056, Avg reward: 159.4238951611946\n","Episode: 637, Epsilon: 0.1, Steps: 560, Reward: 153.49676631396304, Best reward: 310.2183089855056, Avg reward: 160.98137541928511\n","Episode: 638, Epsilon: 0.1, Steps: 702, Reward: 218.3459153634089, Best reward: 310.2183089855056, Avg reward: 161.5121819823776\n","Episode: 639, Epsilon: 0.1, Steps: 1000, Reward: -36.933925879850776, Best reward: 310.2183089855056, Avg reward: 161.42476263349076\n","Episode: 640, Epsilon: 0.1, Steps: 452, Reward: 195.45327461859767, Best reward: 310.2183089855056, Avg reward: 161.0786785313547\n","Episode: 641, Epsilon: 0.1, Steps: 203, Reward: 1.2735438183122625, Best reward: 310.2183089855056, Avg reward: 159.42072052648444\n","Episode: 642, Epsilon: 0.1, Steps: 589, Reward: 147.97560137499556, Best reward: 310.2183089855056, Avg reward: 158.83231595737317\n","Episode: 643, Epsilon: 0.1, Steps: 279, Reward: 235.28569877725278, Best reward: 310.2183089855056, Avg reward: 158.88889123424926\n","Episode: 644, Epsilon: 0.1, Steps: 569, Reward: 135.730375091349, Best reward: 310.2183089855056, Avg reward: 158.08922106201223\n","Episode: 645, Epsilon: 0.1, Steps: 608, Reward: 112.0740238035582, Best reward: 310.2183089855056, Avg reward: 156.7751912332702\n","Episode: 646, Epsilon: 0.1, Steps: 603, Reward: 153.24454496336242, Best reward: 310.2183089855056, Avg reward: 156.14443468990876\n","Episode: 647, Epsilon: 0.1, Steps: 789, Reward: 177.90681900762496, Best reward: 310.2183089855056, Avg reward: 156.3131278400175\n","Episode: 648, Epsilon: 0.1, Steps: 881, Reward: 83.0796994375533, Best reward: 310.2183089855056, Avg reward: 157.62439541224984\n","Episode: 649, Epsilon: 0.1, Steps: 506, Reward: 191.70854477534306, Best reward: 310.2183089855056, Avg reward: 156.80623965039246\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# in cer paper, they did'nt used decaying epsilon greedy.\n","import gymnasium as gym\n","import time\n","import signal\n","import time\n","import sys\n","import pickle\n","\n","env = make_env(\"LunarLander-v2\", \"videos/\", 50)\n","action_space = [_ for _ in range(env.action_space.n)]\n","record = True\n","\n","\n","trainer_params = {\n","    \"noe\": 650, \n","    \"max_steps\": 10000,\n","    \"max_eps\": 0.1,\n","    \"min_eps\": 0.1,\n","    \"eps_decay_rate\": 1e-5,\n","    \"eps\": 0.1,\n","    \"action_space\": action_space,\n","    \"is_tg\": True,\n","    \"tg_bot_freq_epi\": 10,\n","    \"record\": record,\n","    \"gamma\": 0.99, \n","    \"lr\": 0.0001, \n","    \"input_dims\": env.observation_space.shape,\n","    \"mem_size\" : 30000,\n","    \"batch_size\" : 32,\n","    \"replace\" : 1000,\n","    \"algo\" : \"DQN\",\n","    \"env_name\" : \"lunarlander\",\n","    \"n_actions\" : len(action_space),\n","    \"chkpt_dir\": \"tmp/dqn/\",\n","    \"actions\": action_space,\n","    \"target_score\": 230,\n","    \"tau\": 0.01,\n","    \"target_update\": 230,\n","    \"cer\": True\n","}\n","\n","    \n","if __name__ == \"__main__\": \n","    \n","    try: \n","        manage_memory()\n","       \n","        trainer = Trainer(env, trainer_params)\n","        episode_rewards, epsilon_history, avg_rewards, best_reward = trainer.train_rl_model()\n","        \n","        with open(\"dqn_episode_rewards.obj\", \"wb\") as f: \n","            pickle.dump(episode_rewards, f)\n","        \n","        with open(\"dqn_epsilon_history.obj\", \"wb\") as f: \n","            pickle.dump(epsilon_history, f)\n","        \n","        with open(\"dqn_avg_rewards.obj\", \"wb\") as f: \n","            pickle.dump(avg_rewards, f)\n","            \n","        plot_learning_curve(episode_rewards, epsilon_history, \"vanila_dqn_cer\")\n","        \n","    except Exception as error: \n","        raise error\n","        \n","   # eval_model(env, \"keras model\", \"videos/\", fps=10)\n"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T10:30:09.617454Z","iopub.status.busy":"2023-03-14T10:30:09.616390Z","iopub.status.idle":"2023-03-14T10:30:09.631940Z","shell.execute_reply":"2023-03-14T10:30:09.630842Z","shell.execute_reply.started":"2023-03-14T10:30:09.617415Z"},"trusted":true},"outputs":[],"source":["import gymnasium as gym\n","import time\n","\n","env = make_env(\"LunarLander-v2\", \"videos/\", 50)\n","action_space = [_ for _ in range(env.action_space.n)]\n","\n","import random \n","import imageio\n","\n","def eval_model(env, model, out_directory, fps=20):\n","    images = []  \n","    done = False\n","    state = env.reset(seed=random.randint(0,500))\n","    img = env.render()\n","    images.append(img)\n","    rewards = 0 \n","    while not done:\n","        if type(state) == tuple: \n","            state = state[0].astype(\"float32\")\n","        action = greedy_policy(state, model, action_space)\n","        state, reward, done, info, _ = env.step(action) \n","        rewards += reward\n","        \n","        img = env.render()\n","        images.append(img)\n","    imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n","    return rewards"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2023-03-14T10:31:33.502268Z","iopub.status.busy":"2023-03-14T10:31:33.501273Z","iopub.status.idle":"2023-03-14T10:31:44.325575Z","shell.execute_reply":"2023-03-14T10:31:44.324194Z","shell.execute_reply.started":"2023-03-14T10:31:33.502225Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x640c200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"data":{"text/plain":["114.46160243925621"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["model = tf.keras.models.load_model(\"/kaggle/working/tmp/dqn/lunarlander_DQN_q_value_cer\")\n","rewards = eval_model(env, model, \"video.mp4\", fps=30)\n","rewards"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
