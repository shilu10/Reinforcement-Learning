{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-15T06:47:17.817095Z","iopub.status.busy":"2023-03-15T06:47:17.816070Z","iopub.status.idle":"2023-03-15T06:49:39.528684Z","shell.execute_reply":"2023-03-15T06:49:39.527468Z","shell.execute_reply.started":"2023-03-15T06:47:17.817036Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m^C\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install gymnasium[atari] --quiet\n","!pip install gymnasium --quiet\n","!pip install -U gymnasium[atari] --quiet\n","!pip install imageio_ffmpeg --quiet\n","!pip install npy_append_array --quiet\n","!pip install pyTelegramBotAPI --quiet\n","!pip install gymnasium[accept-rom-license] --quiet\n","!pip install gymnasium[box2d] --quiet"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:24.816993Z","iopub.status.busy":"2023-03-15T06:51:24.816204Z","iopub.status.idle":"2023-03-15T06:51:24.828365Z","shell.execute_reply":"2023-03-15T06:51:24.827049Z","shell.execute_reply.started":"2023-03-15T06:51:24.816925Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","\n","class ExperienceReplayBuffer: \n","    def __init__(self, max_memory, input_shape, n_actions): \n","        self.mem_size = max_memory\n","        self.mem_counter = 0\n","        self.state_memory = np.zeros((self.mem_size, *input_shape),\n","                                     dtype=np.float32)\n","        self.new_state_memory = np.zeros((self.mem_size, *input_shape),\n","                                         dtype=np.float32)\n","\n","        self.action_memory = np.zeros(self.mem_size, dtype=np.int64)\n","        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n","        self.terminal_memory = np.zeros(self.mem_size, dtype=bool)\n","\n","    def store_experience(self, state, action, reward, next_state, done): \n","        index = self.mem_counter % self.mem_size \n","\n","        self.state_memory[index] = state\n","        self.new_state_memory[index] = next_state\n","        self.reward_memory[index] = reward\n","        self.action_memory[index] = action\n","        self.terminal_memory[index] = done\n","        self.mem_counter += 1\n","        \n","\n","    def sample_experience(self, batch_size):\n","        max_mem = min(self.mem_counter, self.mem_size)\n","        batch_index = np.random.choice(max_mem, batch_size, replace=False)\n","\n","        states = self.state_memory[batch_index]\n","        next_states = self.new_state_memory[batch_index]\n","        rewards = self.reward_memory[batch_index]\n","        actions = self.action_memory[batch_index]\n","        terminal = self.terminal_memory[batch_index]\n","\n","        return states, actions, rewards, next_states, terminal\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T08:36:19.557026Z","iopub.status.busy":"2023-03-15T08:36:19.556630Z","iopub.status.idle":"2023-03-15T08:36:19.569522Z","shell.execute_reply":"2023-03-15T08:36:19.568379Z","shell.execute_reply.started":"2023-03-15T08:36:19.556986Z"},"trusted":true},"outputs":[],"source":["import tensorflow.keras as keras\n","from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPool2D, Input\n","\n","\n","class DeepQNetwork2D(keras.Model):\n","    def __init__(self, input_dims, n_actions):\n","        super(DeepQNetwork2D, self).__init__()\n","     #   self.fc1 = Dense(64, activation='relu')\n","        self.fc1 = Dense(64, activation='relu', , input_shape=input_dims)\n","        self.fc2 = Dense(64, activation='relu')\n","        self.fc3 = Dense(n_actions, activation=None)\n","\n","    def call(self, state):\n","\n","        x = self.fc1(state)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","\n","class DeepQNetwork3D(keras.Model): \n","    def __init__(self, input_dims, n_actions):\n","        super(DeepQNetwork3D, self).__init__()\n","\n","        self.conv1 = Conv2D(32, 8, strides=(4, 4), activation='relu', data_format=\"channels_first\", input_shape=input_dims)\n","        self.conv2 = Conv2D(32, 4, strides=(2, 2), activation='relu', data_format=\"channels_first\")\n","        self.conv3 = Conv2D(64, 3, strides=(1, 1), activation='relu', data_format=\"channels_first\")\n","        self.flatten = Flatten()\n","\n","        self.fc2 = Dense(128, activation='relu')\n","        self.fc3 = Dense(n_actions, activation=None)\n","\n","    def call(self, state):\n","\n","        x = self.conv1(state)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.flatten(x)\n","        \n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:25.801358Z","iopub.status.busy":"2023-03-15T06:51:25.800247Z","iopub.status.idle":"2023-03-15T06:51:25.809054Z","shell.execute_reply":"2023-03-15T06:51:25.808000Z","shell.execute_reply.started":"2023-03-15T06:51:25.801311Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","def epsilon_greedy_policy(q_val_network, observation, action_space, epsilon):\n","        if np.random.random() > epsilon:\n","            state = tf.convert_to_tensor([observation])\n","            actions = q_val_network(state, verbose=0)\n","            action = tf.math.argmax(actions, axis=1).numpy()[0]\n","        else:\n","            action = np.random.choice(action_space)\n","        return action\n","\n","\n","def greedy_policy(observation, q_val_network, action_space): \n","    state = tf.convert_to_tensor([observation])\n","    actions = q_val_network(state)\n","    action = tf.math.argmax(actions, axis=1).numpy()[0]\n","    return action\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:26.228350Z","iopub.status.busy":"2023-03-15T06:51:26.228055Z","iopub.status.idle":"2023-03-15T06:51:26.262115Z","shell.execute_reply":"2023-03-15T06:51:26.260878Z","shell.execute_reply.started":"2023-03-15T06:51:26.228321Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","\n","#https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code/blob/master/DQN/tf2/agent.py\n","class Agent: \n","    def __init__(self, agent_params):\n","        # Parameters\n","        self.gamma = agent_params.get(\"gamma\")\n","        self.lr = agent_params.get(\"lr\")\n","        self.input_dims = agent_params.get(\"input_dims\")\n","        self.batch_size = agent_params.get(\"batch_size\")\n","        self.replace_target_weight_counter = agent_params.get(\"replace\")\n","        self.algo = agent_params.get(\"algo\")\n","        self.env_name = agent_params.get(\"env_name\")\n","        self.chkpt_dir = agent_params.get(\"chkpt_dir\")\n","        self.n_actions = agent_params.get(\"n_actions\")\n","        self.action_space = agent_params.get('actions')\n","        \n","        self.eps = agent_params.get(\"eps\")\n","        self.min_eps = agent_params.get(\"min_eps\")\n","        self.eps_decay_rate = agent_params.get(\"eps_decay_rate\")\n","        \n","        self.learn_step_counter = 0\n","        self.fname = self.chkpt_dir + self.env_name + '_' + self.algo + '_'\n","        self.mem_size = agent_params.get(\"mem_size\")\n","        \n","        self.TAU = agent_params.get(\"tau\")\n","        self.soft_update = agent_params.get(\"soft_update\")\n","\n","        # networks and replaybuffer\n","        self.memory = ExperienceReplayBuffer(self.mem_size, self.input_dims, self.n_actions)\n","        self.q_value_network = DeepQNetwork2D(self.input_dims, self.n_actions) if len(self.input_dims) < 3 else \\\n","                                                        DeepQNetwork3D(self.input_dims, self.n_actions)\n","        self.q_value_network.compile(optimizer=RMSprop(lr=0.00025, rho=0.95, epsilon=0.01))\n","        self.target_q_network = DeepQNetwork2D(self.input_dims, self.n_actions) if len(self.input_dims) < 3 else \\\n","                                                        DeepQNetwork3D(self.input_dims, self.n_actions)\n","        self.target_q_network.compile(optimizer=RMSprop(lr=0.00025, rho=0.95, epsilon=0.01))\n","\n","    def save_models(self):\n","        self.q_value_network.save(self.fname+'q_value')\n","        self.target_q_network.save(self.fname+'target_q')\n","        print('... models saved successfully ...')\n","\n","    def load_models(self):\n","        self.q_value_network = keras.models.load_model(self.fname+'q_value')\n","        self.target_q_network = keras.models.load_model(self.fname+'target_q')\n","        print('... models loaded successfully ...')\n","\n","    def store_experience(self, state, action, reward, state_, done):\n","        self.memory.store_experience(state, action, reward, state_, done)\n","\n","    def sample_experience(self):\n","        state, action, reward, new_state, done = \\\n","                                  self.memory.sample_experience(self.batch_size)\n","        states = tf.convert_to_tensor(state)\n","        rewards = tf.convert_to_tensor(reward)\n","        dones = tf.convert_to_tensor(done)\n","        actions = tf.convert_to_tensor(action, dtype=tf.int32)\n","        states_ = tf.convert_to_tensor(new_state)\n","        return states, actions, rewards, states_, dones\n","\n","    def choose_action(self, observation):\n","        if np.random.random() > self.eps:\n","            state = tf.convert_to_tensor([observation])\n","            actions = self.q_value_network(state)\n","            action = tf.math.argmax(actions, axis=1).numpy()[0]\n","        else:\n","            action = np.random.choice(self.action_space)\n","        return action\n","\n","    def replace_target_network(self):\n","        if not self.soft_update:\n","            self.target_q_network.set_weights(self.q_value_network.get_weights())\n","            return\n","        else: \n","            q_model_theta = self.q_value_network.get_weights()\n","            target_model_theta = self.target_q_network.get_weights()\n","            counter = 0\n","            for q_weight, target_weight in zip(q_model_theta, target_model_theta):\n","                target_weight = target_weight * (1-self.TAU) + q_weight * self.TAU\n","                target_model_theta[counter] = target_weight\n","                counter += 1\n","            self.target_q_network.set_weights(target_model_theta)\n","    \n","    def decrement_epsilon(self): \n","        self.eps -= self.eps_decay_rate\n","        self.eps = max(self.eps, self.min_eps)\n","\n","    def learn(self):\n","\n","        if self.memory.mem_counter < self.batch_size:\n","            return\n","\n","        self.replace_target_network()\n","        \n","        states, actions, rewards, states_, dones = self.sample_experience()\n","\n","        with tf.GradientTape() as tape:\n","        \n","            q_pred = self.q_value_network(states, verbose=False)\n","            q_next_val = self.q_value_network(states_, verbose=False)\n","            \n","            q_pred, q_next_val = q_pred.numpy(), q_next_val.numpy()\n","            \n","            q_target = q_pred.copy()\n","\n","            q_eval = self.target_q_network(states_, verbose=False)\n","            max_action_ids = np.argmax(q_next_val, axis=1)\n","\n","            q_target[[np.arange(self.batch_size)], max_action_ids] = rewards[np.arange(self.batch_size)] + self.gamma * q_eval[[np.arange(self.batch_size)], max_action_ids]  * (1 - dones[np.arange(self.batch_size)])\n","            \n","            loss = keras.losses.MSE(tf.to_tensor(q_pred), tf.to_tensor(q_target))\n","        \n","        params = self.q_value_network.trainable_variables\n","        grads = tape.gradient(loss, params)\n","        self.q_value_network.optimizer.apply_gradients(zip(grads, params))\n","        \n","        self.learn_step_counter += 1\n","        self.decrement_epsilon()       "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:26.807541Z","iopub.status.busy":"2023-03-15T06:51:26.806797Z","iopub.status.idle":"2023-03-15T06:51:26.815088Z","shell.execute_reply":"2023-03-15T06:51:26.813868Z","shell.execute_reply.started":"2023-03-15T06:51:26.807500Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\ndef learn(self):\\n    if self.memory.mem_counter < self.batch_size:\\n        return\\n\\n    self.replace_target_network()\\n\\n    states, actions, rewards, states_, dones = self.sample_experience()\\n\\n    indices = tf.range(self.batch_size, dtype=tf.int32)\\n  \\n    action_indices = tf.stack([indices, actions], axis=1)\\n\\n    \\n    q_target = self.q_value_network.predict(states, verbose=False)\\n    q_next_val = self.q_value_network.predict(states_, verbose=False)\\n        \\n    q_eval = self.target_q_network.predict(states_, verbose=False)\\n    max_action_ids = np.argmax(q_next_val, axis=1)\\n        \\n    q_target[[np.arange(self.batch_size)], max_action_ids] = rewards[i] + self.gamma * q_eval[[np.arange(self.batch_size)], max_action_ids]  * (1 - dones[i].numpy())\\n\\n    self.learn_step_counter += 1\\n    self.decrement_epsilon()\\n    \\n    self.q_value_network.fit(states, q_target, batch_size=self.batch_size, epochs=1, verbose=False)\\n    \\n\\n'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["    \"\"\"\n","    def learn(self):\n","        if self.memory.mem_counter < self.batch_size:\n","            return\n","\n","        self.replace_target_network()\n","\n","        states, actions, rewards, states_, dones = self.sample_experience()\n","\n","        indices = tf.range(self.batch_size, dtype=tf.int32)\n","        action_indices = tf.stack([indices, actions], axis=1)\n","\n","        with tf.GradientTape() as tape:\n","            q_pred = tf.gather_nd(self.q_value_network(states), indices=action_indices)\n","            q_next = self.target_q_network(states_)\n","            q_eval = self.q_value_network(states_)\n","\n","            max_actions = tf.math.argmax(q_eval, axis=1, output_type=tf.int32)\n","            max_action_idx = tf.stack([indices, max_actions], axis=1)\n","\n","            q_target = rewards + \\\n","                self.gamma*tf.gather_nd(q_next, indices=max_action_idx) *\\\n","                (1 - dones.numpy())\n","\n","            loss = keras.losses.MSE(q_pred, q_target)\n","\n","        params = self.q_value_network.trainable_variables\n","        grads = tape.gradient(loss, params)\n","\n","        self.q_value_network.optimizer.apply_gradients(zip(grads, params))\n","\n","        self.learn_step_counter += 1\n","\n","        self.decrement_epsilon()\n","        return self.eps\n","    \"\"\""]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:27.256040Z","iopub.status.busy":"2023-03-15T06:51:27.255126Z","iopub.status.idle":"2023-03-15T06:51:27.268827Z","shell.execute_reply":"2023-03-15T06:51:27.267712Z","shell.execute_reply.started":"2023-03-15T06:51:27.255989Z"},"trusted":true},"outputs":[],"source":["import collections\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gymnasium as gym\n","import tensorflow as tf\n","from gymnasium.wrappers import *\n","\n","\n","def manage_memory():\n","    gpus = tf.config.list_physical_devices('GPU')\n","    if gpus:\n","        try:\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, True)\n","        except RuntimeError as e:\n","            print(e)\n","\n","\n","def plot_learning_curve(scores, epsilons, filename, lines=None):\n","    x = [_ for _ in range(len(scores))]\n","    fig=plt.figure()\n","    ax=fig.add_subplot(111, label=\"1\")\n","    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n","\n","    ax.plot(x, epsilons, color=\"C0\")\n","    ax.set_xlabel(\"Training Steps\", color=\"C0\")\n","    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n","    ax.tick_params(axis='x', colors=\"C0\")\n","    ax.tick_params(axis='y', colors=\"C0\")\n","\n","    N = len(scores)\n","    running_avg = np.empty(N)\n","    for t in range(N):\n","\t    running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n","\n","    ax2.scatter(x, running_avg, color=\"C1\")\n","    ax2.axes.get_xaxis().set_visible(False)\n","    ax2.yaxis.tick_right()\n","    ax2.set_ylabel('Score', color=\"C1\")\n","    ax2.yaxis.set_label_position('right')\n","    ax2.tick_params(axis='y', colors=\"C1\")\n","\n","    if lines is not None:\n","        for line in lines:\n","            plt.axvline(x=line)\n","\n","    plt.savefig(filename)\n","\n","\n","def make_env(env_name, video_file_name, episode_freq_fo_video): \n","    env = gym.make(env_name, render_mode=\"rgb_array\")\n","    \n","    if len(env.observation_space.shape) >= 3: \n","        print(\"yes\")\n","        #env = AtariPreprocessing(env, 10, 4, 84, False, True)\n","        env = ResizeObservation(env, 84)\n","        env = GrayScaleObservation(env, keep_dim=False)\n","        env = FrameStack(env, 4, lz4_compress=False)\n","        env = NormalizeObservation(env)\n","\n","    return env"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:27.775727Z","iopub.status.busy":"2023-03-15T06:51:27.775358Z","iopub.status.idle":"2023-03-15T06:51:27.781697Z","shell.execute_reply":"2023-03-15T06:51:27.780646Z","shell.execute_reply.started":"2023-03-15T06:51:27.775692Z"},"trusted":true},"outputs":[],"source":["class Writer:\n","    def __init__(self, fname): \n","        self.fname = fname \n","\n","    def write_to_file(self, content): \n","        with open(self.fname, \"a\") as file: \n","            file.write(content + \"\\n\")\n","\n","    def read_file(self, fname):\n","        with open(fname, \"r\") as file: \n","            return file.read()\n","            "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:28.255986Z","iopub.status.busy":"2023-03-15T06:51:28.255332Z","iopub.status.idle":"2023-03-15T06:51:28.267255Z","shell.execute_reply":"2023-03-15T06:51:28.266244Z","shell.execute_reply.started":"2023-03-15T06:51:28.255922Z"},"trusted":true},"outputs":[],"source":["import time\n","from telebot import TeleBot\n","import datetime\n","import telebot\n","\n","token = \"6238487424:AAG0jRhvbiVa90qUcf2fAirQr_-quPMs7cU\"\n","chat_id = \"1055055706\"\n","bot = TeleBot(token=token) \n","\n","def telegram_send(message, bot):\n","    chat_id = \"1055055706\"\n","    bot.send_message(chat_id=chat_id, text=message)\n","\n","def welcome_msg(multi_step, double_dqn, dueling):\n","    st = 'Hi! Starting learning with DQN Multi-step = %d, Double DQN = %r, Dueling DQN = %r' % (multi_step, double_dqn, dueling)\n","    telegram_send(st, bot)\n","    \n","def info_msg(episode, max_episode, reward, best_score, loss): \n","    st = f\"Current Episode: {episode}, Current Reward: {reward}, Max Episode: {max_episode}, Best Score: {best_score}, loss: {loss}\"\n","    telegram_send(st, bot)\n","\n","def end_msg(learning_time):\n","    st = 'Finished! Learning time: ' + str(datetime.timedelta(seconds=int(learning_time)))\n","    telegram_send(st, bot)\n","    print(st)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:28.815545Z","iopub.status.busy":"2023-03-15T06:51:28.815172Z","iopub.status.idle":"2023-03-15T06:51:28.823258Z","shell.execute_reply":"2023-03-15T06:51:28.822131Z","shell.execute_reply.started":"2023-03-15T06:51:28.815510Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import imageio\n","\n","\n","class RecordVideo: \n","    \n","    def __init__(self, prefix_fname,  out_directory=\"videos/\", fps=10): \n","        self.prefix_fname = prefix_fname\n","        self.out_directory = out_directory\n","        self.fps = fps\n","        self.images = []\n","        \n","    def add_image(self, image): \n","        self.images.append(image)\n","    \n","    def save(self, episode_no): \n","        name = self.out_directory + self.prefix_fname + \"_\" + str(episode_no) + \".mp4\"\n","        imageio.mimsave(name, [np.array(img) for i, img in enumerate(self.images)], fps=self.fps)\n","        self.images = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T06:51:29.917109Z","iopub.status.busy":"2023-03-15T06:51:29.916660Z","iopub.status.idle":"2023-03-15T06:51:29.936798Z","shell.execute_reply":"2023-03-15T06:51:29.935741Z","shell.execute_reply.started":"2023-03-15T06:51:29.917073Z"},"trusted":true},"outputs":[],"source":["from npy_append_array import NpyAppendArray\n","import numpy as np\n","\n","class Trainer:   \n","    def __init__(self, env, trainer_params): \n","       \n","        self.env = env \n","        self.noe = trainer_params.get(\"noe\")\n","        self.max_steps = trainer_params.get(\"max_steps\")\n","       \n","        self.eps_decay_rate = trainer_params.get(\"eps_decay_rate\")\n","        self.action_space = trainer_params.get(\"action_space\")\n","        self.is_tg = trainer_params.get(\"is_tg\")\n","        self.tg_bot_freq_epi = trainer_params.get(\"tg_bot_freq_epi\")\n","        self.record = trainer_params.get(\"record\")\n","        self.agent_params = {\n","                        \"gamma\":  trainer_params.get(\"gamma\"), \n","                        \"lr\":  trainer_params.get(\"lr\"), \n","                        \"input_dims\":  trainer_params.get(\"input_dims\"),\n","                        \"mem_size\" :  trainer_params.get(\"mem_size\"),\n","                        \"batch_size\" :  trainer_params.get(\"batch_size\"),\n","                        \"replace\" :  trainer_params.get(\"replace\"),\n","                        \"algo\" :  trainer_params.get(\"algo\"),\n","                        \"env_name\" :  trainer_params.get(\"env_name\"),\n","                        \"n_actions\" :  trainer_params.get(\"n_actions\"),\n","                        \"chkpt_dir\":  trainer_params.get(\"chkpt_dir\"),\n","                        \"actions\":  trainer_params.get(\"actions\"),\n","                        \"eps\": trainer_params.get(\"eps\"),\n","                        \"min_eps\": trainer_params.get(\"min_eps\"),\n","                        \"eps_decay_rate\": trainer_params.get(\"eps_decay_rate\"),\n","                        \"tau\": trainer_params.get(\"tau\"), \n","                        \"soft_update\": trainer_params.get(\"soft_update\")\n","                    }\n","        \n","        self.agent = Agent(self.agent_params)\n","        self.writer = Writer(\"model_training_results.txt\")\n","        self.recorder = RecordVideo(trainer_params.get(\"video_prefix\"), \"videos/\", 20)\n","        \n","        self.target_score = trainer_params.get(\"target_score\")\n","        self.checkpoint = trainer_params.get(\"checkpoint\")\n","            \n","    def train_rl_model(self): \n","        episode_rewards = []\n","        epsilon_history = []\n","        avg_rewards = []\n","        best_reward = float(\"-inf\")\n","        \n","        if self.checkpoint:\n","            self.agent.load_models()\n","\n","        for episode in range(self.noe): \n","            n_steps = 0 \n","            episodic_loss = 0\n","            state = self.env.reset()\n","            reward = 0 \n","            \n","            if self.record and episode%100==0: \n","                img = self.env.render()\n","                self.recorder.add_image(img)\n","\n","            for step in range(self.max_steps): \n","                \n","                if self.record and episode%100==0: \n","                    img = self.env.render()\n","                    self.recorder.add_image(img)\n","\n","                if type(state) == tuple: \n","                    state = state[0]\n","                state = state\n","\n","                action = self.agent.choose_action(state)\n","\n","                next_info = self.env.step(action)\n","                next_state, reward_prob, terminated, truncated, _ = next_info\n","                done = truncated or terminated\n","                reward += reward_prob\n","\n","                self.agent.store_experience(state, action, reward_prob, next_state, done)\n","                eps = self.agent.learn()\n","\n","                state = next_state\n","                n_steps += 1 \n","               \n","                \n","                if done: \n","                    break\n","\n","            epsilon_history.append(eps)\n","            episode_rewards.append(reward)\n","            avg_reward = np.mean(episode_rewards[-100:])\n","            avg_rewards.append(avg_reward)\n","\n","            result = f\"Episode: {episode}, Epsilon: {eps}, Steps: {n_steps}, Reward: {reward}, Best reward: {best_reward}, Avg reward: {avg_reward}\"\n","            self.writer.write_to_file(result)\n","            print(result)\n","            \n","            # Saving Best Model\n","            if reward > best_reward: \n","                best_reward = reward\n","                self.agent.save_models()\n","            \n","            # video Recorder\n","            if episode % 100 ==0:\n","                self.recorder.save(episode)\n","                \n","          # Telegram bot\n","            if self.is_tg and episode % self.tg_bot_freq_epi == 0: \n","                info_msg(episode+1, self.noe, reward, best_reward, \"d\")\n","                \n","         # Eatly Stopping\n","            if episode > 100 and np.mean(episode_rewards[-100:]) >= self.target_score: \n","                break\n","                \n","                \n","        return episode_rewards, epsilon_history, avg_rewards, best_reward"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gymnasium as gym\n","import time\n","\n","env = make_env(\"ALE/Pong-v5\", \"videos/\", 50)\n","action_space = [_ for _ in range(env.action_space.n)]\n","\n","episodic_rewards_filename = 'array_files/episodic_reward.npy'\n","epsilon_history_filename = 'array_files/epsilon_history.npy'\n","cum_avg_reward_filename = 'array_files/cum_avg_rewards.npy'\n","losses_filename = 'array_files/losses.npy'\n","\n","trainer_params = {\n","    \"noe\": 1000, \n","    \"max_steps\": 10000,\n","    \"max_eps\": 1,\n","    \"min_eps\": 0.1,\n","    \"eps_decay_rate\": 1e-4,\n","    \"eps\": 1,\n","    \"action_space\": action_space,\n","    \"is_tg\": True,\n","    \"tg_bot_freq_epi\": 10,\n","    \"record\": record,\n","    \"gamma\": 0.95, \n","    \"lr\": 0.0005, \n","    \"input_dims\": env.observation_space.shape,\n","    \"mem_size\" : 100000,\n","    \"batch_size\" : 32,\n","    \"replace\" : 150,\n","    \"algo\" : \"DDQN\",\n","    \"env_name\" : \"lunarlander\",\n","    \"n_actions\" : len(action_space),\n","    \"chkpt_dir\": \"tmp/ddqn/\",\n","    \"actions\": action_space,\n","    \"target_score\": 100,\n","    \"tau\": 0.1,\n","    \"soft_update\": True,\n","    \"video_prefix\": \"ddqn\"\n","}\n","\n","\n","if __name__ == \"__main__\": \n","    try: \n","        manage_memory()\n","        \n","        trainer = Trainer(env, trainer_params)\n","\n","        episode_rewards, avg_rewards, best_reward = trainer.train_rl_model()\n","    #    plot_learning_curve(episode_rewards, \"plot_file\")\n","\n","       # eval_model(env, \"keras model\", \"videos/\", fps=10)\n","    \n","    except Exception as error:\n","        raise error\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T08:42:22.356127Z","iopub.status.busy":"2023-03-15T08:42:22.355460Z","iopub.status.idle":"2023-03-15T10:52:15.741815Z","shell.execute_reply":"2023-03-15T10:52:15.740589Z","shell.execute_reply.started":"2023-03-15T08:42:22.356086Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode: 0, Epsilon: 0.9963000000000004, Steps: 68, Reward: -115.96582095859624, Best reward: -inf, Avg reward: -115.96582095859624\n","... models saved successfully ...\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x603e200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 1, Epsilon: 0.9873000000000014, Steps: 90, Reward: -288.68509102899606, Best reward: -115.96582095859624, Avg reward: -202.32545599379614\n","Episode: 2, Epsilon: 0.9764000000000026, Steps: 109, Reward: -221.91340194686484, Best reward: -115.96582095859624, Avg reward: -208.8547713114857\n","Episode: 3, Epsilon: 0.9648000000000039, Steps: 116, Reward: -93.53937740866279, Best reward: -115.96582095859624, Avg reward: -180.02592283577997\n","... models saved successfully ...\n","Episode: 4, Epsilon: 0.9556000000000049, Steps: 92, Reward: -13.561490912417185, Best reward: -93.53937740866279, Avg reward: -146.7330364511074\n","... models saved successfully ...\n","Episode: 5, Epsilon: 0.9488000000000056, Steps: 68, Reward: -186.24348612461364, Best reward: -13.561490912417185, Avg reward: -153.31811139669176\n","Episode: 6, Epsilon: 0.9412000000000065, Steps: 76, Reward: -42.043738311828875, Best reward: -13.561490912417185, Avg reward: -137.4217723845685\n","Episode: 7, Epsilon: 0.9330000000000074, Steps: 82, Reward: -93.74989293966892, Best reward: -13.561490912417185, Avg reward: -131.96278745395605\n","Episode: 8, Epsilon: 0.9242000000000083, Steps: 88, Reward: -153.24220139429627, Best reward: -13.561490912417185, Avg reward: -134.32716678066052\n","Episode: 9, Epsilon: 0.9169000000000092, Steps: 73, Reward: -227.46032534621327, Best reward: -13.561490912417185, Avg reward: -143.6404826372158\n","Episode: 10, Epsilon: 0.9068000000000103, Steps: 101, Reward: -146.1693128010278, Best reward: -13.561490912417185, Avg reward: -143.87037628847145\n","Episode: 11, Epsilon: 0.8971000000000113, Steps: 97, Reward: -74.08080464788864, Best reward: -13.561490912417185, Avg reward: -138.0545786517562\n","Episode: 12, Epsilon: 0.8866000000000125, Steps: 105, Reward: -200.72060660331692, Best reward: -13.561490912417185, Avg reward: -142.87504234033779\n","Episode: 13, Epsilon: 0.8797000000000132, Steps: 69, Reward: -154.35061939987716, Best reward: -13.561490912417185, Avg reward: -143.69472641601917\n","Episode: 14, Epsilon: 0.8663000000000147, Steps: 134, Reward: -172.19121353392833, Best reward: -13.561490912417185, Avg reward: -145.59449222387977\n","Episode: 15, Epsilon: 0.8596000000000155, Steps: 67, Reward: -135.7718227193953, Best reward: -13.561490912417185, Avg reward: -144.9805753798495\n","Episode: 16, Epsilon: 0.8496000000000166, Steps: 100, Reward: -102.85498878146359, Best reward: -13.561490912417185, Avg reward: -142.50259969759153\n","Episode: 17, Epsilon: 0.836400000000018, Steps: 132, Reward: -200.87958326694968, Best reward: -13.561490912417185, Avg reward: -145.74576545144475\n","Episode: 18, Epsilon: 0.8251000000000193, Steps: 113, Reward: -119.22970796990592, Best reward: -13.561490912417185, Avg reward: -144.3501834787322\n","Episode: 19, Epsilon: 0.8169000000000202, Steps: 82, Reward: -98.43661444600346, Best reward: -13.561490912417185, Avg reward: -142.0545050270958\n","Episode: 20, Epsilon: 0.8036000000000216, Steps: 133, Reward: -304.02194795563855, Best reward: -13.561490912417185, Avg reward: -149.76724040464543\n","Episode: 21, Epsilon: 0.7936000000000227, Steps: 100, Reward: -125.42792147650185, Best reward: -13.561490912417185, Avg reward: -148.66090772609346\n","Episode: 22, Epsilon: 0.7864000000000235, Steps: 72, Reward: -139.57807670840938, Best reward: -13.561490912417185, Avg reward: -148.2660020296724\n","Episode: 23, Epsilon: 0.7762000000000246, Steps: 102, Reward: -118.77375074849219, Best reward: -13.561490912417185, Avg reward: -147.03715822628988\n","Episode: 24, Epsilon: 0.7661000000000258, Steps: 101, Reward: -141.88491614004047, Best reward: -13.561490912417185, Avg reward: -146.8310685428399\n","Episode: 25, Epsilon: 0.7558000000000269, Steps: 103, Reward: -112.67407200608392, Best reward: -13.561490912417185, Avg reward: -145.5173379068108\n","Episode: 26, Epsilon: 0.7422000000000284, Steps: 136, Reward: -108.26058536760993, Best reward: -13.561490912417185, Avg reward: -144.13745818313672\n","Episode: 27, Epsilon: 0.7317000000000295, Steps: 105, Reward: -374.32088895134126, Best reward: -13.561490912417185, Avg reward: -152.3582949962869\n","Episode: 28, Epsilon: 0.7210000000000307, Steps: 107, Reward: -234.17357846162093, Best reward: -13.561490912417185, Avg reward: -155.17951166750532\n","Episode: 29, Epsilon: 0.7132000000000316, Steps: 78, Reward: -93.89501680652208, Best reward: -13.561490912417185, Avg reward: -153.1366951721392\n","Episode: 30, Epsilon: 0.7009000000000329, Steps: 123, Reward: -143.68013479367167, Best reward: -13.561490912417185, Avg reward: -152.83164483734993\n","Episode: 31, Epsilon: 0.691600000000034, Steps: 93, Reward: -87.78589501123126, Best reward: -13.561490912417185, Avg reward: -150.79896515528372\n","Episode: 32, Epsilon: 0.6838000000000348, Steps: 78, Reward: -110.84452853686366, Best reward: -13.561490912417185, Avg reward: -149.58822465169524\n","Episode: 33, Epsilon: 0.6684000000000365, Steps: 154, Reward: -58.2342263330145, Best reward: -13.561490912417185, Avg reward: -146.90134234820462\n","Episode: 34, Epsilon: 0.6592000000000375, Steps: 92, Reward: -45.74584715914409, Best reward: -13.561490912417185, Avg reward: -144.01118534280292\n","Episode: 35, Epsilon: 0.646200000000039, Steps: 130, Reward: -109.94780071100797, Best reward: -13.561490912417185, Avg reward: -143.06498021414194\n","Episode: 36, Epsilon: 0.63640000000004, Steps: 98, Reward: -43.936918917906056, Best reward: -13.561490912417185, Avg reward: -140.3858434223518\n","Episode: 37, Epsilon: 0.6159000000000423, Steps: 205, Reward: -22.029510460299278, Best reward: -13.561490912417185, Avg reward: -137.27120308124515\n","Episode: 38, Epsilon: 0.6044000000000436, Steps: 115, Reward: -88.02480629498325, Best reward: -13.561490912417185, Avg reward: -136.00847495852048\n","Episode: 39, Epsilon: 0.5718000000000472, Steps: 326, Reward: -103.0368265536613, Best reward: -13.561490912417185, Avg reward: -135.18418374839897\n","Episode: 40, Epsilon: 0.5572000000000488, Steps: 146, Reward: -126.85456697651175, Best reward: -13.561490912417185, Avg reward: -134.98102236371878\n","Episode: 41, Epsilon: 0.5396000000000507, Steps: 176, Reward: -22.26762314313055, Best reward: -13.561490912417185, Avg reward: -132.29737000132383\n","Episode: 42, Epsilon: 0.5266000000000521, Steps: 130, Reward: 7.140805389025672, Best reward: -13.561490912417185, Avg reward: -129.05462173643198\n","... models saved successfully ...\n","Episode: 43, Epsilon: 0.5019000000000549, Steps: 247, Reward: -140.79916261502194, Best reward: 7.140805389025672, Avg reward: -129.3215431200363\n","Episode: 44, Epsilon: 0.4890000000000563, Steps: 129, Reward: -0.28807903441547467, Best reward: 7.140805389025672, Avg reward: -126.45413280702249\n","Episode: 45, Epsilon: 0.47550000000005777, Steps: 135, Reward: -109.46743865307094, Best reward: 7.140805389025672, Avg reward: -126.08485684715397\n","Episode: 46, Epsilon: 0.4590000000000596, Steps: 165, Reward: -2.4259089328433134, Best reward: 7.140805389025672, Avg reward: -123.45381540216863\n","Episode: 47, Epsilon: 0.44650000000006096, Steps: 125, Reward: -76.86739733286171, Best reward: 7.140805389025672, Avg reward: -122.48326502572475\n","Episode: 48, Epsilon: 0.4037000000000657, Steps: 428, Reward: -50.48723691966468, Best reward: 7.140805389025672, Avg reward: -121.01395832968271\n","Episode: 49, Epsilon: 0.3719000000000692, Steps: 318, Reward: -220.27887591747657, Best reward: 7.140805389025672, Avg reward: -122.99925668143858\n","Episode: 50, Epsilon: 0.30750000000007627, Steps: 644, Reward: -206.13332243988248, Best reward: 7.140805389025672, Avg reward: -124.62933640219238\n","Episode: 51, Epsilon: 0.28490000000007876, Steps: 226, Reward: -144.40418493578719, Best reward: 7.140805389025672, Avg reward: -125.00962195091536\n","Episode: 52, Epsilon: 0.24420000000008324, Steps: 407, Reward: -115.59979946426935, Best reward: 7.140805389025672, Avg reward: -124.83207813041261\n","Episode: 53, Epsilon: 0.18400000000008987, Steps: 602, Reward: -130.6131276791262, Best reward: 7.140805389025672, Avg reward: -124.93913460353694\n","Episode: 54, Epsilon: 0.14590000000009407, Steps: 381, Reward: -165.600012813418, Best reward: 7.140805389025672, Avg reward: -125.67842329826205\n","Episode: 55, Epsilon: 0.1, Steps: 642, Reward: -179.25241061799267, Best reward: 7.140805389025672, Avg reward: -126.63510164325726\n","Episode: 56, Epsilon: 0.1, Steps: 491, Reward: -194.0535090366002, Best reward: 7.140805389025672, Avg reward: -127.81788072033345\n","Episode: 57, Epsilon: 0.1, Steps: 986, Reward: -220.51431481373348, Best reward: 7.140805389025672, Avg reward: -129.41609510125414\n","Episode: 58, Epsilon: 0.1, Steps: 1000, Reward: -42.319227180288216, Best reward: 7.140805389025672, Avg reward: -127.93987700089878\n","Episode: 59, Epsilon: 0.1, Steps: 1000, Reward: 1.6203997441352973, Best reward: 7.140805389025672, Avg reward: -125.78053905514821\n","Episode: 60, Epsilon: 0.1, Steps: 601, Reward: -86.98681114449515, Best reward: 7.140805389025672, Avg reward: -125.14457630251455\n","Episode: 61, Epsilon: 0.1, Steps: 1000, Reward: -34.13501203423762, Best reward: 7.140805389025672, Avg reward: -123.67668010463912\n","Episode: 62, Epsilon: 0.1, Steps: 1000, Reward: -40.15212327729232, Best reward: 7.140805389025672, Avg reward: -122.35089348833202\n","Episode: 63, Epsilon: 0.1, Steps: 1000, Reward: -48.915247838943195, Best reward: 7.140805389025672, Avg reward: -121.20346152506033\n","Episode: 65, Epsilon: 0.1, Steps: 1000, Reward: -44.00693661635315, Best reward: 7.140805389025672, Avg reward: -119.59555492478785\n","Episode: 66, Epsilon: 0.1, Steps: 1000, Reward: -36.131662336825954, Best reward: 7.140805389025672, Avg reward: -118.34982518466902\n","Episode: 67, Epsilon: 0.1, Steps: 735, Reward: -85.72913501125139, Best reward: 7.140805389025672, Avg reward: -117.87010915270697\n","Episode: 68, Epsilon: 0.1, Steps: 1000, Reward: -76.77610700046354, Best reward: 7.140805389025672, Avg reward: -117.27454390412375\n","Episode: 69, Epsilon: 0.1, Steps: 1000, Reward: -56.472503671140984, Best reward: 7.140805389025672, Avg reward: -116.40594332936683\n","Episode: 70, Epsilon: 0.1, Steps: 1000, Reward: -57.5992380537039, Best reward: 7.140805389025672, Avg reward: -115.57767987478005\n","Episode: 71, Epsilon: 0.1, Steps: 1000, Reward: -45.9691161052748, Best reward: 7.140805389025672, Avg reward: -114.61089426687028\n","Episode: 72, Epsilon: 0.1, Steps: 1000, Reward: -46.47225210068537, Best reward: 7.140805389025672, Avg reward: -113.67748820979925\n","Episode: 73, Epsilon: 0.1, Steps: 1000, Reward: -51.71544583324456, Best reward: 7.140805389025672, Avg reward: -112.84016331281877\n","Episode: 74, Epsilon: 0.1, Steps: 410, Reward: -47.185225064209135, Best reward: 7.140805389025672, Avg reward: -111.96476413617066\n","Episode: 75, Epsilon: 0.1, Steps: 811, Reward: -140.72642260976923, Best reward: 7.140805389025672, Avg reward: -112.34320701082326\n","Episode: 76, Epsilon: 0.1, Steps: 1000, Reward: -29.957239571971144, Best reward: 7.140805389025672, Avg reward: -111.27325938174727\n","Episode: 77, Epsilon: 0.1, Steps: 1000, Reward: 4.106143345912254, Best reward: 7.140805389025672, Avg reward: -109.79403626985419\n","Episode: 78, Epsilon: 0.1, Steps: 1000, Reward: 8.701419541535204, Best reward: 7.140805389025672, Avg reward: -108.294093791229\n","... models saved successfully ...\n","Episode: 79, Epsilon: 0.1, Steps: 1000, Reward: 34.432722540912366, Best reward: 8.701419541535204, Avg reward: -106.51000858707721\n","... models saved successfully ...\n","Episode: 80, Epsilon: 0.1, Steps: 1000, Reward: -6.089253396551487, Best reward: 34.432722540912366, Avg reward: -105.27024617731762\n","Episode: 81, Epsilon: 0.1, Steps: 1000, Reward: 20.118277299090202, Best reward: 34.432722540912366, Avg reward: -103.74111784223948\n","Episode: 82, Epsilon: 0.1, Steps: 1000, Reward: -19.47325392670379, Best reward: 34.432722540912366, Avg reward: -102.7258423733776\n","Episode: 83, Epsilon: 0.1, Steps: 1000, Reward: -131.4485929980494, Best reward: 34.432722540912366, Avg reward: -103.06777988081417\n","Episode: 84, Epsilon: 0.1, Steps: 1000, Reward: 2.1986381217499344, Best reward: 34.432722540912366, Avg reward: -101.82935143372518\n","Episode: 85, Epsilon: 0.1, Steps: 1000, Reward: -23.584576525112073, Best reward: 34.432722540912366, Avg reward: -100.91952846967155\n","Episode: 86, Epsilon: 0.1, Steps: 1000, Reward: -54.2639811162469, Best reward: 34.432722540912366, Avg reward: -100.38325781043677\n","Episode: 87, Epsilon: 0.1, Steps: 1000, Reward: 2.040045871775562, Best reward: 34.432722540912366, Avg reward: -99.21935663222983\n","Episode: 88, Epsilon: 0.1, Steps: 1000, Reward: -45.20805406810254, Best reward: 34.432722540912366, Avg reward: -98.61248806409355\n","Episode: 89, Epsilon: 0.1, Steps: 1000, Reward: -59.18208434866637, Best reward: 34.432722540912366, Avg reward: -98.17437246725547\n","Episode: 90, Epsilon: 0.1, Steps: 1000, Reward: -30.408023673590485, Best reward: 34.432722540912366, Avg reward: -97.42968731567673\n","Episode: 91, Epsilon: 0.1, Steps: 1000, Reward: -9.543466077158008, Best reward: 34.432722540912366, Avg reward: -96.47440230221457\n","Episode: 92, Epsilon: 0.1, Steps: 1000, Reward: -25.024850624904353, Best reward: 34.432722540912366, Avg reward: -95.7061275529962\n","Episode: 93, Epsilon: 0.1, Steps: 1000, Reward: -40.71071784304668, Best reward: 34.432722540912366, Avg reward: -95.12107000289035\n","Episode: 94, Epsilon: 0.1, Steps: 1000, Reward: -57.056359642076835, Best reward: 34.432722540912366, Avg reward: -94.72038884119756\n","Episode: 95, Epsilon: 0.1, Steps: 1000, Reward: -44.41649683962225, Best reward: 34.432722540912366, Avg reward: -94.19638996618119\n","Episode: 96, Epsilon: 0.1, Steps: 1000, Reward: -30.92872885168643, Best reward: 34.432722540912366, Avg reward: -93.54414603716577\n","Episode: 97, Epsilon: 0.1, Steps: 1000, Reward: -12.560317283919598, Best reward: 34.432722540912366, Avg reward: -92.71778043764286\n","Episode: 98, Epsilon: 0.1, Steps: 1000, Reward: -46.83238930621645, Best reward: 34.432722540912366, Avg reward: -92.25429163833553\n","Episode: 99, Epsilon: 0.1, Steps: 1000, Reward: 6.51352256529605, Best reward: 34.432722540912366, Avg reward: -91.26661349629921\n","Episode: 100, Epsilon: 0.1, Steps: 1000, Reward: -54.57029587910425, Best reward: 34.432722540912366, Avg reward: -90.65265824550428\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x5c49200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 101, Epsilon: 0.1, Steps: 1000, Reward: -35.186329387894666, Best reward: 34.432722540912366, Avg reward: -88.11767062909327\n","Episode: 102, Epsilon: 0.1, Steps: 1000, Reward: 19.833398177340346, Best reward: 34.432722540912366, Avg reward: -85.70020262785121\n","Episode: 103, Epsilon: 0.1, Steps: 1000, Reward: 10.539933449523419, Best reward: 34.432722540912366, Avg reward: -84.65940951926932\n","Episode: 104, Epsilon: 0.1, Steps: 1000, Reward: -21.133037373910714, Best reward: 34.432722540912366, Avg reward: -84.73512498388428\n","Episode: 105, Epsilon: 0.1, Steps: 1000, Reward: -0.6266529140022583, Best reward: 34.432722540912366, Avg reward: -82.87895665177817\n","Episode: 106, Epsilon: 0.1, Steps: 1000, Reward: -39.94103178487826, Best reward: 34.432722540912366, Avg reward: -82.85792958650867\n","Episode: 107, Epsilon: 0.1, Steps: 1000, Reward: 1.2400602640503067, Best reward: 34.432722540912366, Avg reward: -81.90803005447147\n","Episode: 108, Epsilon: 0.1, Steps: 1000, Reward: -4.597393972923517, Best reward: 34.432722540912366, Avg reward: -80.42158198025774\n","Episode: 109, Epsilon: 0.1, Steps: 1000, Reward: -2.048376040641217, Best reward: 34.432722540912366, Avg reward: -78.16746248720202\n","Episode: 110, Epsilon: 0.1, Steps: 1000, Reward: -4.393133906143923, Best reward: 34.432722540912366, Avg reward: -76.74970069825319\n","Episode: 111, Epsilon: 0.1, Steps: 1000, Reward: 26.32969681947256, Best reward: 34.432722540912366, Avg reward: -75.74559568357957\n","Episode: 112, Epsilon: 0.1, Steps: 1000, Reward: 42.345831644807795, Best reward: 34.432722540912366, Avg reward: -73.31493130109833\n","... models saved successfully ...\n","Episode: 113, Epsilon: 0.1, Steps: 398, Reward: -97.6825759453084, Best reward: 42.345831644807795, Avg reward: -72.74825086655264\n","Episode: 114, Epsilon: 0.1, Steps: 336, Reward: -92.12742332721017, Best reward: 42.345831644807795, Avg reward: -71.94761296448546\n","Episode: 115, Epsilon: 0.1, Steps: 929, Reward: 203.94419394039772, Best reward: 42.345831644807795, Avg reward: -68.55045279788752\n","... models saved successfully ...\n","Episode: 116, Epsilon: 0.1, Steps: 1000, Reward: 77.73929062227204, Best reward: 203.94419394039772, Avg reward: -66.74451000385017\n","Episode: 117, Epsilon: 0.1, Steps: 240, Reward: -10.10651505676313, Best reward: 203.94419394039772, Avg reward: -64.8367793217483\n","Episode: 118, Epsilon: 0.1, Steps: 976, Reward: 241.9684400597152, Best reward: 203.94419394039772, Avg reward: -61.224797841452094\n","... models saved successfully ...\n","Episode: 119, Epsilon: 0.1, Steps: 1000, Reward: 82.04760676535824, Best reward: 241.9684400597152, Avg reward: -59.419955629338475\n","Episode: 120, Epsilon: 0.1, Steps: 1000, Reward: 160.84158278368193, Best reward: 241.9684400597152, Avg reward: -54.77132032194527\n","Episode: 121, Epsilon: 0.1, Steps: 984, Reward: 220.97727682117076, Best reward: 241.9684400597152, Avg reward: -51.307268338968555\n","Episode: 122, Epsilon: 0.1, Steps: 554, Reward: 237.98340134922847, Best reward: 241.9684400597152, Avg reward: -47.53165355839217\n","Episode: 123, Epsilon: 0.1, Steps: 667, Reward: 190.60427701357924, Best reward: 241.9684400597152, Avg reward: -44.43787328077146\n","Episode: 124, Epsilon: 0.1, Steps: 968, Reward: 241.07327969351124, Best reward: 241.9684400597152, Avg reward: -40.60829132243594\n","Episode: 125, Epsilon: 0.1, Steps: 962, Reward: 243.62604829424924, Best reward: 241.9684400597152, Avg reward: -37.045290119432615\n","... models saved successfully ...\n","Episode: 126, Epsilon: 0.1, Steps: 177, Reward: 40.309893528006256, Best reward: 243.62604829424924, Avg reward: -35.55958533047644\n","Episode: 127, Epsilon: 0.1, Steps: 907, Reward: 261.9979085754943, Best reward: 243.62604829424924, Avg reward: -29.19639735520808\n","... models saved successfully ...\n","Episode: 128, Epsilon: 0.1, Steps: 1000, Reward: 128.61335928718725, Best reward: 261.9979085754943, Avg reward: -25.56852797771999\n","Episode: 129, Epsilon: 0.1, Steps: 1000, Reward: 91.54898081814181, Best reward: 261.9979085754943, Avg reward: -23.714088001473357\n","Episode: 130, Epsilon: 0.1, Steps: 367, Reward: 270.05729379263767, Best reward: 261.9979085754943, Avg reward: -19.576713715610264\n","... models saved successfully ...\n","Episode: 131, Epsilon: 0.1, Steps: 514, Reward: 239.91337353195988, Best reward: 270.05729379263767, Avg reward: -16.299721030178354\n","Episode: 132, Epsilon: 0.1, Steps: 328, Reward: -215.9617135686288, Best reward: 270.05729379263767, Avg reward: -17.350892880496005\n","Episode: 133, Epsilon: 0.1, Steps: 1000, Reward: -121.63021479291855, Best reward: 270.05729379263767, Avg reward: -17.98485276509505\n","Episode: 134, Epsilon: 0.1, Steps: 1000, Reward: -9.958303982237704, Best reward: 270.05729379263767, Avg reward: -17.626977333325982\n","Episode: 135, Epsilon: 0.1, Steps: 1000, Reward: -6.055111795076912, Best reward: 270.05729379263767, Avg reward: -16.588050444166676\n","Episode: 136, Epsilon: 0.1, Steps: 1000, Reward: 13.051900907703068, Best reward: 270.05729379263767, Avg reward: -16.01816224591058\n","Episode: 137, Epsilon: 0.1, Steps: 1000, Reward: -17.83258357436401, Best reward: 270.05729379263767, Avg reward: -15.976192977051229\n","Episode: 138, Epsilon: 0.1, Steps: 1000, Reward: 15.29321028942952, Best reward: 270.05729379263767, Avg reward: -14.943012811207103\n","Episode: 139, Epsilon: 0.1, Steps: 1000, Reward: 39.52285459564985, Best reward: 270.05729379263767, Avg reward: -13.51741599971399\n","Episode: 140, Epsilon: 0.1, Steps: 1000, Reward: 124.40490691660055, Best reward: 270.05729379263767, Avg reward: -11.004821260782867\n","Episode: 141, Epsilon: 0.1, Steps: 1000, Reward: -37.56244650596326, Best reward: 270.05729379263767, Avg reward: -11.157769494411193\n","Episode: 142, Epsilon: 0.1, Steps: 1000, Reward: 5.704818403223698, Best reward: 270.05729379263767, Avg reward: -11.17212936426921\n","Episode: 143, Epsilon: 0.1, Steps: 1000, Reward: 7.8906416333512, Best reward: 270.05729379263767, Avg reward: -9.68523132178548\n","Episode: 144, Epsilon: 0.1, Steps: 1000, Reward: 148.7027699113055, Best reward: 270.05729379263767, Avg reward: -8.195322832328271\n","Episode: 145, Epsilon: 0.1, Steps: 964, Reward: 259.63450225127053, Best reward: 270.05729379263767, Avg reward: -4.504303423284855\n","Episode: 146, Epsilon: 0.1, Steps: 1000, Reward: -2.9398946228685574, Best reward: 270.05729379263767, Avg reward: -4.509443280185109\n","Episode: 147, Epsilon: 0.1, Steps: 617, Reward: 206.60459023324984, Best reward: 270.05729379263767, Avg reward: -1.674723404523994\n","Episode: 148, Epsilon: 0.1, Steps: 802, Reward: 148.83813119378118, Best reward: 270.05729379263767, Avg reward: 0.31853027661046385\n","Episode: 149, Epsilon: 0.1, Steps: 1000, Reward: -34.4865664313742, Best reward: 270.05729379263767, Avg reward: 2.1764533714714895\n","Episode: 150, Epsilon: 0.1, Steps: 574, Reward: 223.49702452942105, Best reward: 270.05729379263767, Avg reward: 6.472756841164524\n","Episode: 151, Epsilon: 0.1, Steps: 910, Reward: 72.03085559237434, Best reward: 270.05729379263767, Avg reward: 8.63710724644614\n","Episode: 152, Epsilon: 0.1, Steps: 717, Reward: 240.52600383341778, Best reward: 270.05729379263767, Avg reward: 12.19836527942301\n","Episode: 153, Epsilon: 0.1, Steps: 603, Reward: 238.33776578926094, Best reward: 270.05729379263767, Avg reward: 15.887874214106878\n","Episode: 154, Epsilon: 0.1, Steps: 1000, Reward: 11.71637783299951, Best reward: 270.05729379263767, Avg reward: 17.661038120571053\n","Episode: 155, Epsilon: 0.1, Steps: 1000, Reward: 21.27481665060174, Best reward: 270.05729379263767, Avg reward: 19.666310393256996\n","Episode: 156, Epsilon: 0.1, Steps: 1000, Reward: 45.67422119744196, Best reward: 270.05729379263767, Avg reward: 22.06358769559742\n","Episode: 157, Epsilon: 0.1, Steps: 510, Reward: 264.20685115725985, Best reward: 270.05729379263767, Avg reward: 26.910799355307354\n","Episode: 158, Epsilon: 0.1, Steps: 255, Reward: 275.13589506240623, Best reward: 270.05729379263767, Avg reward: 30.085350577734292\n","... models saved successfully ...\n","Episode: 159, Epsilon: 0.1, Steps: 765, Reward: 207.21150499561094, Best reward: 275.13589506240623, Avg reward: 32.141261630249055\n","Episode: 160, Epsilon: 0.1, Steps: 1000, Reward: -35.479941124628525, Best reward: 275.13589506240623, Avg reward: 32.656330330447716\n","Episode: 161, Epsilon: 0.1, Steps: 473, Reward: 281.18477364750095, Best reward: 275.13589506240623, Avg reward: 35.80952818726511\n","... models saved successfully ...\n","Episode: 162, Epsilon: 0.1, Steps: 639, Reward: 233.63784527861594, Best reward: 281.18477364750095, Avg reward: 38.547427872824194\n","Episode: 163, Epsilon: 0.1, Steps: 303, Reward: -17.118810464768075, Best reward: 281.18477364750095, Avg reward: 38.865392246565946\n","Episode: 164, Epsilon: 0.1, Steps: 287, Reward: 272.29563594490605, Best reward: 281.18477364750095, Avg reward: 42.511130114172836\n","Episode: 165, Epsilon: 0.1, Steps: 122, Reward: 32.43718482170709, Best reward: 281.18477364750095, Avg reward: 43.27557132855343\n","Episode: 166, Epsilon: 0.1, Steps: 130, Reward: -0.6030500514958561, Best reward: 281.18477364750095, Avg reward: 43.630857451406726\n","Episode: 167, Epsilon: 0.1, Steps: 241, Reward: 274.2557466959037, Best reward: 281.18477364750095, Avg reward: 47.23070626847828\n","Episode: 168, Epsilon: 0.1, Steps: 155, Reward: 26.188224575945426, Best reward: 281.18477364750095, Avg reward: 48.26034958424237\n","Episode: 169, Epsilon: 0.1, Steps: 476, Reward: 229.29375686673623, Best reward: 281.18477364750095, Avg reward: 51.11801218962114\n","Episode: 170, Epsilon: 0.1, Steps: 1000, Reward: 90.81631624124391, Best reward: 281.18477364750095, Avg reward: 52.60216773257062\n","Episode: 171, Epsilon: 0.1, Steps: 622, Reward: 219.25923333593556, Best reward: 281.18477364750095, Avg reward: 55.25445122698273\n","Episode: 172, Epsilon: 0.1, Steps: 442, Reward: 214.15961282389986, Best reward: 281.18477364750095, Avg reward: 57.86076987622859\n","Episode: 173, Epsilon: 0.1, Steps: 103, Reward: -180.83196549026698, Best reward: 281.18477364750095, Avg reward: 56.56960467965836\n","Episode: 174, Epsilon: 0.1, Steps: 120, Reward: -4.275243562462094, Best reward: 281.18477364750095, Avg reward: 56.99870449467582\n","Episode: 175, Epsilon: 0.1, Steps: 153, Reward: -25.881688189243818, Best reward: 281.18477364750095, Avg reward: 58.14715183888108\n","Episode: 176, Epsilon: 0.1, Steps: 291, Reward: -68.31527517380266, Best reward: 281.18477364750095, Avg reward: 57.76357148286277\n","Episode: 177, Epsilon: 0.1, Steps: 502, Reward: 251.70041740963433, Best reward: 281.18477364750095, Avg reward: 60.2395142235\n","Episode: 178, Epsilon: 0.1, Steps: 173, Reward: -13.156460033774366, Best reward: 281.18477364750095, Avg reward: 60.0209354277469\n","Episode: 179, Epsilon: 0.1, Steps: 1000, Reward: 80.51556669929934, Best reward: 281.18477364750095, Avg reward: 60.48176386933077\n","Episode: 180, Epsilon: 0.1, Steps: 153, Reward: 7.697194771518696, Best reward: 281.18477364750095, Avg reward: 60.61962835101147\n","Episode: 181, Epsilon: 0.1, Steps: 157, Reward: 28.072410352645278, Best reward: 281.18477364750095, Avg reward: 60.69916968154702\n","Episode: 182, Epsilon: 0.1, Steps: 257, Reward: -7.055369856892241, Best reward: 281.18477364750095, Avg reward: 60.82334852224513\n","Episode: 183, Epsilon: 0.1, Steps: 1000, Reward: 123.82550598158953, Best reward: 281.18477364750095, Avg reward: 63.376089512041524\n","Episode: 184, Epsilon: 0.1, Steps: 125, Reward: -72.61783411643552, Best reward: 281.18477364750095, Avg reward: 62.627924789659666\n","Episode: 185, Epsilon: 0.1, Steps: 455, Reward: 227.6352346412636, Best reward: 281.18477364750095, Avg reward: 65.14012290132342\n","Episode: 186, Epsilon: 0.1, Steps: 114, Reward: -99.26098122900817, Best reward: 281.18477364750095, Avg reward: 64.6901529001958\n","Episode: 187, Epsilon: 0.1, Steps: 505, Reward: 231.76540481922365, Best reward: 281.18477364750095, Avg reward: 66.98740648967028\n","Episode: 188, Epsilon: 0.1, Steps: 1000, Reward: 21.26601739825093, Best reward: 281.18477364750095, Avg reward: 67.65214720433383\n","Episode: 189, Epsilon: 0.1, Steps: 1000, Reward: 40.77306073163969, Best reward: 281.18477364750095, Avg reward: 68.65169865513688\n","Episode: 190, Epsilon: 0.1, Steps: 150, Reward: -2.535242221641937, Best reward: 281.18477364750095, Avg reward: 68.93042646965638\n","Episode: 191, Epsilon: 0.1, Steps: 151, Reward: 0.1093651707093386, Best reward: 281.18477364750095, Avg reward: 69.02695478213505\n","Episode: 192, Epsilon: 0.1, Steps: 387, Reward: 233.48809472036035, Best reward: 281.18477364750095, Avg reward: 71.6120842355877\n","Episode: 193, Epsilon: 0.1, Steps: 1000, Reward: 73.86078338666933, Best reward: 281.18477364750095, Avg reward: 72.75779924788486\n","Episode: 194, Epsilon: 0.1, Steps: 213, Reward: 30.80556883198713, Best reward: 281.18477364750095, Avg reward: 73.6364185326255\n","Episode: 195, Epsilon: 0.1, Steps: 504, Reward: 177.5913694322311, Best reward: 281.18477364750095, Avg reward: 75.85649719534403\n","Episode: 196, Epsilon: 0.1, Steps: 857, Reward: 155.67269597096728, Best reward: 281.18477364750095, Avg reward: 77.72251144357057\n","Episode: 197, Epsilon: 0.1, Steps: 190, Reward: -190.41656543720237, Best reward: 281.18477364750095, Avg reward: 75.94394896203774\n","Episode: 198, Epsilon: 0.1, Steps: 234, Reward: -145.8290553504861, Best reward: 281.18477364750095, Avg reward: 74.95398230159505\n","Episode: 199, Epsilon: 0.1, Steps: 553, Reward: -76.53561522387425, Best reward: 281.18477364750095, Avg reward: 74.12349092370334\n","Episode: 200, Epsilon: 0.1, Steps: 250, Reward: -273.38923415583594, Best reward: 281.18477364750095, Avg reward: 71.93530154093602\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x5db7200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 201, Epsilon: 0.1, Steps: 686, Reward: 288.91548924070435, Best reward: 281.18477364750095, Avg reward: 75.17631972722201\n","... models saved successfully ...\n","Episode: 202, Epsilon: 0.1, Steps: 668, Reward: 302.6718960480857, Best reward: 288.91548924070435, Avg reward: 78.00470470592947\n","... models saved successfully ...\n","Episode: 203, Epsilon: 0.1, Steps: 392, Reward: 260.0111463995806, Best reward: 302.6718960480857, Avg reward: 80.49941683543004\n","Episode: 204, Epsilon: 0.1, Steps: 231, Reward: -78.84006190533422, Best reward: 302.6718960480857, Avg reward: 79.92234659011581\n","Episode: 205, Epsilon: 0.1, Steps: 162, Reward: -1.219035936657903, Best reward: 302.6718960480857, Avg reward: 79.91642275988924\n","Episode: 206, Epsilon: 0.1, Steps: 302, Reward: 257.8751666156711, Best reward: 302.6718960480857, Avg reward: 82.89458474389474\n","Episode: 207, Epsilon: 0.1, Steps: 486, Reward: -25.46990587962597, Best reward: 302.6718960480857, Avg reward: 82.62748508245797\n","Episode: 208, Epsilon: 0.1, Steps: 299, Reward: 233.30351383583601, Best reward: 302.6718960480857, Avg reward: 85.00649416054556\n","Episode: 209, Epsilon: 0.1, Steps: 296, Reward: 206.9496198619097, Best reward: 302.6718960480857, Avg reward: 87.09647411957107\n","Episode: 210, Epsilon: 0.1, Steps: 137, Reward: 9.274882628397549, Best reward: 302.6718960480857, Avg reward: 87.23315428491647\n","Episode: 211, Epsilon: 0.1, Steps: 113, Reward: 35.14826766138805, Best reward: 302.6718960480857, Avg reward: 87.32133999333564\n","Episode: 212, Epsilon: 0.1, Steps: 87, Reward: 18.249994208518302, Best reward: 302.6718960480857, Avg reward: 87.08038161897275\n","Episode: 213, Epsilon: 0.1, Steps: 420, Reward: 268.596441058951, Best reward: 302.6718960480857, Avg reward: 90.74317178901534\n","Episode: 214, Epsilon: 0.1, Steps: 152, Reward: -48.4750262189615, Best reward: 302.6718960480857, Avg reward: 91.17969576009786\n","Episode: 215, Epsilon: 0.1, Steps: 152, Reward: -7.980880400593577, Best reward: 302.6718960480857, Avg reward: 89.06044501668794\n","Episode: 216, Epsilon: 0.1, Steps: 162, Reward: -61.56173934952079, Best reward: 302.6718960480857, Avg reward: 87.66743471697002\n","Episode: 217, Epsilon: 0.1, Steps: 219, Reward: -166.40014281816403, Best reward: 302.6718960480857, Avg reward: 86.104498439356\n","Episode: 218, Epsilon: 0.1, Steps: 164, Reward: -174.5318661224236, Best reward: 302.6718960480857, Avg reward: 81.9394953775346\n","Episode: 219, Epsilon: 0.1, Steps: 463, Reward: 229.71485444733878, Best reward: 302.6718960480857, Avg reward: 83.41616785435441\n","Episode: 220, Epsilon: 0.1, Steps: 127, Reward: -25.63434266480084, Best reward: 302.6718960480857, Avg reward: 81.55140859986959\n","Episode: 221, Epsilon: 0.1, Steps: 521, Reward: 291.78939257767945, Best reward: 302.6718960480857, Avg reward: 82.25952975743466\n","Episode: 222, Epsilon: 0.1, Steps: 329, Reward: 245.3748368682671, Best reward: 302.6718960480857, Avg reward: 82.33344411262506\n","Episode: 223, Epsilon: 0.1, Steps: 463, Reward: 216.06337356759633, Best reward: 302.6718960480857, Avg reward: 82.58803507816523\n","Episode: 224, Epsilon: 0.1, Steps: 518, Reward: 225.63372472037094, Best reward: 302.6718960480857, Avg reward: 82.43363952843382\n","Episode: 225, Epsilon: 0.1, Steps: 141, Reward: 26.930463390146926, Best reward: 302.6718960480857, Avg reward: 80.26668367939281\n","Episode: 226, Epsilon: 0.1, Steps: 1000, Reward: -32.51469416525487, Best reward: 302.6718960480857, Avg reward: 79.53843780246018\n","Episode: 227, Epsilon: 0.1, Steps: 1000, Reward: 125.25411278715832, Best reward: 302.6718960480857, Avg reward: 78.17099984457683\n","Episode: 228, Epsilon: 0.1, Steps: 243, Reward: 304.45689066641376, Best reward: 302.6718960480857, Avg reward: 79.92943515836907\n","... models saved successfully ...\n","Episode: 229, Epsilon: 0.1, Steps: 1000, Reward: 91.65759765720388, Best reward: 304.45689066641376, Avg reward: 79.9305213267597\n","Episode: 230, Epsilon: 0.1, Steps: 184, Reward: 247.08060875472552, Best reward: 304.45689066641376, Avg reward: 79.70075447638058\n","Episode: 231, Epsilon: 0.1, Steps: 213, Reward: 19.189216449102688, Best reward: 304.45689066641376, Avg reward: 77.49351290555201\n","Episode: 232, Epsilon: 0.1, Steps: 362, Reward: 234.4250386234788, Best reward: 304.45689066641376, Avg reward: 81.99738042747309\n","Episode: 233, Epsilon: 0.1, Steps: 806, Reward: 230.50399106674072, Best reward: 304.45689066641376, Avg reward: 85.51872248606968\n","Episode: 234, Epsilon: 0.1, Steps: 313, Reward: 229.2221108931766, Best reward: 304.45689066641376, Avg reward: 87.91052663482382\n","Episode: 235, Epsilon: 0.1, Steps: 106, Reward: 35.83473437171625, Best reward: 304.45689066641376, Avg reward: 88.32942509649175\n","Episode: 236, Epsilon: 0.1, Steps: 885, Reward: 145.1829023493516, Best reward: 304.45689066641376, Avg reward: 89.65073511090824\n","Episode: 237, Epsilon: 0.1, Steps: 1000, Reward: 45.38552316466845, Best reward: 304.45689066641376, Avg reward: 90.28291617829856\n","Episode: 238, Epsilon: 0.1, Steps: 589, Reward: 220.85394079526725, Best reward: 304.45689066641376, Avg reward: 92.33852348335695\n","Episode: 239, Epsilon: 0.1, Steps: 439, Reward: 258.3367278752843, Best reward: 304.45689066641376, Avg reward: 94.52666221615328\n","Episode: 240, Epsilon: 0.1, Steps: 348, Reward: 231.10843744117838, Best reward: 304.45689066641376, Avg reward: 95.59369752139906\n","Episode: 241, Epsilon: 0.1, Steps: 879, Reward: 192.39509441264386, Best reward: 304.45689066641376, Avg reward: 97.89327293058514\n","Episode: 242, Epsilon: 0.1, Steps: 383, Reward: 257.8872127918016, Best reward: 304.45689066641376, Avg reward: 100.41509687447095\n","Episode: 243, Epsilon: 0.1, Steps: 191, Reward: 275.14114853332944, Best reward: 304.45689066641376, Avg reward: 103.0876019434707\n","Episode: 244, Epsilon: 0.1, Steps: 658, Reward: 205.76566488982238, Best reward: 304.45689066641376, Avg reward: 103.65823089325588\n","Episode: 245, Epsilon: 0.1, Steps: 101, Reward: -167.17175427387917, Best reward: 304.45689066641376, Avg reward: 99.39016832800438\n","Episode: 246, Epsilon: 0.1, Steps: 1000, Reward: 141.1998462093245, Best reward: 304.45689066641376, Avg reward: 100.83156573632633\n","Episode: 247, Epsilon: 0.1, Steps: 539, Reward: 195.5694087273679, Best reward: 304.45689066641376, Avg reward: 100.7212139212675\n","Episode: 248, Epsilon: 0.1, Steps: 821, Reward: 274.0430818451581, Best reward: 304.45689066641376, Avg reward: 101.97326342778126\n","Episode: 249, Epsilon: 0.1, Steps: 722, Reward: 244.98594471955468, Best reward: 304.45689066641376, Avg reward: 104.76798853929054\n","Episode: 250, Epsilon: 0.1, Steps: 188, Reward: 251.68163875274297, Best reward: 304.45689066641376, Avg reward: 105.04983468152378\n","Episode: 251, Epsilon: 0.1, Steps: 617, Reward: 291.3720013891666, Best reward: 304.45689066641376, Avg reward: 107.24324613949169\n","Episode: 252, Epsilon: 0.1, Steps: 400, Reward: -94.70528514923008, Best reward: 304.45689066641376, Avg reward: 103.89093324966521\n","Episode: 253, Epsilon: 0.1, Steps: 624, Reward: 173.57637248776993, Best reward: 304.45689066641376, Avg reward: 103.2433193166503\n","Episode: 254, Epsilon: 0.1, Steps: 564, Reward: 241.98940446094815, Best reward: 304.45689066641376, Avg reward: 105.5460495829298\n","Episode: 255, Epsilon: 0.1, Steps: 255, Reward: 271.42183227042926, Best reward: 304.45689066641376, Avg reward: 108.04751973912808\n","Episode: 256, Epsilon: 0.1, Steps: 549, Reward: 217.64265470415538, Best reward: 304.45689066641376, Avg reward: 109.76720407419522\n","Episode: 257, Epsilon: 0.1, Steps: 457, Reward: 277.4974497333829, Best reward: 304.45689066641376, Avg reward: 109.90011005995642\n","Episode: 258, Epsilon: 0.1, Steps: 116, Reward: -9.128563969798108, Best reward: 304.45689066641376, Avg reward: 107.0574654696344\n","Episode: 259, Epsilon: 0.1, Steps: 170, Reward: 38.35991296928691, Best reward: 304.45689066641376, Avg reward: 105.36894954937114\n","Episode: 260, Epsilon: 0.1, Steps: 317, Reward: 239.75267533448434, Best reward: 304.45689066641376, Avg reward: 108.12127571396226\n","Episode: 261, Epsilon: 0.1, Steps: 1000, Reward: 96.6296200796574, Best reward: 304.45689066641376, Avg reward: 106.27572417828384\n","Episode: 262, Epsilon: 0.1, Steps: 463, Reward: 272.5392765816442, Best reward: 304.45689066641376, Avg reward: 106.66473849131413\n","Episode: 263, Epsilon: 0.1, Steps: 916, Reward: 224.8130319515986, Best reward: 304.45689066641376, Avg reward: 109.08405691547777\n","Episode: 264, Epsilon: 0.1, Steps: 546, Reward: -10.053166893364306, Best reward: 304.45689066641376, Avg reward: 106.26056888709509\n","Episode: 265, Epsilon: 0.1, Steps: 228, Reward: 298.8026494750533, Best reward: 304.45689066641376, Avg reward: 108.92422353362855\n","Episode: 266, Epsilon: 0.1, Steps: 306, Reward: 294.8851385519131, Best reward: 304.45689066641376, Avg reward: 111.87910541966265\n","Episode: 267, Epsilon: 0.1, Steps: 929, Reward: 208.82357515159734, Best reward: 304.45689066641376, Avg reward: 111.22478370421958\n","Episode: 268, Epsilon: 0.1, Steps: 99, Reward: -22.130351516686147, Best reward: 304.45689066641376, Avg reward: 110.74159794329326\n","Episode: 269, Epsilon: 0.1, Steps: 349, Reward: 231.38878437627557, Best reward: 304.45689066641376, Avg reward: 110.76254821838864\n","Episode: 270, Epsilon: 0.1, Steps: 80, Reward: -69.2326335915309, Best reward: 304.45689066641376, Avg reward: 109.16205872006087\n","Episode: 271, Epsilon: 0.1, Steps: 118, Reward: -25.564596452632927, Best reward: 304.45689066641376, Avg reward: 106.71382042217522\n","Episode: 272, Epsilon: 0.1, Steps: 124, Reward: -39.09586103955722, Best reward: 304.45689066641376, Avg reward: 104.18126568354063\n","Episode: 273, Epsilon: 0.1, Steps: 398, Reward: -89.83767906965313, Best reward: 304.45689066641376, Avg reward: 105.09120854774677\n","Episode: 274, Epsilon: 0.1, Steps: 433, Reward: 252.94517069618573, Best reward: 304.45689066641376, Avg reward: 107.66341269033327\n","Episode: 275, Epsilon: 0.1, Steps: 91, Reward: 28.941204989961477, Best reward: 304.45689066641376, Avg reward: 108.21164162212531\n","Episode: 276, Epsilon: 0.1, Steps: 430, Reward: 271.0236315212639, Best reward: 304.45689066641376, Avg reward: 111.60503068907597\n","Episode: 277, Epsilon: 0.1, Steps: 231, Reward: 227.38029665834648, Best reward: 304.45689066641376, Avg reward: 111.36182948156309\n","Episode: 278, Epsilon: 0.1, Steps: 523, Reward: 266.4610074719009, Best reward: 304.45689066641376, Avg reward: 114.15800415661984\n","Episode: 279, Epsilon: 0.1, Steps: 463, Reward: 220.42394606978146, Best reward: 304.45689066641376, Avg reward: 115.55708795032464\n","Episode: 280, Epsilon: 0.1, Steps: 281, Reward: 251.36006764336435, Best reward: 304.45689066641376, Avg reward: 117.9937166790431\n","Episode: 281, Epsilon: 0.1, Steps: 495, Reward: 245.68438602293395, Best reward: 304.45689066641376, Avg reward: 120.169836435746\n","Episode: 282, Epsilon: 0.1, Steps: 233, Reward: -76.28628041085827, Best reward: 304.45689066641376, Avg reward: 119.47752733020636\n","Episode: 283, Epsilon: 0.1, Steps: 697, Reward: 201.01756198370038, Best reward: 304.45689066641376, Avg reward: 120.24944789022747\n","Episode: 284, Epsilon: 0.1, Steps: 678, Reward: 203.7289548024582, Best reward: 304.45689066641376, Avg reward: 123.0129157794164\n","Episode: 285, Epsilon: 0.1, Steps: 302, Reward: 243.69768719504577, Best reward: 304.45689066641376, Avg reward: 123.17354030495422\n","Episode: 286, Epsilon: 0.1, Steps: 493, Reward: 234.74528914356614, Best reward: 304.45689066641376, Avg reward: 126.51360300867998\n","Episode: 287, Epsilon: 0.1, Steps: 700, Reward: 257.87731800999626, Best reward: 304.45689066641376, Avg reward: 126.7747221405877\n","Episode: 288, Epsilon: 0.1, Steps: 1000, Reward: 7.749814803299782, Best reward: 304.45689066641376, Avg reward: 126.63956011463819\n","Episode: 289, Epsilon: 0.1, Steps: 470, Reward: 237.17181068268638, Best reward: 304.45689066641376, Avg reward: 128.60354761414865\n","Episode: 290, Epsilon: 0.1, Steps: 770, Reward: 192.3487575230414, Best reward: 304.45689066641376, Avg reward: 130.55238761159546\n","Episode: 291, Epsilon: 0.1, Steps: 978, Reward: 169.62840119546377, Best reward: 304.45689066641376, Avg reward: 132.24757797184301\n","Episode: 292, Epsilon: 0.1, Steps: 380, Reward: 285.36732119006695, Best reward: 304.45689066641376, Avg reward: 132.7663702365401\n","Episode: 293, Epsilon: 0.1, Steps: 636, Reward: 251.38397027845693, Best reward: 304.45689066641376, Avg reward: 134.54160210545797\n","Episode: 294, Epsilon: 0.1, Steps: 319, Reward: 261.37587062375974, Best reward: 304.45689066641376, Avg reward: 136.8473051233757\n","Episode: 295, Epsilon: 0.1, Steps: 197, Reward: 35.793493447663366, Best reward: 304.45689066641376, Avg reward: 135.42932636353004\n","Episode: 296, Epsilon: 0.1, Steps: 676, Reward: 270.49448958626385, Best reward: 304.45689066641376, Avg reward: 136.57754429968298\n","Episode: 297, Epsilon: 0.1, Steps: 376, Reward: 212.8590666891247, Best reward: 304.45689066641376, Avg reward: 140.61030062094628\n","Episode: 298, Epsilon: 0.1, Steps: 665, Reward: 247.1311275172176, Best reward: 304.45689066641376, Avg reward: 144.5399024496233\n","Episode: 299, Epsilon: 0.1, Steps: 902, Reward: 159.27112270989366, Best reward: 304.45689066641376, Avg reward: 146.89796982896095\n","Episode: 300, Epsilon: 0.1, Steps: 430, Reward: 237.30130852632954, Best reward: 304.45689066641376, Avg reward: 152.00487525578262\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x6dbc200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 301, Epsilon: 0.1, Steps: 126, Reward: -8.835234163861642, Best reward: 304.45689066641376, Avg reward: 149.02736802173698\n","Episode: 302, Epsilon: 0.1, Steps: 239, Reward: 239.6086051647276, Best reward: 304.45689066641376, Avg reward: 148.3967351129034\n","Episode: 303, Epsilon: 0.1, Steps: 373, Reward: 237.16852153335967, Best reward: 304.45689066641376, Avg reward: 148.1683088642412\n","Episode: 304, Epsilon: 0.1, Steps: 565, Reward: 210.85252795950504, Best reward: 304.45689066641376, Avg reward: 151.06523476288956\n","Episode: 305, Epsilon: 0.1, Steps: 102, Reward: -70.77224684952206, Best reward: 304.45689066641376, Avg reward: 150.36970265376092\n","Episode: 306, Epsilon: 0.1, Steps: 414, Reward: 227.3124605147689, Best reward: 304.45689066641376, Avg reward: 150.06407559275192\n","Episode: 307, Epsilon: 0.1, Steps: 464, Reward: 241.80388212750483, Best reward: 304.45689066641376, Avg reward: 152.7368134728232\n","Episode: 308, Epsilon: 0.1, Steps: 211, Reward: 320.3928236417836, Best reward: 304.45689066641376, Avg reward: 153.6077065708827\n","... models saved successfully ...\n","Episode: 309, Epsilon: 0.1, Steps: 280, Reward: 297.9872888608195, Best reward: 320.3928236417836, Avg reward: 154.51808326087175\n","Episode: 310, Epsilon: 0.1, Steps: 1000, Reward: 121.32224361538445, Best reward: 320.3928236417836, Avg reward: 155.63855687074164\n","Episode: 311, Epsilon: 0.1, Steps: 1000, Reward: 64.5319650126751, Best reward: 320.3928236417836, Avg reward: 155.9323938442545\n","Episode: 312, Epsilon: 0.1, Steps: 248, Reward: 276.2429355590374, Best reward: 320.3928236417836, Avg reward: 158.5123232577597\n","Episode: 313, Epsilon: 0.1, Steps: 396, Reward: 256.8729675940666, Best reward: 320.3928236417836, Avg reward: 158.39508852311087\n","Episode: 314, Epsilon: 0.1, Steps: 343, Reward: 229.75881948690483, Best reward: 320.3928236417836, Avg reward: 161.17742698016954\n","Episode: 315, Epsilon: 0.1, Steps: 270, Reward: 271.349436189732, Best reward: 320.3928236417836, Avg reward: 163.97073014607278\n","Episode: 316, Epsilon: 0.1, Steps: 315, Reward: 251.80450127028254, Best reward: 320.3928236417836, Avg reward: 167.10439255227084\n","Episode: 317, Epsilon: 0.1, Steps: 320, Reward: 256.36954539766015, Best reward: 320.3928236417836, Avg reward: 171.33208943442907\n","Episode: 318, Epsilon: 0.1, Steps: 510, Reward: 210.9433546662262, Best reward: 320.3928236417836, Avg reward: 175.18684164231558\n","Episode: 319, Epsilon: 0.1, Steps: 437, Reward: 266.13740306076113, Best reward: 320.3928236417836, Avg reward: 175.55106712844983\n","Episode: 320, Epsilon: 0.1, Steps: 453, Reward: 262.26987160040517, Best reward: 320.3928236417836, Avg reward: 178.43010927110186\n","Episode: 321, Epsilon: 0.1, Steps: 495, Reward: 227.98763427791295, Best reward: 320.3928236417836, Avg reward: 177.7920916881042\n","Episode: 322, Epsilon: 0.1, Steps: 443, Reward: 270.0664255492311, Best reward: 320.3928236417836, Avg reward: 178.03900757491385\n","Episode: 323, Epsilon: 0.1, Steps: 700, Reward: 236.5049571346619, Best reward: 320.3928236417836, Avg reward: 178.24342341058443\n","Episode: 324, Epsilon: 0.1, Steps: 1000, Reward: 58.59453947599632, Best reward: 320.3928236417836, Avg reward: 176.5730315581407\n","Episode: 325, Epsilon: 0.1, Steps: 261, Reward: 228.26652125166854, Best reward: 320.3928236417836, Avg reward: 178.58639213675593\n","Episode: 326, Epsilon: 0.1, Steps: 454, Reward: 283.92857372703065, Best reward: 320.3928236417836, Avg reward: 181.75082481567875\n","Episode: 327, Epsilon: 0.1, Steps: 124, Reward: -1.4753352255939092, Best reward: 320.3928236417836, Avg reward: 180.48353033555125\n","Episode: 328, Epsilon: 0.1, Steps: 584, Reward: 233.9186321315597, Best reward: 320.3928236417836, Avg reward: 179.77814775020272\n","Episode: 329, Epsilon: 0.1, Steps: 450, Reward: 273.64788298498365, Best reward: 320.3928236417836, Avg reward: 181.59805060348054\n","Episode: 330, Epsilon: 0.1, Steps: 393, Reward: 252.134749391487, Best reward: 320.3928236417836, Avg reward: 181.64859200984813\n","Episode: 331, Epsilon: 0.1, Steps: 367, Reward: 215.28560366599436, Best reward: 320.3928236417836, Avg reward: 183.60955588201708\n","Episode: 332, Epsilon: 0.1, Steps: 297, Reward: 264.3751968073782, Best reward: 320.3928236417836, Avg reward: 183.90905746385604\n","Episode: 333, Epsilon: 0.1, Steps: 737, Reward: 281.87594624963333, Best reward: 320.3928236417836, Avg reward: 184.422777015685\n","Episode: 334, Epsilon: 0.1, Steps: 345, Reward: 228.5066465375546, Best reward: 320.3928236417836, Avg reward: 184.41562237212875\n","Episode: 335, Epsilon: 0.1, Steps: 688, Reward: -76.49098353223643, Best reward: 320.3928236417836, Avg reward: 183.29236519308924\n","Episode: 336, Epsilon: 0.1, Steps: 102, Reward: 14.532155802415758, Best reward: 320.3928236417836, Avg reward: 181.98585772761984\n","Episode: 337, Epsilon: 0.1, Steps: 401, Reward: 267.5146519651796, Best reward: 320.3928236417836, Avg reward: 184.20714901562496\n","Episode: 338, Epsilon: 0.1, Steps: 584, Reward: 235.7680692732998, Best reward: 320.3928236417836, Avg reward: 184.3562903004053\n","Episode: 339, Epsilon: 0.1, Steps: 278, Reward: 244.81382830195207, Best reward: 320.3928236417836, Avg reward: 184.22106130467196\n","Episode: 340, Epsilon: 0.1, Steps: 898, Reward: 210.51484223388127, Best reward: 320.3928236417836, Avg reward: 184.01512535259903\n","Episode: 341, Epsilon: 0.1, Steps: 466, Reward: 231.1893439556596, Best reward: 320.3928236417836, Avg reward: 184.40306784802917\n","Episode: 342, Epsilon: 0.1, Steps: 557, Reward: -74.67498048983157, Best reward: 320.3928236417836, Avg reward: 181.07744591521282\n","Episode: 343, Epsilon: 0.1, Steps: 421, Reward: 199.79111200896727, Best reward: 320.3928236417836, Avg reward: 180.3239455499692\n","Episode: 344, Epsilon: 0.1, Steps: 559, Reward: 224.17512928001088, Best reward: 320.3928236417836, Avg reward: 180.50804019387107\n","Episode: 345, Epsilon: 0.1, Steps: 565, Reward: 283.11569931829865, Best reward: 320.3928236417836, Avg reward: 185.01091472979286\n","Episode: 346, Epsilon: 0.1, Steps: 513, Reward: 238.66239402082198, Best reward: 320.3928236417836, Avg reward: 185.98554020790786\n","Episode: 347, Epsilon: 0.1, Steps: 107, Reward: -3.6181487378244697, Best reward: 320.3928236417836, Avg reward: 183.99366463325597\n","Episode: 348, Epsilon: 0.1, Steps: 440, Reward: 265.978814184033, Best reward: 320.3928236417836, Avg reward: 183.91302195664468\n","Episode: 349, Epsilon: 0.1, Steps: 426, Reward: -155.5507751592961, Best reward: 320.3928236417836, Avg reward: 179.9076547578562\n","Episode: 350, Epsilon: 0.1, Steps: 355, Reward: 235.58010699783392, Best reward: 320.3928236417836, Avg reward: 179.74663944030712\n","Episode: 351, Epsilon: 0.1, Steps: 456, Reward: 255.38790760429646, Best reward: 320.3928236417836, Avg reward: 179.38679850245842\n","Episode: 352, Epsilon: 0.1, Steps: 1000, Reward: -21.441602525368186, Best reward: 320.3928236417836, Avg reward: 180.11943532869702\n","Episode: 353, Epsilon: 0.1, Steps: 313, Reward: 253.8736181190887, Best reward: 320.3928236417836, Avg reward: 180.9224077850102\n","Episode: 354, Epsilon: 0.1, Steps: 506, Reward: 198.6923697058312, Best reward: 320.3928236417836, Avg reward: 180.48943743745903\n","Episode: 355, Epsilon: 0.1, Steps: 304, Reward: 295.3677015271687, Best reward: 320.3928236417836, Avg reward: 180.72889613002636\n","Episode: 356, Epsilon: 0.1, Steps: 981, Reward: 208.75463834113586, Best reward: 320.3928236417836, Avg reward: 180.64001596639616\n","Episode: 357, Epsilon: 0.1, Steps: 451, Reward: 269.7627440813101, Best reward: 320.3928236417836, Avg reward: 180.56266890987547\n","Episode: 358, Epsilon: 0.1, Steps: 340, Reward: 254.28077916078098, Best reward: 320.3928236417836, Avg reward: 183.19676234118123\n","Episode: 359, Epsilon: 0.1, Steps: 373, Reward: 277.7580476688112, Best reward: 320.3928236417836, Avg reward: 185.59074368817653\n","Episode: 360, Epsilon: 0.1, Steps: 369, Reward: 192.7134331921094, Best reward: 320.3928236417836, Avg reward: 185.12035126675278\n","Episode: 361, Epsilon: 0.1, Steps: 725, Reward: 153.01195481280433, Best reward: 320.3928236417836, Avg reward: 185.6841746140843\n","Episode: 362, Epsilon: 0.1, Steps: 460, Reward: 238.2169806534554, Best reward: 320.3928236417836, Avg reward: 185.34095165480238\n","Episode: 363, Epsilon: 0.1, Steps: 384, Reward: 246.35974079655102, Best reward: 320.3928236417836, Avg reward: 185.5564187432519\n","Episode: 364, Epsilon: 0.1, Steps: 368, Reward: 242.21375706807297, Best reward: 320.3928236417836, Avg reward: 188.0790879828663\n","Episode: 365, Epsilon: 0.1, Steps: 666, Reward: 254.5458503890687, Best reward: 320.3928236417836, Avg reward: 187.63651999200638\n","Episode: 366, Epsilon: 0.1, Steps: 583, Reward: 233.12746861319545, Best reward: 320.3928236417836, Avg reward: 187.0189432926192\n","Episode: 367, Epsilon: 0.1, Steps: 516, Reward: 239.9979797501372, Best reward: 320.3928236417836, Avg reward: 187.33068733860463\n","Episode: 368, Epsilon: 0.1, Steps: 1000, Reward: 94.1831743858393, Best reward: 320.3928236417836, Avg reward: 188.49382259762987\n","Episode: 369, Epsilon: 0.1, Steps: 1000, Reward: 55.02245424596695, Best reward: 320.3928236417836, Avg reward: 186.73015929632675\n","Episode: 370, Epsilon: 0.1, Steps: 1000, Reward: 138.63433247228357, Best reward: 320.3928236417836, Avg reward: 188.80882895696493\n","Episode: 371, Epsilon: 0.1, Steps: 818, Reward: 216.84972989705358, Best reward: 320.3928236417836, Avg reward: 191.23297222046182\n","Episode: 372, Epsilon: 0.1, Steps: 446, Reward: 221.87612117097024, Best reward: 320.3928236417836, Avg reward: 193.8426920425671\n","Episode: 373, Epsilon: 0.1, Steps: 1000, Reward: 66.7788419747299, Best reward: 320.3928236417836, Avg reward: 195.40885725301095\n","Episode: 374, Epsilon: 0.1, Steps: 393, Reward: 163.28305862251696, Best reward: 320.3928236417836, Avg reward: 194.51223613227427\n","Episode: 375, Epsilon: 0.1, Steps: 1000, Reward: 104.90560901210785, Best reward: 320.3928236417836, Avg reward: 195.27188017249574\n","Episode: 376, Epsilon: 0.1, Steps: 561, Reward: 215.64175888730512, Best reward: 320.3928236417836, Avg reward: 194.7180614461561\n","Episode: 377, Epsilon: 0.1, Steps: 367, Reward: 258.32477771026583, Best reward: 320.3928236417836, Avg reward: 195.0275062566753\n","Episode: 378, Epsilon: 0.1, Steps: 382, Reward: -26.657878842315483, Best reward: 320.3928236417836, Avg reward: 192.09631739353313\n","Episode: 379, Epsilon: 0.1, Steps: 1000, Reward: 64.79762629192078, Best reward: 320.3928236417836, Avg reward: 190.54005419575458\n","Episode: 380, Epsilon: 0.1, Steps: 344, Reward: 277.22627295259144, Best reward: 320.3928236417836, Avg reward: 190.7987162488468\n","Episode: 381, Epsilon: 0.1, Steps: 486, Reward: 233.26577348205495, Best reward: 320.3928236417836, Avg reward: 190.674530123438\n","Episode: 382, Epsilon: 0.1, Steps: 635, Reward: -146.76785341446123, Best reward: 320.3928236417836, Avg reward: 189.96971439340194\n","Episode: 383, Epsilon: 0.1, Steps: 1000, Reward: 30.74878077783008, Best reward: 320.3928236417836, Avg reward: 188.26702658134323\n","Episode: 384, Epsilon: 0.1, Steps: 481, Reward: 188.74687885160566, Best reward: 320.3928236417836, Avg reward: 188.11720582183472\n","Episode: 385, Epsilon: 0.1, Steps: 473, Reward: 240.08504109160788, Best reward: 320.3928236417836, Avg reward: 188.08107936080035\n","Episode: 386, Epsilon: 0.1, Steps: 905, Reward: 194.75413041376817, Best reward: 320.3928236417836, Avg reward: 187.68116777350235\n","Episode: 387, Epsilon: 0.1, Steps: 416, Reward: 266.69825110259836, Best reward: 320.3928236417836, Avg reward: 187.76937710442837\n","Episode: 388, Epsilon: 0.1, Steps: 1000, Reward: 97.48304246903186, Best reward: 320.3928236417836, Avg reward: 188.66670938108572\n","Episode: 389, Epsilon: 0.1, Steps: 268, Reward: 259.47895781849456, Best reward: 320.3928236417836, Avg reward: 188.8897808524438\n","Episode: 390, Epsilon: 0.1, Steps: 1000, Reward: 74.35389812142651, Best reward: 320.3928236417836, Avg reward: 187.70983225842764\n","Episode: 391, Epsilon: 0.1, Steps: 511, Reward: 261.61232018962704, Best reward: 320.3928236417836, Avg reward: 188.62967144836927\n","Episode: 392, Epsilon: 0.1, Steps: 377, Reward: 261.0454693299784, Best reward: 320.3928236417836, Avg reward: 188.38645292976838\n","Episode: 393, Epsilon: 0.1, Steps: 158, Reward: -2.923815103029014, Best reward: 320.3928236417836, Avg reward: 185.84337507595353\n","Episode: 404, Epsilon: 0.1, Steps: 1000, Reward: -2.25238965713031, Best reward: 320.3928236417836, Avg reward: 162.60431669216072\n","Episode: 405, Epsilon: 0.1, Steps: 384, Reward: 257.21274973033053, Best reward: 320.3928236417836, Avg reward: 165.88416665795924\n","Episode: 406, Epsilon: 0.1, Steps: 492, Reward: -64.988861239441, Best reward: 320.3928236417836, Avg reward: 162.96115344041712\n","Episode: 407, Epsilon: 0.1, Steps: 502, Reward: 166.61157294544017, Best reward: 320.3928236417836, Avg reward: 162.2092303485965\n","Episode: 408, Epsilon: 0.1, Steps: 444, Reward: 212.55511815965343, Best reward: 320.3928236417836, Avg reward: 161.1308532937752\n","Episode: 409, Epsilon: 0.1, Steps: 425, Reward: 226.66838043433634, Best reward: 320.3928236417836, Avg reward: 160.41766420951038\n","Episode: 410, Epsilon: 0.1, Steps: 1000, Reward: -98.37358305940663, Best reward: 320.3928236417836, Avg reward: 158.22070594276246\n","Episode: 411, Epsilon: 0.1, Steps: 460, Reward: 199.21364323048002, Best reward: 320.3928236417836, Avg reward: 159.5675227249405\n","Episode: 412, Epsilon: 0.1, Steps: 540, Reward: 239.61696707366448, Best reward: 320.3928236417836, Avg reward: 159.2012630400868\n","Episode: 413, Epsilon: 0.1, Steps: 1000, Reward: 56.46200020071126, Best reward: 320.3928236417836, Avg reward: 157.19715336615323\n","Episode: 414, Epsilon: 0.1, Steps: 746, Reward: 251.77203099645598, Best reward: 320.3928236417836, Avg reward: 157.41728548124874\n","Episode: 415, Epsilon: 0.1, Steps: 777, Reward: 228.8352112890887, Best reward: 320.3928236417836, Avg reward: 156.9921432322423\n","Episode: 416, Epsilon: 0.1, Steps: 169, Reward: -171.1131414623257, Best reward: 320.3928236417836, Avg reward: 152.76296680491623\n","Episode: 417, Epsilon: 0.1, Steps: 450, Reward: 228.60665036802817, Best reward: 320.3928236417836, Avg reward: 152.4853378546199\n","Episode: 418, Epsilon: 0.1, Steps: 358, Reward: 263.68844091036317, Best reward: 320.3928236417836, Avg reward: 153.0127887170613\n","Episode: 419, Epsilon: 0.1, Steps: 549, Reward: 279.8918360695077, Best reward: 320.3928236417836, Avg reward: 153.15033304714876\n","Episode: 420, Epsilon: 0.1, Steps: 941, Reward: 169.00095882996382, Best reward: 320.3928236417836, Avg reward: 152.21764391944436\n","Episode: 421, Epsilon: 0.1, Steps: 473, Reward: 154.99038036429394, Best reward: 320.3928236417836, Avg reward: 151.48767138030814\n","Episode: 422, Epsilon: 0.1, Steps: 1000, Reward: -75.65295785936908, Best reward: 320.3928236417836, Avg reward: 148.03047754622216\n","Episode: 423, Epsilon: 0.1, Steps: 127, Reward: -20.379792566621774, Best reward: 320.3928236417836, Avg reward: 145.4616300492093\n","Episode: 424, Epsilon: 0.1, Steps: 1000, Reward: 116.52974427236467, Best reward: 320.3928236417836, Avg reward: 146.04098209717299\n","Episode: 425, Epsilon: 0.1, Steps: 480, Reward: 225.38130011151074, Best reward: 320.3928236417836, Avg reward: 146.0121298857714\n","Episode: 426, Epsilon: 0.1, Steps: 311, Reward: 238.23946080956858, Best reward: 320.3928236417836, Avg reward: 145.5552387565968\n","Episode: 427, Epsilon: 0.1, Steps: 303, Reward: 280.486151367135, Best reward: 320.3928236417836, Avg reward: 148.37485362252409\n","Episode: 428, Epsilon: 0.1, Steps: 706, Reward: 191.2375133447576, Best reward: 320.3928236417836, Avg reward: 147.94804243465606\n","Episode: 429, Epsilon: 0.1, Steps: 905, Reward: 210.0316374864704, Best reward: 320.3928236417836, Avg reward: 147.31187997967095\n","Episode: 430, Epsilon: 0.1, Steps: 265, Reward: 226.54970493648642, Best reward: 320.3928236417836, Avg reward: 147.0560295351209\n","Episode: 431, Epsilon: 0.1, Steps: 274, Reward: 285.86587605122804, Best reward: 320.3928236417836, Avg reward: 147.76183225897324\n","Episode: 432, Epsilon: 0.1, Steps: 635, Reward: 173.23230790855598, Best reward: 320.3928236417836, Avg reward: 146.85040336998503\n","Episode: 433, Epsilon: 0.1, Steps: 513, Reward: 234.34954155456956, Best reward: 320.3928236417836, Avg reward: 146.3751393230344\n","Episode: 434, Epsilon: 0.1, Steps: 471, Reward: 207.72292747867255, Best reward: 320.3928236417836, Avg reward: 146.16730213244557\n","Episode: 435, Epsilon: 0.1, Steps: 351, Reward: 224.65273496136064, Best reward: 320.3928236417836, Avg reward: 149.17873931738157\n","Episode: 436, Epsilon: 0.1, Steps: 1000, Reward: 106.75060217406293, Best reward: 320.3928236417836, Avg reward: 150.10092378109803\n","Episode: 437, Epsilon: 0.1, Steps: 349, Reward: 253.09900883214698, Best reward: 320.3928236417836, Avg reward: 149.95676734976772\n","Episode: 438, Epsilon: 0.1, Steps: 391, Reward: 275.9690312398519, Best reward: 320.3928236417836, Avg reward: 150.35877696943322\n","Episode: 439, Epsilon: 0.1, Steps: 491, Reward: 287.88129324320175, Best reward: 320.3928236417836, Avg reward: 150.7894516188457\n","Episode: 440, Epsilon: 0.1, Steps: 464, Reward: 277.52912664292666, Best reward: 320.3928236417836, Avg reward: 151.45959446293617\n","Episode: 441, Epsilon: 0.1, Steps: 256, Reward: 259.2688728292966, Best reward: 320.3928236417836, Avg reward: 151.74038975167252\n","Episode: 442, Epsilon: 0.1, Steps: 315, Reward: 235.64873640226847, Best reward: 320.3928236417836, Avg reward: 154.84362692059352\n","Episode: 443, Epsilon: 0.1, Steps: 310, Reward: 268.2870163403083, Best reward: 320.3928236417836, Avg reward: 155.52858596390695\n","Episode: 444, Epsilon: 0.1, Steps: 259, Reward: 228.92152552644305, Best reward: 320.3928236417836, Avg reward: 155.57604992637124\n","Episode: 445, Epsilon: 0.1, Steps: 606, Reward: 235.81570156856006, Best reward: 320.3928236417836, Avg reward: 155.10304994887386\n","Episode: 446, Epsilon: 0.1, Steps: 549, Reward: 246.52905070069372, Best reward: 320.3928236417836, Avg reward: 155.18171651567258\n","Episode: 447, Epsilon: 0.1, Steps: 540, Reward: 241.7115846958982, Best reward: 320.3928236417836, Avg reward: 157.6350138500098\n","Episode: 448, Epsilon: 0.1, Steps: 457, Reward: 275.9438442724115, Best reward: 320.3928236417836, Avg reward: 157.7346641508936\n","Episode: 449, Epsilon: 0.1, Steps: 383, Reward: 243.0846906034113, Best reward: 320.3928236417836, Avg reward: 161.72101880852068\n","Episode: 450, Epsilon: 0.1, Steps: 734, Reward: 157.65951360053745, Best reward: 320.3928236417836, Avg reward: 160.94181287454774\n","Episode: 451, Epsilon: 0.1, Steps: 728, Reward: 211.38847569862133, Best reward: 320.3928236417836, Avg reward: 160.50181855549096\n","Episode: 452, Epsilon: 0.1, Steps: 471, Reward: 272.16603550712443, Best reward: 320.3928236417836, Avg reward: 163.4378949358159\n","Episode: 453, Epsilon: 0.1, Steps: 101, Reward: 8.958325556206873, Best reward: 320.3928236417836, Avg reward: 160.98874201018705\n","Episode: 454, Epsilon: 0.1, Steps: 710, Reward: 258.74782024942067, Best reward: 320.3928236417836, Avg reward: 161.58929651562295\n","Episode: 455, Epsilon: 0.1, Steps: 304, Reward: 239.73682690876456, Best reward: 320.3928236417836, Avg reward: 161.0329877694389\n","Episode: 456, Epsilon: 0.1, Steps: 421, Reward: 198.30977663779476, Best reward: 320.3928236417836, Avg reward: 160.9285391524055\n","Episode: 457, Epsilon: 0.1, Steps: 385, Reward: 251.9439269508881, Best reward: 320.3928236417836, Avg reward: 160.75035098110126\n","Episode: 458, Epsilon: 0.1, Steps: 407, Reward: 282.9143256402416, Best reward: 320.3928236417836, Avg reward: 161.0366864458959\n","Episode: 459, Epsilon: 0.1, Steps: 469, Reward: 246.35151999578957, Best reward: 320.3928236417836, Avg reward: 160.72262116916568\n","Episode: 460, Epsilon: 0.1, Steps: 703, Reward: 185.28350507633974, Best reward: 320.3928236417836, Avg reward: 160.64832188800798\n","Episode: 461, Epsilon: 0.1, Steps: 304, Reward: 260.47569735690297, Best reward: 320.3928236417836, Avg reward: 161.722959313449\n","Episode: 462, Epsilon: 0.1, Steps: 155, Reward: -22.252597059162056, Best reward: 320.3928236417836, Avg reward: 159.11826353632281\n","Episode: 463, Epsilon: 0.1, Steps: 1000, Reward: 99.9610631780872, Best reward: 320.3928236417836, Avg reward: 157.6542767601382\n","Episode: 464, Epsilon: 0.1, Steps: 489, Reward: 185.47114968429327, Best reward: 320.3928236417836, Avg reward: 157.08685068630038\n","Episode: 465, Epsilon: 0.1, Steps: 160, Reward: 37.939744986714345, Best reward: 320.3928236417836, Avg reward: 154.92078963227684\n","Episode: 466, Epsilon: 0.1, Steps: 368, Reward: 251.92370870937262, Best reward: 320.3928236417836, Avg reward: 155.1087520332386\n","Episode: 467, Epsilon: 0.1, Steps: 294, Reward: 280.05203081974446, Best reward: 320.3928236417836, Avg reward: 155.5092925439347\n","Episode: 468, Epsilon: 0.1, Steps: 471, Reward: 248.13500189028795, Best reward: 320.3928236417836, Avg reward: 157.04881081897918\n","Episode: 469, Epsilon: 0.1, Steps: 523, Reward: 207.89572103325588, Best reward: 320.3928236417836, Avg reward: 158.57754348685205\n","Episode: 470, Epsilon: 0.1, Steps: 254, Reward: 199.17986206685003, Best reward: 320.3928236417836, Avg reward: 159.1829987827977\n","Episode: 471, Epsilon: 0.1, Steps: 445, Reward: 241.16510036368933, Best reward: 320.3928236417836, Avg reward: 159.42615248746407\n","Episode: 472, Epsilon: 0.1, Steps: 386, Reward: 251.49434204961292, Best reward: 320.3928236417836, Avg reward: 159.7223346962505\n","Episode: 473, Epsilon: 0.1, Steps: 214, Reward: 233.30456889549055, Best reward: 320.3928236417836, Avg reward: 161.3875919654581\n","Episode: 474, Epsilon: 0.1, Steps: 318, Reward: 198.0234397288158, Best reward: 320.3928236417836, Avg reward: 161.73499577652106\n","Episode: 475, Epsilon: 0.1, Steps: 388, Reward: 167.8336250473277, Best reward: 320.3928236417836, Avg reward: 162.36427593687327\n","Episode: 476, Epsilon: 0.1, Steps: 139, Reward: 52.23095890622926, Best reward: 320.3928236417836, Avg reward: 160.73016793706253\n","Episode: 477, Epsilon: 0.1, Steps: 721, Reward: 166.8674493904976, Best reward: 320.3928236417836, Avg reward: 159.81559465386488\n","Episode: 478, Epsilon: 0.1, Steps: 469, Reward: 216.97695091834476, Best reward: 320.3928236417836, Avg reward: 162.25194295147145\n","Episode: 479, Epsilon: 0.1, Steps: 505, Reward: 220.62913851897895, Best reward: 320.3928236417836, Avg reward: 163.81025807374206\n","Episode: 480, Epsilon: 0.1, Steps: 407, Reward: 261.2882428885573, Best reward: 320.3928236417836, Avg reward: 163.65087777310168\n","Episode: 481, Epsilon: 0.1, Steps: 413, Reward: -223.9031119485558, Best reward: 320.3928236417836, Avg reward: 159.07918891879558\n","Episode: 482, Epsilon: 0.1, Steps: 311, Reward: 265.40970539781875, Best reward: 320.3928236417836, Avg reward: 163.20096450691838\n","Episode: 483, Epsilon: 0.1, Steps: 458, Reward: 291.00279747237687, Best reward: 320.3928236417836, Avg reward: 165.80350467386387\n","Episode: 484, Epsilon: 0.1, Steps: 919, Reward: 224.9400706061112, Best reward: 320.3928236417836, Avg reward: 166.16543659140888\n","Episode: 485, Epsilon: 0.1, Steps: 213, Reward: 25.807360272770026, Best reward: 320.3928236417836, Avg reward: 164.02265978322052\n","Episode: 486, Epsilon: 0.1, Steps: 918, Reward: 232.87212046522475, Best reward: 320.3928236417836, Avg reward: 164.4038396837351\n","Episode: 487, Epsilon: 0.1, Steps: 1000, Reward: 87.84908112617835, Best reward: 320.3928236417836, Avg reward: 162.6153479839709\n","Episode: 488, Epsilon: 0.1, Steps: 280, Reward: 279.5847337011155, Best reward: 320.3928236417836, Avg reward: 164.43636489629174\n","Episode: 489, Epsilon: 0.1, Steps: 280, Reward: 271.17987739202476, Best reward: 320.3928236417836, Avg reward: 164.55337409202704\n","Episode: 490, Epsilon: 0.1, Steps: 321, Reward: 269.57575875964307, Best reward: 320.3928236417836, Avg reward: 166.50559269840923\n","Episode: 491, Epsilon: 0.1, Steps: 391, Reward: 251.3354737807435, Best reward: 320.3928236417836, Avg reward: 166.40282423432035\n","Episode: 492, Epsilon: 0.1, Steps: 341, Reward: 231.9246851038028, Best reward: 320.3928236417836, Avg reward: 166.11161639205864\n","Episode: 493, Epsilon: 0.1, Steps: 566, Reward: 229.89911737340316, Best reward: 320.3928236417836, Avg reward: 168.43984571682293\n","Episode: 494, Epsilon: 0.1, Steps: 729, Reward: 257.96336371831546, Best reward: 320.3928236417836, Avg reward: 169.81068416502274\n","Episode: 495, Epsilon: 0.1, Steps: 318, Reward: 312.6129041238434, Best reward: 320.3928236417836, Avg reward: 174.348547249609\n","Episode: 496, Epsilon: 0.1, Steps: 790, Reward: 256.3869818117775, Best reward: 320.3928236417836, Avg reward: 178.02140416165454\n","Episode: 497, Epsilon: 0.1, Steps: 339, Reward: 263.7770086351009, Best reward: 320.3928236417836, Avg reward: 182.64453158993862\n","Episode: 498, Epsilon: 0.1, Steps: 388, Reward: 265.2910297593123, Best reward: 320.3928236417836, Avg reward: 182.6145899897445\n","Episode: 499, Epsilon: 0.1, Steps: 245, Reward: 204.91532329103578, Best reward: 320.3928236417836, Avg reward: 186.3396195653496\n","Episode: 500, Epsilon: 0.1, Steps: 524, Reward: 271.2461805719063, Best reward: 320.3928236417836, Avg reward: 189.41950968259127\n"]},{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x749e200] Warning: data is not aligned! This can lead to a speed loss\n"]},{"name":"stdout","output_type":"stream","text":["Episode: 501, Epsilon: 0.1, Steps: 513, Reward: 224.3989907508593, Best reward: 320.3928236417836, Avg reward: 191.53060662420182\n","Episode: 502, Epsilon: 0.1, Steps: 174, Reward: 47.383241374978894, Best reward: 320.3928236417836, Avg reward: 194.78587724718855\n","Episode: 503, Epsilon: 0.1, Steps: 926, Reward: 212.4936645193525, Best reward: 320.3928236417836, Avg reward: 193.79085809366944\n","Episode: 504, Epsilon: 0.1, Steps: 204, Reward: -5.048939709834983, Best reward: 320.3928236417836, Avg reward: 193.76289259314242\n","Episode: 505, Epsilon: 0.1, Steps: 346, Reward: 222.60060850353062, Best reward: 320.3928236417836, Avg reward: 193.41677118087443\n","Episode: 506, Epsilon: 0.1, Steps: 146, Reward: 68.45783366376472, Best reward: 320.3928236417836, Avg reward: 194.75123812990645\n","Episode: 507, Epsilon: 0.1, Steps: 365, Reward: 245.64136071641124, Best reward: 320.3928236417836, Avg reward: 195.54153600761612\n","Episode: 508, Epsilon: 0.1, Steps: 324, Reward: 233.27528061177372, Best reward: 320.3928236417836, Avg reward: 195.7487376321374\n","Episode: 509, Epsilon: 0.1, Steps: 1000, Reward: 53.48382304839177, Best reward: 320.3928236417836, Avg reward: 194.0168920582779\n","Episode: 510, Epsilon: 0.1, Steps: 343, Reward: 244.68192574697744, Best reward: 320.3928236417836, Avg reward: 197.44744714634177\n","Episode: 511, Epsilon: 0.1, Steps: 462, Reward: -106.54785855773123, Best reward: 320.3928236417836, Avg reward: 194.38983212845963\n","Episode: 512, Epsilon: 0.1, Steps: 347, Reward: 294.71771231736807, Best reward: 320.3928236417836, Avg reward: 194.94083958089664\n","Episode: 513, Epsilon: 0.1, Steps: 387, Reward: 222.38849977935055, Best reward: 320.3928236417836, Avg reward: 196.60010457668304\n","Episode: 514, Epsilon: 0.1, Steps: 365, Reward: 284.3756818831066, Best reward: 320.3928236417836, Avg reward: 196.92614108554957\n","Episode: 515, Epsilon: 0.1, Steps: 546, Reward: 206.14276706320962, Best reward: 320.3928236417836, Avg reward: 196.6992166432908\n","Episode: 516, Epsilon: 0.1, Steps: 442, Reward: 187.910960892766, Best reward: 320.3928236417836, Avg reward: 200.2894576668417\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import gymnasium as gym\n","import time\n","import signal\n","import time\n","import sys\n","import pickle\n","\n","env = make_env(\"LunarLander-v2\", \"videos/\", 50)\n","action_space = [_ for _ in range(env.action_space.n)]\n","record = True\n","\n","\n","trainer_params = {\n","    \"noe\": 650, \n","    \"max_steps\": 10000,\n","    \"max_eps\": 1,\n","    \"min_eps\": 0.1,\n","    \"eps_decay_rate\": 1e-4,\n","    \"eps\": 1,\n","    \"action_space\": action_space,\n","    \"is_tg\": True,\n","    \"tg_bot_freq_epi\": 10,\n","    \"record\": record,\n","    \"gamma\": 0.99, \n","    \"lr\": 0.0001, \n","    \"input_dims\": env.observation_space.shape,\n","    \"mem_size\" : 100000,\n","    \"batch_size\" : 32,\n","    \"replace\" : 150,\n","    \"algo\" : \"DDQN\",\n","    \"env_name\" : \"lunarlander\",\n","    \"n_actions\" : len(action_space),\n","    \"chkpt_dir\": \"tmp/ddqn/\",\n","    \"actions\": action_space,\n","    \"target_score\": 200,\n","    \"tau\": 0.1,\n","    \"soft_update\": True,\n","    \"video_prefix\": \"ddqn\",\n","    \"checkpoint\": False\n","}\n","\n","    \n","if __name__ == \"__main__\": \n","    \n","    try: \n","        manage_memory()\n","       \n","        trainer = Trainer(env, trainer_params)\n","        episode_rewards, epsilon_history, avg_rewards, best_reward = trainer.train_rl_model()\n","        \n","        with open(\"ddqn_episode_rewards.obj\", \"wb\") as f: \n","            pickle.dump(episode_rewards, f)\n","        \n","        with open(\"ddqn_epsilon_history.obj\", \"wb\") as f: \n","            pickle.dump(epsilon_history, f)\n","        \n","        with open(\"ddqn_avg_rewards.obj\", \"wb\") as f: \n","            pickle.dump(avg_rewards, f)\n","            \n","        plot_learning_curve(episode_rewards, epsilon_history, \"vanilla_ddqn\")\n","        \n","    except Exception as error: \n","        raise error\n","        \n","   # eval_model(env, \"keras model\", \"videos/\", fps=10)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T10:54:09.623307Z","iopub.status.busy":"2023-03-15T10:54:09.622760Z","iopub.status.idle":"2023-03-15T10:54:09.641144Z","shell.execute_reply":"2023-03-15T10:54:09.638834Z","shell.execute_reply.started":"2023-03-15T10:54:09.623255Z"},"trusted":true},"outputs":[],"source":["import random \n","import imageio\n","import tensorflow as tf   \n","    \n","    \n","          \n","\n","class Eval: \n","\n","    def __init__(self, env, model_path, action_space, number_of_episode=50, test_video_path=\"test_videos/\"):\n","        self.env = env \n","        self.model = tf.keras.models.load_model(model_path)\n","        self.recorder = RecordVideo('dqn_lunarlander_test', test_video_path, 15)\n","        self.number_of_episode = number_of_episode\n","        self.action_space = action_space\n","        \n","    def test(self): \n","        rewards = []\n","        steps = []\n","        for episode in range(self.number_of_episode): \n","            done = False\n","            reward = 0\n","            step = 0\n","            state = env.reset(seed=random.randint(0,500))\n","            if episode % 5 == 0: \n","                img = env.render()\n","                self.recorder.add_image(img) \n","\n","            while not done:\n","                if type(state) == tuple: \n","                    state = state[0]\n","                    \n","                action =  greedy_policy(state, self.model, self.action_space)\n","                state, reward_prob, terminated, truncated, _ = env.step(action)\n","                done = terminated or truncated \n","                reward += reward_prob\n","                step += 1 \n","                if episode % 10 == 0:\n","                    img = env.render()\n","                    self.recorder.add_image(img)\n","            \n","            rewards.append(reward)\n","            steps.append(step)\n","            self.recorder.save(1) if episode % 5 == 0 else None\n","        \n","        return rewards, steps                                                                                                                                                        \n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T10:55:19.981699Z","iopub.status.busy":"2023-03-15T10:55:19.981311Z","iopub.status.idle":"2023-03-15T10:55:20.386171Z","shell.execute_reply":"2023-03-15T10:55:20.384576Z","shell.execute_reply.started":"2023-03-15T10:55:19.981658Z"},"trusted":true},"outputs":[],"source":["env = make_env(\"LunarLander-v2\", \"videos/\", 50)\n","action_space = [_ for _ in range(env.action_space.n)]\n","model_path = \"/kaggle/working/tmp/ddqn/lunarlander_DDQN_q_value/\"\n","\n","eval = Eval(env, model_path, action_space, 1)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T10:55:35.321150Z","iopub.status.busy":"2023-03-15T10:55:35.320718Z","iopub.status.idle":"2023-03-15T10:55:39.071284Z","shell.execute_reply":"2023-03-15T10:55:39.069999Z","shell.execute_reply.started":"2023-03-15T10:55:35.321108Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[swscaler @ 0x73e4200] Warning: data is not aligned! This can lead to a speed loss\n"]}],"source":["test_rewards, steps = eval.test()"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-03-15T10:55:44.431895Z","iopub.status.busy":"2023-03-15T10:55:44.430735Z","iopub.status.idle":"2023-03-15T10:55:44.441174Z","shell.execute_reply":"2023-03-15T10:55:44.439970Z","shell.execute_reply.started":"2023-03-15T10:55:44.431846Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[253.02580494015186]"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["test_rewards"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
