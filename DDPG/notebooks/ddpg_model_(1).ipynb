{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari] --quiet\n",
        "!pip install gymnasium --quiet\n",
        "!pip install -U gymnasium[atari] --quiet\n",
        "!pip install imageio_ffmpeg --quiet\n",
        "!pip install npy_append_array --quiet\n",
        "!pip install pyTelegramBotAPI --quiet\n",
        "!pip install gymnasium[accept-rom-license] --quiet\n",
        "!pip install gymnasium[box2d] --quiet"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-03-26T10:49:41.685275Z",
          "iopub.execute_input": "2023-03-26T10:49:41.685818Z",
          "iopub.status.idle": "2023-03-26T10:51:22.287625Z",
          "shell.execute_reply.started": "2023-03-26T10:49:41.685787Z",
          "shell.execute_reply": "2023-03-26T10:51:22.286315Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuN30ouc3RQ6",
        "outputId": "2545d427-d0f2-4d4f-b15f-044ab0aeea86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.9/244.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9-5w2On3RRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class ExperienceReplayBuffer:\n",
        "    def __init__(self, max_memory, input_shape, batch_size, n_actions, cer=False):\n",
        "        self.mem_size = max_memory\n",
        "        self.mem_counter = 0\n",
        "        self.state_memory = np.zeros((self.mem_size, *input_shape),\n",
        "                                     dtype=np.float32)\n",
        "        self.next_state_memory = np.zeros((self.mem_size, *input_shape),\n",
        "                                         dtype=np.float32)\n",
        "\n",
        "        self.action_memory = np.zeros((self.mem_size, n_actions), dtype=np.float32)\n",
        "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
        "        self.terminal_memory = np.zeros(self.mem_size, dtype=bool)\n",
        "        self.batch_size = batch_size\n",
        "        self.cer = cer\n",
        "\n",
        "    def store_experience(self, state, action, reward, next_state, done):\n",
        "        index = self.mem_counter % self.mem_size\n",
        "\n",
        "        self.state_memory[index] = state\n",
        "        self.next_state_memory[index] = next_state\n",
        "        self.reward_memory[index] = reward\n",
        "        self.action_memory[index] = action\n",
        "        self.terminal_memory[index] = done\n",
        "        self.mem_counter += 1\n",
        "\n",
        "    def sample_experience(self, batch_size):\n",
        "        # used to get the last transition\n",
        "        offset = 1 if self.cer else 0\n",
        "\n",
        "        max_mem = min(self.mem_counter, self.mem_size) - offset\n",
        "        batch_index = np.random.choice(max_mem, batch_size - offset, replace=False)\n",
        "\n",
        "        states = self.state_memory[batch_index]\n",
        "        next_states = self.next_state_memory[batch_index]\n",
        "        rewards = self.reward_memory[batch_index]\n",
        "        actions = self.action_memory[batch_index]\n",
        "        terminals = self.terminal_memory[batch_index]\n",
        "\n",
        "        if self.cer:\n",
        "            last_index = self.mem_counter % self.mem_size - 1\n",
        "            last_state = self.state_memory[last_index]\n",
        "            last_action = self.action_memory[last_index]\n",
        "            last_terminal = self.terminal_memory[last_index]\n",
        "            last_next_state = self.next_state_memory[last_index]\n",
        "            last_reward = self.reward_memory[last_index]\n",
        "\n",
        "            # for 2d and 3d use vstack to append, for 1d array use append() to append the data\n",
        "            states = np.vstack((self.state_memory[batch_index], last_state))\n",
        "            next_states = np.vstack((self.next_state_memory[batch_index], last_next_state))\n",
        "\n",
        "            actions = np.append(actions, last_action)\n",
        "            terminals = np.append(terminals, last_terminal)\n",
        "            rewards = np.append(rewards, last_reward)\n",
        "\n",
        "        return states, actions, rewards, next_states, terminals\n",
        "\n",
        "\n",
        "    def is_sufficient(self):\n",
        "        return self.mem_counter > self.batch_size\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T10:51:22.290261Z",
          "iopub.execute_input": "2023-03-26T10:51:22.290573Z",
          "iopub.status.idle": "2023-03-26T10:51:22.307612Z",
          "shell.execute_reply.started": "2023-03-26T10:51:22.290541Z",
          "shell.execute_reply": "2023-03-26T10:51:22.306443Z"
        },
        "trusted": true,
        "id": "aplOeq6G3RRM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7s1mTnS3RRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Input, Lambda, concatenate\n",
        "\n",
        "class ActorNetwork(tf.keras.Model):\n",
        "    def __init__(self, input_dims, action_bound, action_dims, name):\n",
        "        super(ActorNetwork, self).__init__()\n",
        "        self.model_name = name\n",
        "        self.input_dims = input_dims\n",
        "        self.action_bound = action_bound\n",
        "        self.action_dims = action_dims\n",
        "\n",
        "        self.fc1 = Dense(64, activation=\"relu\", input_shape=input_dims, kernel_initializer=\"he_uniform\")\n",
        "        self.fc2 = Dense(32, activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
        "        self.fc3 = Dense(32, activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
        "        self.out = Dense(action_dims, activation='tanh')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"model_name\": self.model_name,\n",
        "            \"input_dims\": self.input_dims,\n",
        "            \"action_bound\": self.action_bound,\n",
        "            \"action_dims\": self.action_dims,\n",
        "          })\n",
        "        return config\n",
        "\n",
        "\n",
        "class CriticNetwork(tf.keras.Model):\n",
        "    def __init__(self, input_dims, action_dims, name):\n",
        "        super(CriticNetwork, self).__init__()\n",
        "        self.model_name = name\n",
        "        self.input_dims = input_dims\n",
        "        self.action_dims = action_dims\n",
        "\n",
        "        self.fc1 = Dense(64, activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
        "        self.fc2 = Dense(32, activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
        "        self.fc3 = Dense(32, activation=\"relu\", kernel_initializer=\"he_uniform\")\n",
        "        self.out = Dense(1, activation='linear')\n",
        "\n",
        "    def call(self, state, action):\n",
        "        x = self.fc1(tf.concat([state, action], axis=1))\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"model_name\": self.model_name,\n",
        "            \"input_dims\": self.input_dims,\n",
        "            \"action_dims\": self.action_dims,\n",
        "          })\n",
        "        return config"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T10:51:22.309431Z",
          "iopub.execute_input": "2023-03-26T10:51:22.309818Z",
          "iopub.status.idle": "2023-03-26T10:51:22.325701Z",
          "shell.execute_reply.started": "2023-03-26T10:51:22.309781Z",
          "shell.execute_reply": "2023-03-26T10:51:22.324680Z"
        },
        "trusted": true,
        "id": "1I3XF2gO3RRT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVxQ40xl3RRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "\n",
        "class DDPGAgent:\n",
        "\n",
        "    def __init__(self, input_dims, n_actions, gamma, alpha, beta,\n",
        "                                batch_size, mem_size, soft_update,\n",
        "                                tau, min_action, max_action, noise):\n",
        "        self.gamma = gamma\n",
        "        self.noise = noise\n",
        "        self.n_actions = n_actions\n",
        "        self.soft_update = soft_update\n",
        "        self.tau = tau\n",
        "        self.fname = \"models/ddpg/\"\n",
        "        self.min_action = min_action\n",
        "        self.max_action = max_action\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.memory = ExperienceReplayBuffer(mem_size, input_dims, batch_size, n_actions, cer=False)\n",
        "        self.actor = ActorNetwork(input_dims, max_action, n_actions, \"actor\")\n",
        "        self.target_actor = ActorNetwork(input_dims, max_action, n_actions, \"target_actor\")\n",
        "        self.critic = CriticNetwork(input_dims, 1, \"critic\")\n",
        "        self.target_critic = CriticNetwork(input_dims, 1, \"target_critic_\")\n",
        "        self.actor.compile(optimizer=Adam(learning_rate=alpha))\n",
        "        self.critic.compile(optimizer=Adam(learning_rate=beta))\n",
        "        self.target_actor.compile(optimizer=Adam(learning_rate=alpha))\n",
        "        self.target_critic.compile(optimizer=Adam(learning_rate=beta))\n",
        "        self.bg_noise = np.zeros(n_actions)\n",
        "\n",
        "        self.update_target_networks()\n",
        "\n",
        "    def ou_noise(self, x, rho=0.15, mu=0, dt=1e-1, sigma=0.2, dim=1):\n",
        "        return x + rho * (mu-x) * dt + sigma * np.sqrt(dt) * np.random.normal(size=dim)\n",
        "\n",
        "    def get_action(self, state, evaluate):\n",
        "        # adding noise, makes us to do the exploration,\n",
        "        state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
        "        actions = self.actor(state)\n",
        "        noise = self.ou_noise(self.bg_noise, dim=self.n_actions)\n",
        "        if not evaluate:\n",
        "            actions = actions + noise\n",
        "\n",
        "        actions = tf.clip_by_value(actions, self.min_action, self.max_action)\n",
        "        self.bg_noise = noise\n",
        "        return actions[0]\n",
        "\n",
        "    def store_experience(self, state, action, reward, state_, done):\n",
        "        self.memory.store_experience(state, action, reward, state_, done)\n",
        "\n",
        "    def sample_experience(self):\n",
        "        state, action, reward, new_state, done = \\\n",
        "                                  self.memory.sample_experience(self.batch_size)\n",
        "        states = tf.convert_to_tensor(state)\n",
        "        rewards = tf.convert_to_tensor(reward)\n",
        "        dones = tf.convert_to_tensor(done)\n",
        "        actions = tf.convert_to_tensor(action)\n",
        "        states_ = tf.convert_to_tensor(new_state)\n",
        "        return states, actions, rewards, states_, dones\n",
        "\n",
        "    def save_models(self):\n",
        "        self.actor.save(self.fname + \"ddpg_actor_network\")\n",
        "        self.target_actor.save(self.fname + \"ddpg_target_actor_network\")\n",
        "        self.critic.save(self.fname  + \"ddpg_critic_network\")\n",
        "        self.target_critic.save(self.fname  + \"ddpg_target_critic_network\")\n",
        "        print(\"[+] Saving the models\")\n",
        "\n",
        "    def load_models(self):\n",
        "        self.actor = tf.keras.models.load_model(self.fname + \"_\" + \"ddpg_actor_network\")\n",
        "        self.target_actor = tf.keras.models.load_model(self.fname + \"_\" + \"ddpg_target-actor_network\")\n",
        "        self.critic = tf.keras.models.load_model(self.fname + \"_\" + \"ddpg_critic_network\")\n",
        "        self.target_critic = tf.keras.models.load_model(self.fname + \"_\" + \"ddpg_target_critic_network\")\n",
        "        print(\"[+] Loading the models\")\n",
        "\n",
        "    def learn(self):\n",
        "        if not self.memory.is_sufficient():\n",
        "            return\n",
        "        states, actions, rewards, next_states, dones = self.sample_experience()\n",
        "        states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
        "        next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
        "        rewards = tf.convert_to_tensor(rewards, tf.float32)\n",
        "        actions = tf.convert_to_tensor(actions, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            target_actions = self.target_actor(next_states)\n",
        "            one_step_lookahead_vals = tf.squeeze(self.target_critic(next_states, target_actions), 1)\n",
        "            q_vals = tf.squeeze(self.critic(states, actions), 1)\n",
        "            target_q_vals = rewards + self.gamma * one_step_lookahead_vals * ([1 - int(d) for d in dones])\n",
        "            critic_loss = self.critic_loss(q_vals, target_q_vals)\n",
        "\n",
        "        critic_params = self.critic.trainable_variables\n",
        "        critic_grads = tape.gradient(critic_loss, critic_params)\n",
        "        self.critic.optimizer.apply_gradients(zip(critic_grads, critic_params))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            pred_actions = self.actor(states)\n",
        "            q_vals = -self.critic(states, pred_actions)\n",
        "            actor_loss = self.actor_loss(q_vals)\n",
        "\n",
        "        actor_params = self.actor.trainable_variables\n",
        "        actor_grads = tape.gradient(actor_loss, actor_params)\n",
        "        self.actor.optimizer.apply_gradients(zip(actor_grads, actor_params))\n",
        "\n",
        "        self.update_target_networks()\n",
        "\n",
        "    def critic_loss(self, q_vals, target_q_vals):\n",
        "        loss = tf.keras.losses.MSE(q_vals, target_q_vals)\n",
        "        return loss\n",
        "\n",
        "    def actor_loss(self, q_vals):\n",
        "        return tf.math.reduce_mean(q_vals)\n",
        "\n",
        "    def update_target_networks(self):\n",
        "        actor_weights = self.actor.get_weights()\n",
        "        t_actor_weights = self.target_actor.get_weights()\n",
        "        critic_weights = self.critic.get_weights()\n",
        "        t_critic_weights = self.target_critic.get_weights()\n",
        "        if self.soft_update:\n",
        "            for i in range(len(actor_weights)):\n",
        "                t_actor_weights[i] = self.tau * actor_weights[i] + (1 - self.tau) * t_actor_weights[i]\n",
        "\n",
        "            for i in range(len(critic_weights)):\n",
        "                t_critic_weights[i] = self.tau * critic_weights[i] + (1 - self.tau) * t_critic_weights[i]\n",
        "\n",
        "            self.target_actor.set_weights(t_actor_weights)\n",
        "            self.target_critic.set_weights(t_critic_weights)\n",
        "\n",
        "        else:\n",
        "            self.target_actor.set_weights(t_actor_weights)\n",
        "            self.target_critic.set_weights(t_critic_weights)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T10:51:22.328756Z",
          "iopub.execute_input": "2023-03-26T10:51:22.329142Z",
          "iopub.status.idle": "2023-03-26T10:51:22.356770Z",
          "shell.execute_reply.started": "2023-03-26T10:51:22.329106Z",
          "shell.execute_reply": "2023-03-26T10:51:22.355641Z"
        },
        "trusted": true,
        "id": "Mfp_uhUp3RRW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_KG9NX73RRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from telebot import TeleBot\n",
        "import datetime\n",
        "import telebot\n",
        "\n",
        "token = \"6238487424:AAG0jRhvbiVa90qUcf2fAirQr_-quPMs7cU\"\n",
        "chat_id = \"1055055706\"\n",
        "bot = TeleBot(token=token)\n",
        "\n",
        "def telegram_send(message, bot):\n",
        "    chat_id = \"1055055706\"\n",
        "    bot.send_message(chat_id=chat_id, text=message)\n",
        "\n",
        "def welcome_msg(multi_step, double_dqn, dueling):\n",
        "    st = 'Hi! Starting learning with DQN Multi-step = %d, Double DQN = %r, Dueling DQN = %r' % (multi_step, double_dqn, dueling)\n",
        "    telegram_send(st, bot)\n",
        "\n",
        "def info_msg(episode, max_episode, reward, best_score, loss):\n",
        "    st = f\"Current Episode: {episode}, Current Reward: {reward}, Max Episode: {max_episode}, Best Score: {best_score}, loss: {loss}\"\n",
        "    telegram_send(st, bot)\n",
        "\n",
        "def end_msg(learning_time):\n",
        "    st = 'Finished! Learning time: ' + str(datetime.timedelta(seconds=int(learning_time)))\n",
        "    telegram_send(st, bot)\n",
        "    print(st)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T10:51:22.358500Z",
          "iopub.execute_input": "2023-03-26T10:51:22.358948Z",
          "iopub.status.idle": "2023-03-26T10:51:22.389344Z",
          "shell.execute_reply.started": "2023-03-26T10:51:22.358909Z",
          "shell.execute_reply": "2023-03-26T10:51:22.388411Z"
        },
        "trusted": true,
        "id": "d2RXYWQF3RRb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SzJF6IXw3RRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gymnasium as gym\n",
        "import tensorflow as tf\n",
        "from gymnasium.wrappers import *\n",
        "\n",
        "\n",
        "def manage_memory():\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        except RuntimeError as e:\n",
        "            print(e)\n",
        "\n",
        "\n",
        "def plot_learning_curve(x, scores, figure_file):\n",
        "    running_avg = np.zeros(len(scores))\n",
        "    for i in range(len(running_avg)):\n",
        "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
        "    plt.plot(x, running_avg)\n",
        "    plt.title('Running average of previous 100 scores')\n",
        "    plt.savefig(figure_file)\n",
        "\n",
        "\n",
        "def make_env(env_name, video_file_name, episode_freq_fo_video):\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "\n",
        "    if len(env.observation_space.shape) >= 3:\n",
        "        #env = AtariPreprocessing(env, 10, 4, 84, False, True)\n",
        "        env = ResizeObservation(env, 84)\n",
        "        env = GrayScaleObservation(env, keep_dim=False)\n",
        "        env = FrameStack(env, 4, lz4_compress=False)\n",
        "        env = NormalizeObservation(env)\n",
        "\n",
        "    return env"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T10:51:22.390607Z",
          "iopub.execute_input": "2023-03-26T10:51:22.391139Z",
          "iopub.status.idle": "2023-03-26T10:51:23.937719Z",
          "shell.execute_reply.started": "2023-03-26T10:51:22.391105Z",
          "shell.execute_reply": "2023-03-26T10:51:23.936671Z"
        },
        "trusted": true,
        "id": "tsfuZYtF3RRe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Writer:\n",
        "    def __init__(self, fname):\n",
        "        self.fname = fname\n",
        "\n",
        "    def write_to_file(self, content):\n",
        "        with open(self.fname, \"a\") as file:\n",
        "            file.write(content + \"\\n\")\n",
        "\n",
        "    def read_file(self, fname):\n",
        "        with open(fname, \"r\") as file:\n",
        "            return file.read()\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T10:51:23.939086Z",
          "iopub.execute_input": "2023-03-26T10:51:23.939560Z",
          "iopub.status.idle": "2023-03-26T10:51:23.947334Z",
          "shell.execute_reply.started": "2023-03-26T10:51:23.939523Z",
          "shell.execute_reply": "2023-03-26T10:51:23.945376Z"
        },
        "trusted": true,
        "id": "5mbUD14A3RRf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "\n",
        "class RecordVideo:\n",
        "\n",
        "    def __init__(self, prefix_fname,  out_directory=\"videos/\", fps=10):\n",
        "        self.prefix_fname = prefix_fname\n",
        "        self.out_directory = out_directory\n",
        "        self.fps = fps\n",
        "        self.images = []\n",
        "\n",
        "    def add_image(self, image):\n",
        "        self.images.append(image)\n",
        "\n",
        "    def save(self, episode_no):\n",
        "        name = self.out_directory + self.prefix_fname + \"_\" + str(episode_no) + \".mp4\"\n",
        "        imageio.mimsave(name, [np.array(img) for i, img in enumerate(self.images)], fps=self.fps)\n",
        "        self.images = []"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T12:49:23.277411Z",
          "iopub.execute_input": "2023-03-26T12:49:23.278377Z",
          "iopub.status.idle": "2023-03-26T12:49:23.286757Z",
          "shell.execute_reply.started": "2023-03-26T12:49:23.278324Z",
          "shell.execute_reply": "2023-03-26T12:49:23.285551Z"
        },
        "trusted": true,
        "id": "5_f44e193RRh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_JWiW9F3RRi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from npy_append_array import NpyAppendArray\n",
        "import numpy as np\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, env, gamma, alpha, beta, batch_size,\n",
        "                                     tau, sot_update, noe, max_steps,\n",
        "                                     is_tg, tg_bot_freq_epi, record,\n",
        "                                     mem_size, noise):\n",
        "\n",
        "        self.env = env\n",
        "        self.target_score = 80\n",
        "        self.noe = noe\n",
        "        self.max_steps = max_steps\n",
        "        self.is_tg = is_tg\n",
        "        self.tg_bot_freq_epi = tg_bot_freq_epi\n",
        "        self.record = record\n",
        "        self.writer = Writer(\"model_training_results.txt\")\n",
        "        self.recorder = RecordVideo(\"ddpg\", \"videos/\", 20)\n",
        "        self.agent = DDPGAgent(env.observation_space.shape,\n",
        "                               env.action_space.shape[0], gamma, alpha,\n",
        "                               beta, batch_size, mem_size,\n",
        "                               soft_update, tau, env.action_space.low[0],\n",
        "                               env.action_space.high[0], noise\n",
        "                            )\n",
        "\n",
        "    def train_rl_model(self):\n",
        "        avg_rewards = []\n",
        "        best_reward = float(\"-inf\")\n",
        "        episode_rewards = []\n",
        "        for episode in range(self.noe):\n",
        "            n_steps = 0\n",
        "            state = self.env.reset()\n",
        "            reward = 0\n",
        "\n",
        "            if record and episode % 50 == 0:\n",
        "                img = self.env.render()\n",
        "                self.recorder.add_image(img)\n",
        "\n",
        "            for step in range(self.max_steps):\n",
        "\n",
        "                if type(state) == tuple:\n",
        "                    state = state[0]\n",
        "                state = state\n",
        "\n",
        "                action = self.agent.get_action(state, evaluate=False)\n",
        "\n",
        "                next_info = self.env.step(action)\n",
        "                next_state, reward_prob, terminated, truncated, _ = next_info\n",
        "                done = truncated or terminated\n",
        "                reward += reward_prob\n",
        "\n",
        "                self.agent.store_experience(state, action, reward_prob, next_state, done)\n",
        "                self.agent.learn()\n",
        "\n",
        "                state = next_state\n",
        "                n_steps += 1\n",
        "\n",
        "                # record\n",
        "                if record and episode % 50 == 0:\n",
        "                    img = self.env.render()\n",
        "                    self.recorder.add_image(img)\n",
        "\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            episode_rewards.append(reward)\n",
        "            avg_reward = np.mean(episode_rewards[-100:])\n",
        "            avg_rewards.append(avg_reward)\n",
        "\n",
        "            result = f\"Episode: {episode}, Steps: {n_steps}, Reward: {reward}, Best reward: {best_reward}, Avg reward: {avg_reward}\"\n",
        "            self.writer.write_to_file(result)\n",
        "            print(result)\n",
        "\n",
        "            # Recording.\n",
        "            if record and episode % 50 == 0:\n",
        "                self.recorder.save(episode)\n",
        "\n",
        "            # Saving Best Model\n",
        "            if reward > best_reward:\n",
        "                best_reward = reward\n",
        "                self.agent.save_models()\n",
        "\n",
        "            # Telegram bot\n",
        "            if self.is_tg and episode % self.tg_bot_freq_epi == 0:\n",
        "                info_msg(episode+1, self.noe, reward, best_reward, \"d\")\n",
        "\n",
        "            # Eatly Stopping\n",
        "            if episode > 100 and np.mean(episode_rewards[-20:]) >= self.target_score:\n",
        "                break\n",
        "\n",
        "        return episode_rewards, avg_rewards, best_reward\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T12:51:18.443093Z",
          "iopub.execute_input": "2023-03-26T12:51:18.443562Z",
          "iopub.status.idle": "2023-03-26T12:51:18.460439Z",
          "shell.execute_reply.started": "2023-03-26T12:51:18.443524Z",
          "shell.execute_reply": "2023-03-26T12:51:18.458795Z"
        },
        "trusted": true,
        "id": "6A86nBhv3RRi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import time\n",
        "import signal\n",
        "import time\n",
        "import sys\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "env = make_env(\"MountainCarContinuous-v0\", \"videos/\", 50)\n",
        "record = False\n",
        "gamma = 0.9\n",
        "alpha = 0.001\n",
        "beta = 0.002\n",
        "batch_size = 64\n",
        "tau = 0.01\n",
        "soft_update = True\n",
        "noe = 500\n",
        "max_steps = 100000\n",
        "is_tg = True\n",
        "tg_bot_freq_epi = 20\n",
        "record = True\n",
        "mem_size = 5000000\n",
        "noise = 0.5\n",
        "\n",
        "\n",
        "if not os.path.exists(\"videos\"):\n",
        "    os.mkdir(\"videos\")\n",
        "\n",
        "if not os.path.exists(\"test_videos\"):\n",
        "    os.mkdir(\"test_videos\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    try:\n",
        "        manage_memory()\n",
        "        trainer = Trainer(env, gamma, alpha, beta, batch_size, tau,\n",
        "                          soft_update, noe, max_steps, is_tg,\n",
        "                          tg_bot_freq_epi, record, mem_size, noise\n",
        "                )\n",
        "        episode_rewards, avg_rewards, best_reward = trainer.train_rl_model()\n",
        "\n",
        "        with open(\"ddpg_episode_rewards.obj\", \"wb\") as f:\n",
        "            pickle.dump(episode_rewards, f)\n",
        "\n",
        "        with open(\"ddpg_avg_rewards.obj\", \"wb\") as f:\n",
        "            pickle.dump(avg_rewards, f)\n",
        "\n",
        "        x = [i+1 for i in range(len(episode_rewards))]\n",
        "        plot_learning_curve(x, episode_rewards, \"ddpg_con_mountain_car\")\n",
        "\n",
        "       # model_path = \"models/lunarlander_DQN_q_value/\"\n",
        "\n",
        "        #evaluator = Eval(env, action_space, model_path, \"vanilla_dqn_lunarlander\", 10)\n",
        "        #evaluator.test()\n",
        "\n",
        "    except Exception as error:\n",
        "        raise error\n",
        "\n",
        "   # eval_model(env, \"keras model\", \"videos/\", fps=10)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-26T12:54:00.647056Z",
          "iopub.execute_input": "2023-03-26T12:54:00.647452Z",
          "iopub.status.idle": "2023-03-26T13:44:38.355937Z",
          "shell.execute_reply.started": "2023-03-26T12:54:00.647415Z",
          "shell.execute_reply": "2023-03-26T13:44:38.353422Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Uq2SBgvs3RRk",
        "outputId": "f338221d-3bdf-419d-8206-8a063b0f4b3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 0, Steps: 999, Reward: -18.345257403946857, Best reward: -inf, Avg reward: -18.345257403946857\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] Saving the models\n",
            "Episode: 1, Steps: 999, Reward: -8.69484981633549, Best reward: -18.345257403946857, Avg reward: -13.520053610141172\n",
            "[+] Saving the models\n",
            "Episode: 2, Steps: 829, Reward: 89.83760830536033, Best reward: -8.69484981633549, Avg reward: 20.932500361692664\n",
            "[+] Saving the models\n",
            "Episode: 3, Steps: 659, Reward: 85.94509032949702, Best reward: 89.83760830536033, Avg reward: 37.18564785364375\n",
            "Episode: 4, Steps: 454, Reward: 80.93457761665556, Best reward: 89.83760830536033, Avg reward: 45.93543380624611\n",
            "Episode: 5, Steps: 874, Reward: 55.393410946955065, Best reward: 89.83760830536033, Avg reward: 47.5117633296976\n",
            "Episode: 6, Steps: 999, Reward: -16.723557087995403, Best reward: 89.83760830536033, Avg reward: 38.33528898431289\n",
            "Episode: 7, Steps: 587, Reward: 81.06411686312299, Best reward: 89.83760830536033, Avg reward: 43.676392469164156\n",
            "Episode: 8, Steps: 448, Reward: 93.11045323485213, Best reward: 89.83760830536033, Avg reward: 49.16906588757393\n",
            "[+] Saving the models\n",
            "Episode: 9, Steps: 262, Reward: 94.96680990918601, Best reward: 93.11045323485213, Avg reward: 53.74884028973514\n",
            "[+] Saving the models\n",
            "Episode: 10, Steps: 253, Reward: 94.44423973805007, Best reward: 94.96680990918601, Avg reward: 57.44842205776377\n",
            "Episode: 11, Steps: 241, Reward: 90.37445414598193, Best reward: 94.96680990918601, Avg reward: 60.19225806511529\n",
            "Episode: 12, Steps: 194, Reward: 96.30897684545994, Best reward: 94.96680990918601, Avg reward: 62.97046720206488\n",
            "[+] Saving the models\n",
            "Episode: 13, Steps: 281, Reward: 91.57542008774148, Best reward: 96.30897684545994, Avg reward: 65.01367812247035\n",
            "Episode: 14, Steps: 270, Reward: 91.33163096036672, Best reward: 96.30897684545994, Avg reward: 66.76820831166344\n",
            "Episode: 15, Steps: 339, Reward: 94.67092011630864, Best reward: 96.30897684545994, Avg reward: 68.51212779945376\n",
            "Episode: 16, Steps: 480, Reward: 85.4630816778776, Best reward: 96.30897684545994, Avg reward: 69.5092427334787\n",
            "Episode: 17, Steps: 578, Reward: 87.83152966129441, Best reward: 96.30897684545994, Avg reward: 70.52714756280179\n",
            "Episode: 18, Steps: 528, Reward: 80.7965808383876, Best reward: 96.30897684545994, Avg reward: 71.06764405099052\n",
            "Episode: 19, Steps: 363, Reward: 91.43562719406427, Best reward: 96.30897684545994, Avg reward: 72.0860432081442\n",
            "Episode: 20, Steps: 492, Reward: 92.36030117847167, Best reward: 96.30897684545994, Avg reward: 73.05148406387408\n",
            "Episode: 21, Steps: 174, Reward: 95.07335221886521, Best reward: 96.30897684545994, Avg reward: 74.05247807091914\n",
            "Episode: 22, Steps: 530, Reward: 94.4295562322732, Best reward: 96.30897684545994, Avg reward: 74.938437990978\n",
            "Episode: 23, Steps: 373, Reward: 94.55438819058993, Best reward: 96.30897684545994, Avg reward: 75.75576924929517\n",
            "Episode: 24, Steps: 152, Reward: 96.09838979672848, Best reward: 96.30897684545994, Avg reward: 76.5694740711925\n",
            "Episode: 25, Steps: 655, Reward: 87.81934398230165, Best reward: 96.30897684545994, Avg reward: 77.00216137546593\n",
            "Episode: 26, Steps: 377, Reward: 93.56805771954382, Best reward: 96.30897684545994, Avg reward: 77.61571309191325\n",
            "Episode: 27, Steps: 999, Reward: -18.823206970180443, Best reward: 96.30897684545994, Avg reward: 74.17146594683848\n",
            "Episode: 28, Steps: 161, Reward: 93.22117385203572, Best reward: 96.30897684545994, Avg reward: 74.82835242632805\n",
            "Episode: 29, Steps: 526, Reward: 94.1770912201962, Best reward: 96.30897684545994, Avg reward: 75.47331038612366\n",
            "Episode: 30, Steps: 378, Reward: 94.275635642637, Best reward: 96.30897684545994, Avg reward: 76.07983700730152\n",
            "Episode: 31, Steps: 229, Reward: 93.68705885922188, Best reward: 96.30897684545994, Avg reward: 76.63006269017401\n",
            "Episode: 32, Steps: 429, Reward: 93.59131929878923, Best reward: 96.30897684545994, Avg reward: 77.14404016316234\n",
            "Episode: 33, Steps: 332, Reward: 95.19794563952313, Best reward: 96.30897684545994, Avg reward: 77.67503738305531\n",
            "Episode: 34, Steps: 244, Reward: 89.04016513101028, Best reward: 96.30897684545994, Avg reward: 77.99975531871117\n",
            "Episode: 35, Steps: 175, Reward: 94.87254098673786, Best reward: 96.30897684545994, Avg reward: 78.46844380948968\n",
            "Episode: 36, Steps: 379, Reward: 88.7039437406792, Best reward: 96.30897684545994, Avg reward: 78.74507894276508\n",
            "Episode: 37, Steps: 261, Reward: 93.7109562247912, Best reward: 96.30897684545994, Avg reward: 79.13891781860787\n",
            "Episode: 38, Steps: 400, Reward: 92.40440843337383, Best reward: 96.30897684545994, Avg reward: 79.47905860360187\n",
            "Episode: 39, Steps: 231, Reward: 91.29619533387613, Best reward: 96.30897684545994, Avg reward: 79.77448702185873\n",
            "Episode: 40, Steps: 210, Reward: 94.78289277607708, Best reward: 96.30897684545994, Avg reward: 80.14054569879087\n",
            "Episode: 41, Steps: 235, Reward: 93.7054396648927, Best reward: 96.30897684545994, Avg reward: 80.46351936465045\n",
            "Episode: 42, Steps: 211, Reward: 93.81117859348521, Best reward: 96.30897684545994, Avg reward: 80.7739300443908\n",
            "Episode: 43, Steps: 272, Reward: 95.95821892242638, Best reward: 96.30897684545994, Avg reward: 81.1190275188916\n",
            "Episode: 44, Steps: 214, Reward: 94.76422262414269, Best reward: 96.30897684545994, Avg reward: 81.42225407678607\n",
            "Episode: 45, Steps: 180, Reward: 95.22824961375156, Best reward: 96.30897684545994, Avg reward: 81.7223844145462\n",
            "Episode: 46, Steps: 368, Reward: 94.58462655712984, Best reward: 96.30897684545994, Avg reward: 81.99604914098414\n",
            "Episode: 47, Steps: 282, Reward: 95.71988801382766, Best reward: 96.30897684545994, Avg reward: 82.28196245083505\n",
            "Episode: 48, Steps: 688, Reward: 80.87329378084053, Best reward: 96.30897684545994, Avg reward: 82.25321411063108\n",
            "Episode: 49, Steps: 188, Reward: 94.32924455122347, Best reward: 96.30897684545994, Avg reward: 82.49473471944293\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 50, Steps: 317, Reward: 94.78265552172515, Best reward: 96.30897684545994, Avg reward: 82.7356743430171\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 51, Steps: 160, Reward: 94.69305966134354, Best reward: 96.30897684545994, Avg reward: 82.96562406067723\n",
            "Episode: 52, Steps: 243, Reward: 92.4381195449072, Best reward: 96.30897684545994, Avg reward: 83.14435039056835\n",
            "Episode: 53, Steps: 188, Reward: 92.72010667923286, Best reward: 96.30897684545994, Avg reward: 83.3216792107288\n",
            "Episode: 54, Steps: 172, Reward: 95.04815195140826, Best reward: 96.30897684545994, Avg reward: 83.53488780601388\n",
            "Episode: 55, Steps: 194, Reward: 92.40719410927824, Best reward: 96.30897684545994, Avg reward: 83.6933218471436\n",
            "Episode: 56, Steps: 536, Reward: 93.58620948917608, Best reward: 96.30897684545994, Avg reward: 83.86688127945996\n",
            "Episode: 57, Steps: 285, Reward: 95.63217060678754, Best reward: 96.30897684545994, Avg reward: 84.06973109544836\n",
            "Episode: 58, Steps: 352, Reward: 92.82542164494973, Best reward: 96.30897684545994, Avg reward: 84.21813263018568\n",
            "Episode: 59, Steps: 348, Reward: 93.24652345905149, Best reward: 96.30897684545994, Avg reward: 84.36860581066678\n",
            "Episode: 60, Steps: 370, Reward: 95.25098583602824, Best reward: 96.30897684545994, Avg reward: 84.54700548321368\n",
            "Episode: 61, Steps: 150, Reward: 95.73461003198018, Best reward: 96.30897684545994, Avg reward: 84.7274507178712\n",
            "Episode: 62, Steps: 148, Reward: 95.72460995580921, Best reward: 96.30897684545994, Avg reward: 84.90200880101307\n",
            "Episode: 63, Steps: 499, Reward: 92.13663169324539, Best reward: 96.30897684545994, Avg reward: 85.01504978370421\n",
            "Episode: 64, Steps: 151, Reward: 95.22291744296497, Best reward: 96.30897684545994, Avg reward: 85.172093901539\n",
            "Episode: 65, Steps: 183, Reward: 95.39395600125384, Best reward: 96.30897684545994, Avg reward: 85.32697060001952\n",
            "Episode: 66, Steps: 200, Reward: 90.38362410139015, Best reward: 96.30897684545994, Avg reward: 85.4024430403385\n",
            "Episode: 67, Steps: 124, Reward: 94.99723012326191, Best reward: 96.30897684545994, Avg reward: 85.54354285038148\n",
            "Episode: 68, Steps: 252, Reward: 95.20182737939238, Best reward: 96.30897684545994, Avg reward: 85.68351798848309\n",
            "Episode: 69, Steps: 196, Reward: 95.79462425609093, Best reward: 96.30897684545994, Avg reward: 85.82796236373463\n",
            "Episode: 70, Steps: 196, Reward: 93.79005193539022, Best reward: 96.30897684545994, Avg reward: 85.94010447037766\n",
            "Episode: 71, Steps: 257, Reward: 94.92794089302494, Best reward: 96.30897684545994, Avg reward: 86.06493553180331\n",
            "Episode: 72, Steps: 274, Reward: 94.61311573183708, Best reward: 96.30897684545994, Avg reward: 86.18203389070787\n",
            "Episode: 73, Steps: 261, Reward: 92.40536182492028, Best reward: 96.30897684545994, Avg reward: 86.26613291684588\n",
            "Episode: 74, Steps: 363, Reward: 90.5935736668187, Best reward: 96.30897684545994, Avg reward: 86.32383212684552\n",
            "Episode: 75, Steps: 232, Reward: 95.12256924143712, Best reward: 96.30897684545994, Avg reward: 86.43960498361646\n",
            "Episode: 76, Steps: 157, Reward: 94.73460819623223, Best reward: 96.30897684545994, Avg reward: 86.54733229806602\n",
            "Episode: 77, Steps: 282, Reward: 93.65350698729839, Best reward: 96.30897684545994, Avg reward: 86.63843710177412\n",
            "Episode: 78, Steps: 338, Reward: 92.62115917844567, Best reward: 96.30897684545994, Avg reward: 86.7141677609725\n",
            "Episode: 79, Steps: 342, Reward: 93.57804424683869, Best reward: 96.30897684545994, Avg reward: 86.79996621704584\n",
            "Episode: 80, Steps: 80, Reward: 95.16959013103875, Best reward: 96.30897684545994, Avg reward: 86.90329490734204\n",
            "Episode: 81, Steps: 353, Reward: 92.8291438215576, Best reward: 96.30897684545994, Avg reward: 86.9755613575154\n",
            "Episode: 82, Steps: 242, Reward: 93.7027455977905, Best reward: 96.30897684545994, Avg reward: 87.05661177004883\n",
            "Episode: 83, Steps: 483, Reward: 93.14576518215574, Best reward: 96.30897684545994, Avg reward: 87.12910169162153\n",
            "Episode: 84, Steps: 396, Reward: 91.31824785084866, Best reward: 96.30897684545994, Avg reward: 87.17838576408303\n",
            "Episode: 85, Steps: 770, Reward: 88.69696154031476, Best reward: 96.30897684545994, Avg reward: 87.19604362194619\n",
            "Episode: 86, Steps: 300, Reward: 86.4892208468148, Best reward: 96.30897684545994, Avg reward: 87.18791922223204\n",
            "Episode: 87, Steps: 377, Reward: 90.0811895093487, Best reward: 96.30897684545994, Avg reward: 87.22079729367655\n",
            "Episode: 88, Steps: 276, Reward: 91.54112357341776, Best reward: 96.30897684545994, Avg reward: 87.26934028558377\n",
            "Episode: 89, Steps: 182, Reward: 94.40131514638576, Best reward: 96.30897684545994, Avg reward: 87.34858445070378\n",
            "Episode: 90, Steps: 258, Reward: 94.21517030633838, Best reward: 96.30897684545994, Avg reward: 87.42404143812834\n",
            "Episode: 91, Steps: 313, Reward: 95.05720642617214, Best reward: 96.30897684545994, Avg reward: 87.507010622781\n",
            "Episode: 92, Steps: 254, Reward: 94.43010399448627, Best reward: 96.30897684545994, Avg reward: 87.58145248699289\n",
            "Episode: 93, Steps: 184, Reward: 94.5188485618599, Best reward: 96.30897684545994, Avg reward: 87.65525457289571\n",
            "Episode: 94, Steps: 205, Reward: 95.25674091071458, Best reward: 96.30897684545994, Avg reward: 87.73527021855696\n",
            "Episode: 95, Steps: 341, Reward: 84.51465201438185, Best reward: 96.30897684545994, Avg reward: 87.70172211226345\n",
            "Episode: 96, Steps: 231, Reward: 92.6813833055217, Best reward: 96.30897684545994, Avg reward: 87.75305882559603\n",
            "Episode: 97, Steps: 398, Reward: 89.23218193073453, Best reward: 96.30897684545994, Avg reward: 87.7681519185056\n",
            "Episode: 98, Steps: 297, Reward: 81.9572094180089, Best reward: 96.30897684545994, Avg reward: 87.7094555296117\n",
            "Episode: 99, Steps: 226, Reward: 95.64913246088668, Best reward: 96.30897684545994, Avg reward: 87.78885229892445\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 100, Steps: 140, Reward: 92.18556863892682, Best reward: 96.30897684545994, Avg reward: 88.89416055935318\n",
            "Episode: 101, Steps: 172, Reward: 94.39413737067419, Best reward: 96.30897684545994, Avg reward: 89.9250504312233\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-or-GYIx3RRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8czjHUE3RRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHQtNRP-3RRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ml9ztBI-3RRm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}